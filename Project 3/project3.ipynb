{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "07d7229b-be81-4f17-81fd-cc661b9bbdf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "57bc62b9-ee0a-4ee8-9f05-9f733857e39b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(index):\n",
    "    encoding = np.zeros(4)\n",
    "    encoding[index] = 1\n",
    "    \n",
    "    return encoding\n",
    "\n",
    "def generate_diagram():\n",
    "    D = 20\n",
    "    diagram = np.zeros((D, D, 4), dtype=np.int8) # 20 x 20 diagram\n",
    "\n",
    "    color_order = random.sample(range(1, 4 + 1), 4) # pre-picking order of colors for the 4 wires \n",
    "    row_order = random.sample(range(20), 2) # pre-picking the order of rows to set to that color\n",
    "    col_order = random.sample(range(20), 2) # pre-picking the order of columns\n",
    "\n",
    "    if random.random() <= 0.5: # 50% chance starting with rows/columns \n",
    "        diagram[row_order[0],:] = one_hot_encoding(color_order[0] - 1)\n",
    "        diagram[:,col_order[0]] = one_hot_encoding(color_order[1] - 1)\n",
    "        diagram[row_order[1],:] = one_hot_encoding(color_order[2] - 1)\n",
    "        diagram[:,col_order[1]] = one_hot_encoding(color_order[3] - 1)\n",
    "    else:\n",
    "        diagram[:,col_order[0]] = one_hot_encoding(color_order[1] - 1)\n",
    "        diagram[row_order[0],:] = one_hot_encoding(color_order[0] - 1)\n",
    "        diagram[:,col_order[1]] = one_hot_encoding(color_order[3] - 1)\n",
    "        diagram[row_order[1],:] = one_hot_encoding(color_order[2] - 1)\n",
    "\n",
    "    # display(diagram)\n",
    "\n",
    "    # dangerous = color_order.index(1) < color_order.index(3) # red before yellow means dangerous\n",
    "    dangerous = (color_order.index(1) < color_order.index(3)) and ((color_order.index(1) % 2) != (color_order.index(3) % 2))\n",
    "    cut = color_order[2] # 3rd wire \"always to be cut\"\n",
    "\n",
    "    return diagram, int(dangerous)\n",
    "\n",
    "def to_emoji(color):\n",
    "    colors = { 'red', 'blue', 'yellow', 'green' }\n",
    "    color_emojis = [ 'â¬›', 'ðŸŸ¥', 'ðŸŸ¦', 'ðŸŸ¨', 'ðŸŸ©' ]\n",
    "\n",
    "    return color_emojis[color]\n",
    "\n",
    "def display(diagram):\n",
    "    for y in range(len(diagram)):\n",
    "        for x in range(len(diagram[0])):\n",
    "            print(to_emoji(diagram[y, x]), end='')\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "2e1b4608-b7a4-47d6-bcee-7c8811fd78a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_dataset(size):\n",
    "    diagrams = []\n",
    "    dangerous = []\n",
    "    \n",
    "    for i in range(size):\n",
    "        diagram, danger = generate_diagram()\n",
    "        diagrams.append(diagram)\n",
    "        dangerous.append(danger)\n",
    "        \n",
    "    return np.array(diagrams), np.array(dangerous)\n",
    "\n",
    "diagrams, danger = generate_dataset(5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "7300d347-4c08-4d6d-aaf1-3173a95ba451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5500, 20, 20, 4)"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "1b0a77de-5528-40e0-9179-674b7d490d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 1600), (5000,), (500, 1600), (500,))"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(diagrams, danger, test_size=500/5500)\n",
    "num_features = 20 * 20 * 4\n",
    "\n",
    "X_train = X_train.reshape(-1, num_features)\n",
    "X_test = X_test.reshape(-1, num_features)\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "c0646bf3-6f7f-4330-a748-ba162aa6d188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3297\n",
       "1    1703\n",
       "dtype: int64"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "id": "bed44305-84f3-40ed-bb5b-c524eb273bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def f(X, weights):\n",
    "    return sigmoid(np.dot(X, weights))\n",
    "\n",
    "def BCE_loss_fn(X, y, weights, r_lambda=0):\n",
    "    epsilon = 1e-15  # to avoid log(0) error\n",
    "    predictions = f(X, weights)\n",
    "    predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "    \n",
    "    l2_reg_term = r_lambda * np.mean(np.square(weights))\n",
    "    \n",
    "    return -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions)) + l2_reg_term\n",
    "\n",
    "def compute_gradient(X, y, weights, r_lambda=0):\n",
    "    predictions = f(X, weights)\n",
    "    error = predictions - y\n",
    "    \n",
    "    gradient = np.dot(X.T, error) / X.shape[0]\n",
    "    \n",
    "    l2_reg_term = r_lambda * weights\n",
    "\n",
    "    return gradient + l2_reg_term / X.shape[0]\n",
    "\n",
    "def compute_gradient_SGD(X, y, weights, index, r_lambda=0):\n",
    "    predictions = f(X[index], weights)\n",
    "    error = predictions - y[index]\n",
    "    gradient = np.dot(X[index].T, error)\n",
    "    \n",
    "    l2_reg = r_lambda * weights\n",
    "    \n",
    "    return gradient + l2_reg / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "abf8eb89-3137-4ea1-91f9-649591e3b53b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1600)"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "c0a50f5f-8a7f-4106-97e3-c6817812cebe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931471805599454, Test Loss: 0.6548507859362701, Test Accuracy: 63.80%\n",
      "Epoch 1, Loss: 0.6390462740458499, Test Loss: 0.6562540939047968, Test Accuracy: 63.80%\n",
      "Epoch 2, Loss: 0.6355973560080813, Test Loss: 0.6573940608776385, Test Accuracy: 63.80%\n",
      "Epoch 3, Loss: 0.633373448548577, Test Loss: 0.6584430342794587, Test Accuracy: 63.80%\n",
      "Epoch 4, Loss: 0.631576749403781, Test Loss: 0.6594912363659639, Test Accuracy: 63.80%\n",
      "Epoch 5, Loss: 0.6301011140582612, Test Loss: 0.6605342577050561, Test Accuracy: 63.80%\n",
      "Epoch 6, Loss: 0.6288785928379951, Test Loss: 0.6615550065091437, Test Accuracy: 63.80%\n",
      "Epoch 7, Loss: 0.6278565756913284, Test Loss: 0.6625394771555108, Test Accuracy: 63.80%\n",
      "Epoch 8, Loss: 0.6269939386696086, Test Loss: 0.6634782733976322, Test Accuracy: 63.60%\n",
      "Epoch 9, Loss: 0.6262584546418881, Test Loss: 0.6643657747287485, Test Accuracy: 63.40%\n",
      "Epoch 10, Loss: 0.6256247953452214, Test Loss: 0.6651991484271227, Test Accuracy: 63.40%\n",
      "Epoch 11, Loss: 0.6250729892721969, Test Loss: 0.6659775499690477, Test Accuracy: 63.40%\n",
      "Epoch 12, Loss: 0.6245872334651401, Test Loss: 0.6667015212008373, Test Accuracy: 63.40%\n",
      "Epoch 13, Loss: 0.624154977914496, Test Loss: 0.6673725464931699, Test Accuracy: 63.00%\n",
      "Epoch 14, Loss: 0.6237662191034732, Test Loss: 0.6679927282423694, Test Accuracy: 63.20%\n",
      "Epoch 15, Loss: 0.6234129537774763, Test Loss: 0.668564551206154, Test Accuracy: 62.80%\n",
      "Epoch 16, Loss: 0.6230887554755777, Test Loss: 0.6690907126437485, Test Accuracy: 62.80%\n",
      "Epoch 17, Loss: 0.6227884452355162, Test Loss: 0.6695740010874137, Test Accuracy: 62.80%\n",
      "Epoch 18, Loss: 0.6225078346853541, Test Loss: 0.6700172109851056, Test Accuracy: 62.80%\n",
      "Epoch 19, Loss: 0.622243524916463, Test Loss: 0.6704230837421912, Test Accuracy: 62.60%\n",
      "Epoch 20, Loss: 0.621992748467098, Test Loss: 0.6707942681322964, Test Accuracy: 62.60%\n",
      "Epoch 21, Loss: 0.6217532447297506, Test Loss: 0.6711332948597464, Test Accuracy: 63.00%\n",
      "Epoch 22, Loss: 0.6215231613587235, Test Loss: 0.6714425614014216, Test Accuracy: 62.80%\n",
      "Epoch 23, Loss: 0.6213009759729088, Test Loss: 0.6717243242553433, Test Accuracy: 62.60%\n",
      "Epoch 24, Loss: 0.6210854337560417, Test Loss: 0.6719806964665476, Test Accuracy: 62.60%\n",
      "Epoch 25, Loss: 0.6208754975535091, Test Loss: 0.6722136488540948, Test Accuracy: 62.60%\n",
      "Epoch 26, Loss: 0.6206703078268547, Test Loss: 0.6724250137753156, Test Accuracy: 62.80%\n",
      "Epoch 27, Loss: 0.6204691504114908, Test Loss: 0.6726164905708057, Test Accuracy: 62.80%\n",
      "Epoch 28, Loss: 0.6202714304725783, Test Loss: 0.6727896520629936, Test Accuracy: 62.80%\n",
      "Epoch 29, Loss: 0.6200766514008837, Test Loss: 0.6729459516521775, Test Accuracy: 62.60%\n",
      "Epoch 30, Loss: 0.6198843976589299, Test Loss: 0.6730867306814791, Test Accuracy: 62.60%\n",
      "Epoch 31, Loss: 0.6196943207963409, Test Loss: 0.6732132258371479, Test Accuracy: 62.60%\n",
      "Epoch 32, Loss: 0.6195061280158407, Test Loss: 0.6733265764212477, Test Accuracy: 62.60%\n",
      "Epoch 33, Loss: 0.6193195727984787, Test Loss: 0.6734278313860799, Test Accuracy: 62.60%\n",
      "Epoch 34, Loss: 0.6191344471963854, Test Loss: 0.6735179560582841, Test Accuracy: 62.60%\n",
      "Epoch 35, Loss: 0.6189505754798602, Test Loss: 0.6735978385088802, Test Accuracy: 62.60%\n",
      "Epoch 36, Loss: 0.6187678088875769, Test Loss: 0.6736682955460953, Test Accuracy: 62.60%\n",
      "Epoch 37, Loss: 0.6185860212778032, Test Loss: 0.6737300783226439, Test Accuracy: 62.60%\n",
      "Epoch 38, Loss: 0.618405105517548, Test Loss: 0.6737838775596133, Test Accuracy: 62.40%\n",
      "Epoch 39, Loss: 0.6182249704776571, Test Loss: 0.6738303283963804, Test Accuracy: 62.40%\n",
      "Epoch 40, Loss: 0.6180455385267476, Test Loss: 0.6738700148808557, Test Accuracy: 62.40%\n",
      "Epoch 41, Loss: 0.6178667434368152, Test Loss: 0.6739034741174572, Test Accuracy: 62.40%\n",
      "Epoch 42, Loss: 0.6176885286293856, Test Loss: 0.6739312000920231, Test Accuracy: 62.40%\n",
      "Epoch 43, Loss: 0.6175108457040173, Test Loss: 0.6739536471937329, Test Accuracy: 62.40%\n",
      "Epoch 44, Loss: 0.6173336532014273, Test Loss: 0.6739712334542944, Test Accuracy: 62.40%\n",
      "Epoch 45, Loss: 0.6171569155619954, Test Loss: 0.6739843435243614, Test Accuracy: 62.60%\n",
      "Epoch 46, Loss: 0.6169806022472968, Test Loss: 0.6739933314065266, Test Accuracy: 62.60%\n",
      "Epoch 47, Loss: 0.616804686997948, Test Loss: 0.6739985229634062, Test Accuracy: 62.60%\n",
      "Epoch 48, Loss: 0.6166291472056344, Test Loss: 0.674000218218357, Test Accuracy: 62.60%\n",
      "Epoch 49, Loss: 0.6164539633809666, Test Loss: 0.6739986934653301, Test Accuracy: 62.60%\n",
      "Epoch 50, Loss: 0.6162791187018978, Test Loss: 0.6739942032032943, Test Accuracy: 62.60%\n",
      "Epoch 51, Loss: 0.6161045986299829, Test Loss: 0.6739869819095917, Test Accuracy: 62.60%\n",
      "Epoch 52, Loss: 0.6159303905838639, Test Loss: 0.6739772456655443, Test Accuracy: 62.40%\n",
      "Epoch 53, Loss: 0.6157564836610974, Test Loss: 0.6739651936466207, Test Accuracy: 62.40%\n",
      "Epoch 54, Loss: 0.6155828684008852, Test Loss: 0.6739510094885152, Test Accuracy: 62.40%\n",
      "Epoch 55, Loss: 0.6154095365814607, Test Loss: 0.6739348625395862, Test Accuracy: 62.40%\n",
      "Epoch 56, Loss: 0.6152364810468782, Test Loss: 0.6739169090092493, Test Accuracy: 62.40%\n",
      "Epoch 57, Loss: 0.6150636955587852, Test Loss: 0.6738972930211302, Test Accuracy: 62.40%\n",
      "Epoch 58, Loss: 0.6148911746694409, Test Loss: 0.6738761475790497, Test Accuracy: 62.40%\n",
      "Epoch 59, Loss: 0.6147189136128383, Test Loss: 0.6738535954532279, Test Accuracy: 62.40%\n",
      "Epoch 60, Loss: 0.6145469082112534, Test Loss: 0.6738297499934736, Test Accuracy: 62.40%\n",
      "Epoch 61, Loss: 0.614375154794971, Test Loss: 0.6738047158755432, Test Accuracy: 62.40%\n",
      "Epoch 62, Loss: 0.6142036501332669, Test Loss: 0.6737785897863244, Test Accuracy: 62.40%\n",
      "Epoch 63, Loss: 0.6140323913750209, Test Loss: 0.673751461053017, Test Accuracy: 62.40%\n",
      "Epoch 64, Loss: 0.6138613759975748, Test Loss: 0.6737234122210319, Test Accuracy: 62.40%\n",
      "Epoch 65, Loss: 0.6136906017626604, Test Loss: 0.6736945195849281, Test Accuracy: 62.40%\n",
      "Epoch 66, Loss: 0.6135200666783872, Test Loss: 0.6736648536763321, Test Accuracy: 62.40%\n",
      "Epoch 67, Loss: 0.6133497689664411, Test Loss: 0.6736344797124414, Test Accuracy: 62.40%\n",
      "Epoch 68, Loss: 0.6131797070337535, Test Loss: 0.6736034580084113, Test Accuracy: 62.40%\n",
      "Epoch 69, Loss: 0.6130098794480194, Test Loss: 0.6735718443566309, Test Accuracy: 62.40%\n",
      "Epoch 70, Loss: 0.612840284916529, Test Loss: 0.6735396903756418, Test Accuracy: 62.40%\n",
      "Epoch 71, Loss: 0.612670922267851, Test Loss: 0.673507043831215, Test Accuracy: 62.40%\n",
      "Epoch 72, Loss: 0.6125017904359757, Test Loss: 0.6734739489318857, Test Accuracy: 62.40%\n",
      "Epoch 73, Loss: 0.6123328884465793, Test Loss: 0.6734404466010501, Test Accuracy: 62.40%\n",
      "Epoch 74, Loss: 0.6121642154051202, Test Loss: 0.6734065747275496, Test Accuracy: 62.40%\n",
      "Epoch 75, Loss: 0.6119957704865159, Test Loss: 0.6733723683965005, Test Accuracy: 62.40%\n",
      "Epoch 76, Loss: 0.6118275529261885, Test Loss: 0.6733378601019844, Test Accuracy: 62.40%\n",
      "Epoch 77, Loss: 0.6116595620122915, Test Loss: 0.6733030799430725, Test Accuracy: 62.40%\n",
      "Epoch 78, Loss: 0.6114917970789597, Test Loss: 0.6732680558045356, Test Accuracy: 62.40%\n",
      "Epoch 79, Loss: 0.6113242575004452, Test Loss: 0.6732328135234789, Test Accuracy: 62.40%\n",
      "Epoch 80, Loss: 0.6111569426860204, Test Loss: 0.6731973770430313, Test Accuracy: 62.40%\n",
      "Epoch 81, Loss: 0.6109898520755465, Test Loss: 0.6731617685541375, Test Accuracy: 62.40%\n",
      "Epoch 82, Loss: 0.6108229851356187, Test Loss: 0.6731260086263952, Test Accuracy: 62.40%\n",
      "Epoch 83, Loss: 0.6106563413562115, Test Loss: 0.6730901163288192, Test Accuracy: 62.40%\n",
      "Epoch 84, Loss: 0.6104899202477581, Test Loss: 0.6730541093413317, Test Accuracy: 62.40%\n",
      "Epoch 85, Loss: 0.610323721338607, Test Loss: 0.6730180040577135, Test Accuracy: 62.20%\n",
      "Epoch 86, Loss: 0.6101577441728078, Test Loss: 0.6729818156806934, Test Accuracy: 62.20%\n",
      "Epoch 87, Loss: 0.6099919883081796, Test Loss: 0.6729455583097942, Test Accuracy: 62.20%\n",
      "Epoch 88, Loss: 0.6098264533146276, Test Loss: 0.6729092450225056, Test Accuracy: 62.40%\n",
      "Epoch 89, Loss: 0.6096611387726766, Test Loss: 0.6728728879493078, Test Accuracy: 62.40%\n",
      "Epoch 90, Loss: 0.6094960442721903, Test Loss: 0.672836498343025, Test Accuracy: 62.40%\n",
      "Epoch 91, Loss: 0.6093311694112542, Test Loss: 0.6728000866429509, Test Accuracy: 62.40%\n",
      "Epoch 92, Loss: 0.6091665137952007, Test Loss: 0.6727636625341552, Test Accuracy: 62.40%\n",
      "Epoch 93, Loss: 0.6090020770357585, Test Loss: 0.6727272350023408, Test Accuracy: 62.40%\n",
      "Epoch 94, Loss: 0.6088378587503092, Test Loss: 0.6726908123845979, Test Accuracy: 62.40%\n",
      "Epoch 95, Loss: 0.608673858561238, Test Loss: 0.6726544024163715, Test Accuracy: 62.40%\n",
      "Epoch 96, Loss: 0.6085100760953667, Test Loss: 0.6726180122749319, Test Accuracy: 62.40%\n",
      "Epoch 97, Loss: 0.6083465109834583, Test Loss: 0.6725816486196173, Test Accuracy: 62.40%\n",
      "Epoch 98, Loss: 0.6081831628597836, Test Loss: 0.6725453176290958, Test Accuracy: 62.40%\n",
      "Epoch 99, Loss: 0.6080200313617423, Test Loss: 0.6725090250358723, Test Accuracy: 62.40%\n",
      "Epoch 100, Loss: 0.6078571161295319, Test Loss: 0.6724727761582528, Test Accuracy: 62.40%\n",
      "Epoch 101, Loss: 0.6076944168058588, Test Loss: 0.6724365759299563, Test Accuracy: 62.40%\n",
      "Epoch 102, Loss: 0.6075319330356842, Test Loss: 0.672400428927553, Test Accuracy: 62.40%\n",
      "Epoch 103, Loss: 0.6073696644660022, Test Loss: 0.6723643393958947, Test Accuracy: 62.40%\n",
      "Epoch 104, Loss: 0.6072076107456467, Test Loss: 0.6723283112716857, Test Accuracy: 62.40%\n",
      "Epoch 105, Loss: 0.607045771525121, Test Loss: 0.6722923482053366, Test Accuracy: 62.40%\n",
      "Epoch 106, Loss: 0.6068841464564495, Test Loss: 0.672256453581229, Test Accuracy: 62.40%\n",
      "Epoch 107, Loss: 0.6067227351930473, Test Loss: 0.6722206305365067, Test Accuracy: 62.40%\n",
      "Epoch 108, Loss: 0.6065615373896068, Test Loss: 0.6721848819785101, Test Accuracy: 62.40%\n",
      "Epoch 109, Loss: 0.6064005527019976, Test Loss: 0.6721492106009471, Test Accuracy: 62.40%\n",
      "Epoch 110, Loss: 0.6062397807871789, Test Loss: 0.672113618898901, Test Accuracy: 62.40%\n",
      "Epoch 111, Loss: 0.6060792213031235, Test Loss: 0.6720781091827553, Test Accuracy: 62.40%\n",
      "Epoch 112, Loss: 0.6059188739087511, Test Loss: 0.672042683591123, Test Accuracy: 62.40%\n",
      "Epoch 113, Loss: 0.6057587382638682, Test Loss: 0.6720073441028439, Test Accuracy: 62.40%\n",
      "Epoch 114, Loss: 0.6055988140291181, Test Loss: 0.6719720925481295, Test Accuracy: 62.40%\n",
      "Epoch 115, Loss: 0.6054391008659353, Test Loss: 0.6719369306189095, Test Accuracy: 62.40%\n",
      "Epoch 116, Loss: 0.6052795984365059, Test Loss: 0.6719018598784411, Test Accuracy: 62.40%\n",
      "Epoch 117, Loss: 0.6051203064037329, Test Loss: 0.6718668817702389, Test Accuracy: 62.40%\n",
      "Epoch 118, Loss: 0.6049612244312065, Test Loss: 0.671831997626366, Test Accuracy: 62.40%\n",
      "Epoch 119, Loss: 0.6048023521831768, Test Loss: 0.6717972086751443, Test Accuracy: 62.40%\n",
      "Epoch 120, Loss: 0.6046436893245307, Test Loss: 0.6717625160483149, Test Accuracy: 62.40%\n",
      "Epoch 121, Loss: 0.6044852355207722, Test Loss: 0.6717279207876969, Test Accuracy: 62.40%\n",
      "Epoch 122, Loss: 0.6043269904380025, Test Loss: 0.6716934238513764, Test Accuracy: 62.40%\n",
      "Epoch 123, Loss: 0.6041689537429077, Test Loss: 0.6716590261194612, Test Accuracy: 62.40%\n",
      "Epoch 124, Loss: 0.6040111251027414, Test Loss: 0.6716247283994314, Test Accuracy: 62.40%\n",
      "Epoch 125, Loss: 0.6038535041853149, Test Loss: 0.6715905314311165, Test Accuracy: 62.40%\n",
      "Epoch 126, Loss: 0.6036960906589862, Test Loss: 0.671556435891325, Test Accuracy: 62.40%\n",
      "Epoch 127, Loss: 0.6035388841926502, Test Loss: 0.6715224423981507, Test Accuracy: 62.40%\n",
      "Epoch 128, Loss: 0.6033818844557313, Test Loss: 0.6714885515149792, Test Accuracy: 62.40%\n",
      "Epoch 129, Loss: 0.6032250911181751, Test Loss: 0.6714547637542175, Test Accuracy: 62.40%\n",
      "Epoch 130, Loss: 0.6030685038504442, Test Loss: 0.6714210795807637, Test Accuracy: 62.40%\n",
      "Epoch 131, Loss: 0.6029121223235101, Test Loss: 0.6713874994152375, Test Accuracy: 62.40%\n",
      "Epoch 132, Loss: 0.6027559462088511, Test Loss: 0.6713540236369873, Test Accuracy: 62.40%\n",
      "Epoch 133, Loss: 0.6025999751784453, Test Loss: 0.6713206525868889, Test Accuracy: 62.40%\n",
      "Epoch 134, Loss: 0.6024442089047694, Test Loss: 0.671287386569955, Test Accuracy: 62.40%\n",
      "Epoch 135, Loss: 0.6022886470607937, Test Loss: 0.6712542258577608, Test Accuracy: 62.40%\n",
      "Epoch 136, Loss: 0.6021332893199801, Test Loss: 0.6712211706907072, Test Accuracy: 62.40%\n",
      "Epoch 137, Loss: 0.6019781353562798, Test Loss: 0.6711882212801263, Test Accuracy: 62.40%\n",
      "Epoch 138, Loss: 0.6018231848441293, Test Loss: 0.6711553778102455, Test Accuracy: 62.40%\n",
      "Epoch 139, Loss: 0.6016684374584514, Test Loss: 0.6711226404400148, Test Accuracy: 62.40%\n",
      "Epoch 140, Loss: 0.6015138928746507, Test Loss: 0.6710900093048127, Test Accuracy: 62.40%\n",
      "Epoch 141, Loss: 0.6013595507686137, Test Loss: 0.6710574845180336, Test Accuracy: 62.40%\n",
      "Epoch 142, Loss: 0.6012054108167069, Test Loss: 0.671025066172569, Test Accuracy: 62.20%\n",
      "Epoch 143, Loss: 0.6010514726957754, Test Loss: 0.6709927543421873, Test Accuracy: 62.20%\n",
      "Epoch 144, Loss: 0.6008977360831428, Test Loss: 0.6709605490828214, Test Accuracy: 62.20%\n",
      "Epoch 145, Loss: 0.6007442006566089, Test Loss: 0.6709284504337679, Test Accuracy: 62.20%\n",
      "Epoch 146, Loss: 0.6005908660944498, Test Loss: 0.670896458418807, Test Accuracy: 62.20%\n",
      "Epoch 147, Loss: 0.600437732075417, Test Loss: 0.6708645730472458, Test Accuracy: 62.20%\n",
      "Epoch 148, Loss: 0.6002847982787363, Test Loss: 0.6708327943148921, Test Accuracy: 62.20%\n",
      "Epoch 149, Loss: 0.6001320643841078, Test Loss: 0.6708011222049624, Test Accuracy: 62.20%\n",
      "Epoch 150, Loss: 0.599979530071705, Test Loss: 0.67076955668893, Test Accuracy: 62.20%\n",
      "Epoch 151, Loss: 0.5998271950221742, Test Loss: 0.6707380977273147, Test Accuracy: 62.20%\n",
      "Epoch 152, Loss: 0.5996750589166344, Test Loss: 0.6707067452704214, Test Accuracy: 62.20%\n",
      "Epoch 153, Loss: 0.5995231214366763, Test Loss: 0.6706754992590291, Test Accuracy: 62.20%\n",
      "Epoch 154, Loss: 0.5993713822643626, Test Loss: 0.6706443596250327, Test Accuracy: 62.20%\n",
      "Epoch 155, Loss: 0.5992198410822271, Test Loss: 0.6706133262920441, Test Accuracy: 62.20%\n",
      "Epoch 156, Loss: 0.5990684975732751, Test Loss: 0.6705823991759515, Test Accuracy: 62.20%\n",
      "Epoch 157, Loss: 0.5989173514209816, Test Loss: 0.670551578185444, Test Accuracy: 62.20%\n",
      "Epoch 158, Loss: 0.5987664023092929, Test Loss: 0.6705208632224975, Test Accuracy: 62.20%\n",
      "Epoch 159, Loss: 0.5986156499226246, Test Loss: 0.6704902541828341, Test Accuracy: 62.20%\n",
      "Epoch 160, Loss: 0.5984650939458627, Test Loss: 0.6704597509563457, Test Accuracy: 62.20%\n",
      "Epoch 161, Loss: 0.5983147340643624, Test Loss: 0.6704293534274927, Test Accuracy: 62.20%\n",
      "Epoch 162, Loss: 0.5981645699639481, Test Loss: 0.6703990614756759, Test Accuracy: 62.20%\n",
      "Epoch 163, Loss: 0.5980146013309133, Test Loss: 0.670368874975584, Test Accuracy: 62.20%\n",
      "Epoch 164, Loss: 0.5978648278520206, Test Loss: 0.6703387937975175, Test Accuracy: 62.20%\n",
      "Epoch 165, Loss: 0.5977152492145004, Test Loss: 0.6703088178076927, Test Accuracy: 62.20%\n",
      "Epoch 166, Loss: 0.5975658651060519, Test Loss: 0.6702789468685246, Test Accuracy: 62.20%\n",
      "Epoch 167, Loss: 0.5974166752148421, Test Loss: 0.6702491808388921, Test Accuracy: 62.20%\n",
      "Epoch 168, Loss: 0.5972676792295061, Test Loss: 0.6702195195743846, Test Accuracy: 62.20%\n",
      "Epoch 169, Loss: 0.5971188768391463, Test Loss: 0.6701899629275351, Test Accuracy: 62.20%\n",
      "Epoch 170, Loss: 0.5969702677333324, Test Loss: 0.6701605107480345, Test Accuracy: 62.20%\n",
      "Epoch 171, Loss: 0.5968218516021014, Test Loss: 0.6701311628829358, Test Accuracy: 62.20%\n",
      "Epoch 172, Loss: 0.596673628135957, Test Loss: 0.670101919176842, Test Accuracy: 62.00%\n",
      "Epoch 173, Loss: 0.5965255970258697, Test Loss: 0.6700727794720832, Test Accuracy: 62.00%\n",
      "Epoch 174, Loss: 0.5963777579632762, Test Loss: 0.6700437436088821, Test Accuracy: 62.00%\n",
      "Epoch 175, Loss: 0.5962301106400794, Test Loss: 0.6700148114255081, Test Accuracy: 62.00%\n",
      "Epoch 176, Loss: 0.5960826547486477, Test Loss: 0.6699859827584231, Test Accuracy: 62.20%\n",
      "Epoch 177, Loss: 0.5959353899818162, Test Loss: 0.6699572574424157, Test Accuracy: 62.20%\n",
      "Epoch 178, Loss: 0.5957883160328843, Test Loss: 0.6699286353107285, Test Accuracy: 62.20%\n",
      "Epoch 179, Loss: 0.5956414325956172, Test Loss: 0.6699001161951753, Test Accuracy: 62.20%\n",
      "Epoch 180, Loss: 0.5954947393642446, Test Loss: 0.6698716999262542, Test Accuracy: 62.20%\n",
      "Epoch 181, Loss: 0.5953482360334615, Test Loss: 0.6698433863332481, Test Accuracy: 62.20%\n",
      "Epoch 182, Loss: 0.5952019222984265, Test Loss: 0.6698151752443249, Test Accuracy: 62.20%\n",
      "Epoch 183, Loss: 0.5950557978547629, Test Loss: 0.6697870664866256, Test Accuracy: 62.20%\n",
      "Epoch 184, Loss: 0.5949098623985576, Test Loss: 0.6697590598863509, Test Accuracy: 62.20%\n",
      "Epoch 185, Loss: 0.5947641156263613, Test Loss: 0.6697311552688399, Test Accuracy: 62.20%\n",
      "Epoch 186, Loss: 0.5946185572351878, Test Loss: 0.669703352458645, Test Accuracy: 62.00%\n",
      "Epoch 187, Loss: 0.594473186922514, Test Loss: 0.669675651279601, Test Accuracy: 62.00%\n",
      "Epoch 188, Loss: 0.5943280043862801, Test Loss: 0.6696480515548906, Test Accuracy: 62.00%\n",
      "Epoch 189, Loss: 0.5941830093248881, Test Loss: 0.6696205531071051, Test Accuracy: 62.00%\n",
      "Epoch 190, Loss: 0.5940382014372029, Test Loss: 0.669593155758302, Test Accuracy: 62.00%\n",
      "Epoch 191, Loss: 0.5938935804225508, Test Loss: 0.6695658593300585, Test Accuracy: 62.00%\n",
      "Epoch 192, Loss: 0.5937491459807204, Test Loss: 0.6695386636435204, Test Accuracy: 62.00%\n",
      "Epoch 193, Loss: 0.5936048978119608, Test Loss: 0.6695115685194507, Test Accuracy: 62.00%\n",
      "Epoch 194, Loss: 0.5934608356169834, Test Loss: 0.669484573778272, Test Accuracy: 62.00%\n",
      "Epoch 195, Loss: 0.5933169590969591, Test Loss: 0.6694576792401087, Test Accuracy: 62.00%\n",
      "Epoch 196, Loss: 0.5931732679535207, Test Loss: 0.6694308847248245, Test Accuracy: 62.00%\n",
      "Epoch 197, Loss: 0.5930297618887601, Test Loss: 0.6694041900520592, Test Accuracy: 62.00%\n",
      "Epoch 198, Loss: 0.5928864406052298, Test Loss: 0.669377595041262, Test Accuracy: 62.00%\n",
      "Epoch 199, Loss: 0.5927433038059413, Test Loss: 0.6693510995117234, Test Accuracy: 62.00%\n",
      "Epoch 200, Loss: 0.5926003511943664, Test Loss: 0.6693247032826045, Test Accuracy: 62.00%\n",
      "Epoch 201, Loss: 0.5924575824744348, Test Loss: 0.6692984061729645, Test Accuracy: 62.00%\n",
      "Epoch 202, Loss: 0.5923149973505357, Test Loss: 0.6692722080017877, Test Accuracy: 62.20%\n",
      "Epoch 203, Loss: 0.5921725955275166, Test Loss: 0.6692461085880064, Test Accuracy: 61.80%\n",
      "Epoch 204, Loss: 0.5920303767106825, Test Loss: 0.6692201077505244, Test Accuracy: 61.80%\n",
      "Epoch 205, Loss: 0.5918883406057969, Test Loss: 0.6691942053082384, Test Accuracy: 61.80%\n",
      "Epoch 206, Loss: 0.5917464869190802, Test Loss: 0.6691684010800578, Test Accuracy: 61.80%\n",
      "Epoch 207, Loss: 0.5916048153572103, Test Loss: 0.6691426948849232, Test Accuracy: 61.80%\n",
      "Epoch 208, Loss: 0.5914633256273217, Test Loss: 0.6691170865418242, Test Accuracy: 61.80%\n",
      "Epoch 209, Loss: 0.5913220174370054, Test Loss: 0.6690915758698154, Test Accuracy: 61.80%\n",
      "Epoch 210, Loss: 0.5911808904943086, Test Loss: 0.6690661626880322, Test Accuracy: 61.80%\n",
      "Epoch 211, Loss: 0.591039944507734, Test Loss: 0.6690408468157052, Test Accuracy: 61.80%\n",
      "Epoch 212, Loss: 0.5908991791862405, Test Loss: 0.6690156280721725, Test Accuracy: 61.80%\n",
      "Epoch 213, Loss: 0.5907585942392412, Test Loss: 0.6689905062768944, Test Accuracy: 61.80%\n",
      "Epoch 214, Loss: 0.5906181893766049, Test Loss: 0.6689654812494634, Test Accuracy: 61.80%\n",
      "Epoch 215, Loss: 0.5904779643086542, Test Loss: 0.6689405528096155, Test Accuracy: 61.80%\n",
      "Epoch 216, Loss: 0.5903379187461661, Test Loss: 0.6689157207772414, Test Accuracy: 61.80%\n",
      "Epoch 217, Loss: 0.5901980524003716, Test Loss: 0.6688909849723956, Test Accuracy: 61.80%\n",
      "Epoch 218, Loss: 0.5900583649829546, Test Loss: 0.6688663452153051, Test Accuracy: 61.80%\n",
      "Epoch 219, Loss: 0.5899188562060522, Test Loss: 0.668841801326379, Test Accuracy: 61.80%\n",
      "Epoch 220, Loss: 0.589779525782255, Test Loss: 0.6688173531262147, Test Accuracy: 61.80%\n",
      "Epoch 221, Loss: 0.5896403734246048, Test Loss: 0.6687930004356072, Test Accuracy: 61.80%\n",
      "Epoch 222, Loss: 0.5895013988465964, Test Loss: 0.6687687430755546, Test Accuracy: 61.80%\n",
      "Epoch 223, Loss: 0.5893626017621754, Test Loss: 0.6687445808672653, Test Accuracy: 61.80%\n",
      "Epoch 224, Loss: 0.5892239818857395, Test Loss: 0.6687205136321641, Test Accuracy: 61.80%\n",
      "Epoch 225, Loss: 0.5890855389321371, Test Loss: 0.6686965411918973, Test Accuracy: 61.80%\n",
      "Epoch 226, Loss: 0.5889472726166668, Test Loss: 0.6686726633683385, Test Accuracy: 61.80%\n",
      "Epoch 227, Loss: 0.5888091826550779, Test Loss: 0.6686488799835935, Test Accuracy: 61.80%\n",
      "Epoch 228, Loss: 0.5886712687635693, Test Loss: 0.6686251908600049, Test Accuracy: 61.80%\n",
      "Epoch 229, Loss: 0.5885335306587895, Test Loss: 0.6686015958201559, Test Accuracy: 61.80%\n",
      "Epoch 230, Loss: 0.5883959680578361, Test Loss: 0.6685780946868753, Test Accuracy: 61.80%\n",
      "Epoch 231, Loss: 0.5882585806782553, Test Loss: 0.668554687283241, Test Accuracy: 61.80%\n",
      "Epoch 232, Loss: 0.5881213682380418, Test Loss: 0.6685313734325821, Test Accuracy: 61.80%\n",
      "Epoch 233, Loss: 0.5879843304556382, Test Loss: 0.6685081529584848, Test Accuracy: 61.80%\n",
      "Epoch 234, Loss: 0.587847467049935, Test Loss: 0.6684850256847927, Test Accuracy: 61.80%\n",
      "Epoch 235, Loss: 0.587710777740269, Test Loss: 0.6684619914356119, Test Accuracy: 61.80%\n",
      "Epoch 236, Loss: 0.5875742622464254, Test Loss: 0.6684390500353123, Test Accuracy: 61.80%\n",
      "Epoch 237, Loss: 0.5874379202886344, Test Loss: 0.6684162013085306, Test Accuracy: 61.80%\n",
      "Epoch 238, Loss: 0.587301751587573, Test Loss: 0.6683934450801722, Test Accuracy: 61.80%\n",
      "Epoch 239, Loss: 0.5871657558643638, Test Loss: 0.6683707811754136, Test Accuracy: 61.80%\n",
      "Epoch 240, Loss: 0.5870299328405747, Test Loss: 0.6683482094197046, Test Accuracy: 61.80%\n",
      "Epoch 241, Loss: 0.5868942822382183, Test Loss: 0.66832572963877, Test Accuracy: 61.80%\n",
      "Epoch 242, Loss: 0.5867588037797518, Test Loss: 0.6683033416586106, Test Accuracy: 61.80%\n",
      "Epoch 243, Loss: 0.5866234971880769, Test Loss: 0.6682810453055058, Test Accuracy: 61.80%\n",
      "Epoch 244, Loss: 0.5864883621865385, Test Loss: 0.6682588404060148, Test Accuracy: 61.80%\n",
      "Epoch 245, Loss: 0.586353398498925, Test Loss: 0.6682367267869774, Test Accuracy: 61.80%\n",
      "Epoch 246, Loss: 0.5862186058494677, Test Loss: 0.6682147042755157, Test Accuracy: 61.80%\n",
      "Epoch 247, Loss: 0.5860839839628408, Test Loss: 0.6681927726990355, Test Accuracy: 61.80%\n",
      "Epoch 248, Loss: 0.58594953256416, Test Loss: 0.6681709318852264, Test Accuracy: 62.00%\n",
      "Epoch 249, Loss: 0.5858152513789832, Test Loss: 0.668149181662064, Test Accuracy: 62.00%\n",
      "Epoch 250, Loss: 0.5856811401333093, Test Loss: 0.6681275218578101, Test Accuracy: 62.00%\n",
      "Epoch 251, Loss: 0.5855471985535782, Test Loss: 0.6681059523010131, Test Accuracy: 62.00%\n",
      "Epoch 252, Loss: 0.5854134263666705, Test Loss: 0.6680844728205096, Test Accuracy: 62.00%\n",
      "Epoch 253, Loss: 0.5852798232999066, Test Loss: 0.6680630832454252, Test Accuracy: 62.00%\n",
      "Epoch 254, Loss: 0.5851463890810468, Test Loss: 0.6680417834051731, Test Accuracy: 62.00%\n",
      "Epoch 255, Loss: 0.5850131234382903, Test Loss: 0.6680205731294582, Test Accuracy: 62.00%\n",
      "Epoch 256, Loss: 0.5848800261002755, Test Loss: 0.6679994522482737, Test Accuracy: 62.00%\n",
      "Epoch 257, Loss: 0.5847470967960791, Test Loss: 0.6679784205919047, Test Accuracy: 62.00%\n",
      "Epoch 258, Loss: 0.5846143352552157, Test Loss: 0.6679574779909264, Test Accuracy: 62.00%\n",
      "Epoch 259, Loss: 0.5844817412076377, Test Loss: 0.6679366242762061, Test Accuracy: 62.00%\n",
      "Epoch 260, Loss: 0.5843493143837347, Test Loss: 0.6679158592789022, Test Accuracy: 62.00%\n",
      "Epoch 261, Loss: 0.5842170545143325, Test Loss: 0.6678951828304653, Test Accuracy: 62.00%\n",
      "Epoch 262, Loss: 0.5840849613306939, Test Loss: 0.6678745947626381, Test Accuracy: 62.00%\n",
      "Epoch 263, Loss: 0.5839530345645171, Test Loss: 0.6678540949074555, Test Accuracy: 62.00%\n",
      "Epoch 264, Loss: 0.583821273947936, Test Loss: 0.6678336830972448, Test Accuracy: 62.00%\n",
      "Epoch 265, Loss: 0.5836896792135193, Test Loss: 0.6678133591646265, Test Accuracy: 62.00%\n",
      "Epoch 266, Loss: 0.583558250094271, Test Loss: 0.6677931229425126, Test Accuracy: 62.00%\n",
      "Epoch 267, Loss: 0.5834269863236281, Test Loss: 0.6677729742641091, Test Accuracy: 62.00%\n",
      "Epoch 268, Loss: 0.5832958876354624, Test Loss: 0.6677529129629141, Test Accuracy: 62.00%\n",
      "Epoch 269, Loss: 0.5831649537640783, Test Loss: 0.667732938872719, Test Accuracy: 62.00%\n",
      "Epoch 270, Loss: 0.5830341844442135, Test Loss: 0.6677130518276073, Test Accuracy: 62.00%\n",
      "Epoch 271, Loss: 0.5829035794110381, Test Loss: 0.6676932516619561, Test Accuracy: 62.00%\n",
      "Epoch 272, Loss: 0.5827731384001538, Test Loss: 0.6676735382104344, Test Accuracy: 62.00%\n",
      "Epoch 273, Loss: 0.5826428611475942, Test Loss: 0.6676539113080042, Test Accuracy: 62.00%\n",
      "Epoch 274, Loss: 0.5825127473898238, Test Loss: 0.6676343707899207, Test Accuracy: 62.00%\n",
      "Epoch 275, Loss: 0.5823827968637383, Test Loss: 0.6676149164917302, Test Accuracy: 62.00%\n",
      "Epoch 276, Loss: 0.5822530093066627, Test Loss: 0.6675955482492724, Test Accuracy: 61.80%\n",
      "Epoch 277, Loss: 0.5821233844563526, Test Loss: 0.6675762658986787, Test Accuracy: 61.80%\n",
      "Epoch 278, Loss: 0.5819939220509927, Test Loss: 0.6675570692763726, Test Accuracy: 61.80%\n",
      "Epoch 279, Loss: 0.5818646218291958, Test Loss: 0.6675379582190698, Test Accuracy: 61.80%\n",
      "Epoch 280, Loss: 0.5817354835300047, Test Loss: 0.667518932563777, Test Accuracy: 61.80%\n",
      "Epoch 281, Loss: 0.581606506892889, Test Loss: 0.667499992147793, Test Accuracy: 61.80%\n",
      "Epoch 282, Loss: 0.5814776916577457, Test Loss: 0.6674811368087075, Test Accuracy: 61.80%\n",
      "Epoch 283, Loss: 0.5813490375649, Test Loss: 0.6674623663844013, Test Accuracy: 61.80%\n",
      "Epoch 284, Loss: 0.5812205443551027, Test Loss: 0.6674436807130463, Test Accuracy: 61.80%\n",
      "Epoch 285, Loss: 0.5810922117695312, Test Loss: 0.6674250796331049, Test Accuracy: 61.80%\n",
      "Epoch 286, Loss: 0.5809640395497886, Test Loss: 0.6674065629833295, Test Accuracy: 61.80%\n",
      "Epoch 287, Loss: 0.580836027437903, Test Loss: 0.6673881306027631, Test Accuracy: 61.80%\n",
      "Epoch 288, Loss: 0.5807081751763277, Test Loss: 0.6673697823307383, Test Accuracy: 61.80%\n",
      "Epoch 289, Loss: 0.5805804825079399, Test Loss: 0.6673515180068774, Test Accuracy: 61.80%\n",
      "Epoch 290, Loss: 0.5804529491760412, Test Loss: 0.6673333374710918, Test Accuracy: 61.80%\n",
      "Epoch 291, Loss: 0.5803255749243561, Test Loss: 0.6673152405635822, Test Accuracy: 61.80%\n",
      "Epoch 292, Loss: 0.5801983594970325, Test Loss: 0.6672972271248375, Test Accuracy: 61.80%\n",
      "Epoch 293, Loss: 0.5800713026386404, Test Loss: 0.6672792969956359, Test Accuracy: 61.80%\n",
      "Epoch 294, Loss: 0.5799444040941721, Test Loss: 0.6672614500170432, Test Accuracy: 61.80%\n",
      "Epoch 295, Loss: 0.5798176636090413, Test Loss: 0.6672436860304127, Test Accuracy: 61.80%\n",
      "Epoch 296, Loss: 0.579691080929083, Test Loss: 0.667226004877386, Test Accuracy: 61.80%\n",
      "Epoch 297, Loss: 0.5795646558005524, Test Loss: 0.6672084063998917, Test Accuracy: 61.80%\n",
      "Epoch 298, Loss: 0.5794383879701256, Test Loss: 0.6671908904401446, Test Accuracy: 61.80%\n",
      "Epoch 299, Loss: 0.5793122771848975, Test Loss: 0.6671734568406469, Test Accuracy: 61.80%\n",
      "Epoch 300, Loss: 0.5791863231923831, Test Loss: 0.6671561054441868, Test Accuracy: 61.80%\n",
      "Epoch 301, Loss: 0.5790605257405151, Test Loss: 0.6671388360938386, Test Accuracy: 61.80%\n",
      "Epoch 302, Loss: 0.5789348845776455, Test Loss: 0.6671216486329615, Test Accuracy: 61.80%\n",
      "Epoch 303, Loss: 0.5788093994525436, Test Loss: 0.6671045429052006, Test Accuracy: 61.80%\n",
      "Epoch 304, Loss: 0.5786840701143959, Test Loss: 0.6670875187544858, Test Accuracy: 61.60%\n",
      "Epoch 305, Loss: 0.5785588963128061, Test Loss: 0.6670705760250314, Test Accuracy: 61.80%\n",
      "Epoch 306, Loss: 0.5784338777977939, Test Loss: 0.6670537145613357, Test Accuracy: 61.80%\n",
      "Epoch 307, Loss: 0.5783090143197951, Test Loss: 0.6670369342081816, Test Accuracy: 61.80%\n",
      "Epoch 308, Loss: 0.578184305629661, Test Loss: 0.6670202348106347, Test Accuracy: 61.80%\n",
      "Epoch 309, Loss: 0.5780597514786576, Test Loss: 0.6670036162140442, Test Accuracy: 61.80%\n",
      "Epoch 310, Loss: 0.5779353516184658, Test Loss: 0.6669870782640421, Test Accuracy: 61.80%\n",
      "Epoch 311, Loss: 0.5778111058011797, Test Loss: 0.6669706208065427, Test Accuracy: 61.80%\n",
      "Epoch 312, Loss: 0.5776870137793074, Test Loss: 0.6669542436877423, Test Accuracy: 61.80%\n",
      "Epoch 313, Loss: 0.57756307530577, Test Loss: 0.6669379467541191, Test Accuracy: 61.80%\n",
      "Epoch 314, Loss: 0.577439290133901, Test Loss: 0.6669217298524326, Test Accuracy: 61.80%\n",
      "Epoch 315, Loss: 0.577315658017446, Test Loss: 0.6669055928297232, Test Accuracy: 61.80%\n",
      "Epoch 316, Loss: 0.5771921787105622, Test Loss: 0.6668895355333123, Test Accuracy: 61.80%\n",
      "Epoch 317, Loss: 0.5770688519678177, Test Loss: 0.6668735578108009, Test Accuracy: 61.80%\n",
      "Epoch 318, Loss: 0.576945677544191, Test Loss: 0.6668576595100704, Test Accuracy: 61.80%\n",
      "Epoch 319, Loss: 0.5768226551950711, Test Loss: 0.6668418404792813, Test Accuracy: 61.80%\n",
      "Epoch 320, Loss: 0.5766997846762566, Test Loss: 0.6668261005668737, Test Accuracy: 61.80%\n",
      "Epoch 321, Loss: 0.576577065743955, Test Loss: 0.666810439621566, Test Accuracy: 61.80%\n",
      "Epoch 322, Loss: 0.5764544981547821, Test Loss: 0.6667948574923557, Test Accuracy: 61.80%\n",
      "Epoch 323, Loss: 0.5763320816657624, Test Loss: 0.6667793540285173, Test Accuracy: 61.80%\n",
      "Epoch 324, Loss: 0.5762098160343277, Test Loss: 0.6667639290796034, Test Accuracy: 61.80%\n",
      "Epoch 325, Loss: 0.5760877010183174, Test Loss: 0.6667485824954439, Test Accuracy: 61.80%\n",
      "Epoch 326, Loss: 0.5759657363759765, Test Loss: 0.6667333141261457, Test Accuracy: 61.80%\n",
      "Epoch 327, Loss: 0.5758439218659575, Test Loss: 0.6667181238220917, Test Accuracy: 61.80%\n",
      "Epoch 328, Loss: 0.5757222572473173, Test Loss: 0.6667030114339416, Test Accuracy: 61.80%\n",
      "Epoch 329, Loss: 0.5756007422795187, Test Loss: 0.66668797681263, Test Accuracy: 61.80%\n",
      "Epoch 330, Loss: 0.575479376722429, Test Loss: 0.6666730198093679, Test Accuracy: 61.80%\n",
      "Epoch 331, Loss: 0.5753581603363199, Test Loss: 0.6666581402756396, Test Accuracy: 61.80%\n",
      "Epoch 332, Loss: 0.575237092881866, Test Loss: 0.6666433380632059, Test Accuracy: 61.60%\n",
      "Epoch 333, Loss: 0.575116174120146, Test Loss: 0.6666286130241001, Test Accuracy: 61.60%\n",
      "Epoch 334, Loss: 0.5749954038126405, Test Loss: 0.6666139650106305, Test Accuracy: 61.60%\n",
      "Epoch 335, Loss: 0.574874781721233, Test Loss: 0.666599393875378, Test Accuracy: 61.60%\n",
      "Epoch 336, Loss: 0.5747543076082077, Test Loss: 0.6665848994711971, Test Accuracy: 61.60%\n",
      "Epoch 337, Loss: 0.574633981236251, Test Loss: 0.6665704816512144, Test Accuracy: 61.60%\n",
      "Epoch 338, Loss: 0.5745138023684493, Test Loss: 0.6665561402688289, Test Accuracy: 61.60%\n",
      "Epoch 339, Loss: 0.5743937707682892, Test Loss: 0.6665418751777119, Test Accuracy: 61.60%\n",
      "Epoch 340, Loss: 0.5742738861996574, Test Loss: 0.6665276862318052, Test Accuracy: 61.60%\n",
      "Epoch 341, Loss: 0.5741541484268391, Test Loss: 0.6665135732853227, Test Accuracy: 61.60%\n",
      "Epoch 342, Loss: 0.5740345572145188, Test Loss: 0.6664995361927484, Test Accuracy: 61.60%\n",
      "Epoch 343, Loss: 0.5739151123277788, Test Loss: 0.6664855748088365, Test Accuracy: 61.60%\n",
      "Epoch 344, Loss: 0.5737958135320987, Test Loss: 0.6664716889886113, Test Accuracy: 61.60%\n",
      "Epoch 345, Loss: 0.5736766605933561, Test Loss: 0.6664578785873667, Test Accuracy: 61.60%\n",
      "Epoch 346, Loss: 0.573557653277824, Test Loss: 0.6664441434606654, Test Accuracy: 61.60%\n",
      "Epoch 347, Loss: 0.5734387913521729, Test Loss: 0.6664304834643391, Test Accuracy: 61.60%\n",
      "Epoch 348, Loss: 0.5733200745834679, Test Loss: 0.6664168984544873, Test Accuracy: 61.60%\n",
      "Epoch 349, Loss: 0.5732015027391696, Test Loss: 0.666403388287478, Test Accuracy: 61.60%\n",
      "Epoch 350, Loss: 0.573083075587133, Test Loss: 0.6663899528199466, Test Accuracy: 61.60%\n",
      "Epoch 351, Loss: 0.5729647928956074, Test Loss: 0.6663765919087954, Test Accuracy: 61.60%\n",
      "Epoch 352, Loss: 0.5728466544332355, Test Loss: 0.6663633054111936, Test Accuracy: 61.60%\n",
      "Epoch 353, Loss: 0.5727286599690531, Test Loss: 0.6663500931845767, Test Accuracy: 61.60%\n",
      "Epoch 354, Loss: 0.5726108092724884, Test Loss: 0.666336955086646, Test Accuracy: 61.60%\n",
      "Epoch 355, Loss: 0.5724931021133622, Test Loss: 0.6663238909753687, Test Accuracy: 61.60%\n",
      "Epoch 356, Loss: 0.5723755382618858, Test Loss: 0.6663109007089769, Test Accuracy: 61.60%\n",
      "Epoch 357, Loss: 0.5722581174886627, Test Loss: 0.6662979841459672, Test Accuracy: 61.60%\n",
      "Epoch 358, Loss: 0.572140839564686, Test Loss: 0.6662851411451014, Test Accuracy: 61.60%\n",
      "Epoch 359, Loss: 0.572023704261339, Test Loss: 0.6662723715654042, Test Accuracy: 61.60%\n",
      "Epoch 360, Loss: 0.5719067113503947, Test Loss: 0.6662596752661644, Test Accuracy: 61.60%\n",
      "Epoch 361, Loss: 0.5717898606040148, Test Loss: 0.6662470521069342, Test Accuracy: 61.60%\n",
      "Epoch 362, Loss: 0.5716731517947498, Test Loss: 0.6662345019475284, Test Accuracy: 61.60%\n",
      "Epoch 363, Loss: 0.5715565846955376, Test Loss: 0.6662220246480237, Test Accuracy: 61.60%\n",
      "Epoch 364, Loss: 0.5714401590797038, Test Loss: 0.6662096200687594, Test Accuracy: 61.60%\n",
      "Epoch 365, Loss: 0.5713238747209609, Test Loss: 0.6661972880703361, Test Accuracy: 61.60%\n",
      "Epoch 366, Loss: 0.5712077313934079, Test Loss: 0.6661850285136156, Test Accuracy: 61.60%\n",
      "Epoch 367, Loss: 0.5710917288715294, Test Loss: 0.6661728412597205, Test Accuracy: 61.60%\n",
      "Epoch 368, Loss: 0.5709758669301951, Test Loss: 0.6661607261700336, Test Accuracy: 61.60%\n",
      "Epoch 369, Loss: 0.5708601453446602, Test Loss: 0.6661486831061981, Test Accuracy: 61.60%\n",
      "Epoch 370, Loss: 0.5707445638905639, Test Loss: 0.6661367119301166, Test Accuracy: 61.60%\n",
      "Epoch 371, Loss: 0.570629122343929, Test Loss: 0.6661248125039506, Test Accuracy: 61.60%\n",
      "Epoch 372, Loss: 0.5705138204811618, Test Loss: 0.666112984690121, Test Accuracy: 61.60%\n",
      "Epoch 373, Loss: 0.5703986580790512, Test Loss: 0.6661012283513065, Test Accuracy: 61.60%\n",
      "Epoch 374, Loss: 0.5702836349147684, Test Loss: 0.6660895433504441, Test Accuracy: 61.60%\n",
      "Epoch 375, Loss: 0.5701687507658664, Test Loss: 0.6660779295507282, Test Accuracy: 61.60%\n",
      "Epoch 376, Loss: 0.570054005410279, Test Loss: 0.6660663868156106, Test Accuracy: 61.60%\n",
      "Epoch 377, Loss: 0.5699393986263213, Test Loss: 0.6660549150087999, Test Accuracy: 61.60%\n",
      "Epoch 378, Loss: 0.5698249301926879, Test Loss: 0.6660435139942609, Test Accuracy: 61.60%\n",
      "Epoch 379, Loss: 0.5697105998884534, Test Loss: 0.6660321836362146, Test Accuracy: 61.60%\n",
      "Epoch 380, Loss: 0.5695964074930716, Test Loss: 0.6660209237991376, Test Accuracy: 61.60%\n",
      "Epoch 381, Loss: 0.5694823527863745, Test Loss: 0.6660097343477613, Test Accuracy: 61.60%\n",
      "Epoch 382, Loss: 0.5693684355485724, Test Loss: 0.6659986151470727, Test Accuracy: 61.60%\n",
      "Epoch 383, Loss: 0.5692546555602533, Test Loss: 0.6659875660623125, Test Accuracy: 61.60%\n",
      "Epoch 384, Loss: 0.5691410126023818, Test Loss: 0.6659765869589755, Test Accuracy: 61.60%\n",
      "Epoch 385, Loss: 0.5690275064562992, Test Loss: 0.6659656777028109, Test Accuracy: 61.60%\n",
      "Epoch 386, Loss: 0.568914136903723, Test Loss: 0.6659548381598197, Test Accuracy: 61.60%\n",
      "Epoch 387, Loss: 0.5688009037267456, Test Loss: 0.665944068196257, Test Accuracy: 61.60%\n",
      "Epoch 388, Loss: 0.568687806707835, Test Loss: 0.6659333676786295, Test Accuracy: 61.60%\n",
      "Epoch 389, Loss: 0.5685748456298332, Test Loss: 0.6659227364736965, Test Accuracy: 61.60%\n",
      "Epoch 390, Loss: 0.5684620202759559, Test Loss: 0.6659121744484684, Test Accuracy: 61.60%\n",
      "Epoch 391, Loss: 0.5683493304297925, Test Loss: 0.6659016814702071, Test Accuracy: 61.60%\n",
      "Epoch 392, Loss: 0.568236775875305, Test Loss: 0.6658912574064253, Test Accuracy: 61.80%\n",
      "Epoch 393, Loss: 0.568124356396828, Test Loss: 0.6658809021248862, Test Accuracy: 61.80%\n",
      "Epoch 394, Loss: 0.5680120717790675, Test Loss: 0.6658706154936027, Test Accuracy: 61.80%\n",
      "Epoch 395, Loss: 0.5678999218071012, Test Loss: 0.6658603973808378, Test Accuracy: 61.80%\n",
      "Epoch 396, Loss: 0.567787906266377, Test Loss: 0.6658502476551034, Test Accuracy: 61.80%\n",
      "Epoch 397, Loss: 0.5676760249427131, Test Loss: 0.6658401661851602, Test Accuracy: 61.80%\n",
      "Epoch 398, Loss: 0.5675642776222979, Test Loss: 0.6658301528400172, Test Accuracy: 61.80%\n",
      "Epoch 399, Loss: 0.5674526640916886, Test Loss: 0.6658202074889323, Test Accuracy: 61.80%\n",
      "Epoch 400, Loss: 0.5673411841378107, Test Loss: 0.6658103300014098, Test Accuracy: 61.80%\n",
      "Epoch 401, Loss: 0.5672298375479582, Test Loss: 0.6658005202472019, Test Accuracy: 61.80%\n",
      "Epoch 402, Loss: 0.5671186241097925, Test Loss: 0.6657907780963077, Test Accuracy: 61.80%\n",
      "Epoch 403, Loss: 0.5670075436113425, Test Loss: 0.6657811034189725, Test Accuracy: 61.80%\n",
      "Epoch 404, Loss: 0.5668965958410029, Test Loss: 0.6657714960856881, Test Accuracy: 61.80%\n",
      "Epoch 405, Loss: 0.5667857805875348, Test Loss: 0.665761955967191, Test Accuracy: 61.80%\n",
      "Epoch 406, Loss: 0.5666750976400649, Test Loss: 0.6657524829344638, Test Accuracy: 61.80%\n",
      "Epoch 407, Loss: 0.5665645467880841, Test Loss: 0.6657430768587337, Test Accuracy: 61.80%\n",
      "Epoch 408, Loss: 0.5664541278214487, Test Loss: 0.6657337376114724, Test Accuracy: 61.80%\n",
      "Epoch 409, Loss: 0.5663438405303782, Test Loss: 0.6657244650643953, Test Accuracy: 61.80%\n",
      "Epoch 410, Loss: 0.5662336847054561, Test Loss: 0.665715259089462, Test Accuracy: 61.80%\n",
      "Epoch 411, Loss: 0.5661236601376278, Test Loss: 0.665706119558875, Test Accuracy: 61.80%\n",
      "Epoch 412, Loss: 0.5660137666182018, Test Loss: 0.6656970463450798, Test Accuracy: 61.80%\n",
      "Epoch 413, Loss: 0.5659040039388479, Test Loss: 0.6656880393207643, Test Accuracy: 61.80%\n",
      "Epoch 414, Loss: 0.5657943718915974, Test Loss: 0.6656790983588583, Test Accuracy: 61.80%\n",
      "Epoch 415, Loss: 0.5656848702688426, Test Loss: 0.6656702233325338, Test Accuracy: 61.80%\n",
      "Epoch 416, Loss: 0.5655754988633351, Test Loss: 0.6656614141152034, Test Accuracy: 61.80%\n",
      "Epoch 417, Loss: 0.5654662574681871, Test Loss: 0.6656526705805212, Test Accuracy: 61.80%\n",
      "Epoch 418, Loss: 0.5653571458768695, Test Loss: 0.6656439926023816, Test Accuracy: 61.80%\n",
      "Epoch 419, Loss: 0.5652481638832118, Test Loss: 0.6656353800549186, Test Accuracy: 61.80%\n",
      "Epoch 420, Loss: 0.5651393112814016, Test Loss: 0.6656268328125067, Test Accuracy: 61.80%\n",
      "Epoch 421, Loss: 0.565030587865984, Test Loss: 0.6656183507497588, Test Accuracy: 61.80%\n",
      "Epoch 422, Loss: 0.5649219934318614, Test Loss: 0.6656099337415275, Test Accuracy: 61.80%\n",
      "Epoch 423, Loss: 0.5648135277742926, Test Loss: 0.6656015816629037, Test Accuracy: 61.80%\n",
      "Epoch 424, Loss: 0.5647051906888921, Test Loss: 0.6655932943892161, Test Accuracy: 61.80%\n",
      "Epoch 425, Loss: 0.5645969819716302, Test Loss: 0.6655850717960315, Test Accuracy: 61.80%\n",
      "Epoch 426, Loss: 0.5644889014188318, Test Loss: 0.6655769137591535, Test Accuracy: 61.80%\n",
      "Epoch 427, Loss: 0.5643809488271764, Test Loss: 0.6655688201546233, Test Accuracy: 61.80%\n",
      "Epoch 428, Loss: 0.5642731239936972, Test Loss: 0.6655607908587181, Test Accuracy: 61.80%\n",
      "Epoch 429, Loss: 0.5641654267157808, Test Loss: 0.6655528257479516, Test Accuracy: 61.80%\n",
      "Epoch 430, Loss: 0.5640578567911669, Test Loss: 0.6655449246990729, Test Accuracy: 61.80%\n",
      "Epoch 431, Loss: 0.563950414017947, Test Loss: 0.6655370875890668, Test Accuracy: 61.80%\n",
      "Epoch 432, Loss: 0.5638430981945644, Test Loss: 0.6655293142951528, Test Accuracy: 61.80%\n",
      "Epoch 433, Loss: 0.5637359091198139, Test Loss: 0.6655216046947853, Test Accuracy: 61.80%\n",
      "Epoch 434, Loss: 0.563628846592841, Test Loss: 0.6655139586656521, Test Accuracy: 61.80%\n",
      "Epoch 435, Loss: 0.5635219104131408, Test Loss: 0.6655063760856755, Test Accuracy: 61.80%\n",
      "Epoch 436, Loss: 0.563415100380559, Test Loss: 0.6654988568330115, Test Accuracy: 61.80%\n",
      "Epoch 437, Loss: 0.5633084162952893, Test Loss: 0.6654914007860478, Test Accuracy: 61.80%\n",
      "Epoch 438, Loss: 0.563201857957875, Test Loss: 0.665484007823406, Test Accuracy: 62.00%\n",
      "Epoch 439, Loss: 0.5630954251692066, Test Loss: 0.665476677823939, Test Accuracy: 62.00%\n",
      "Epoch 440, Loss: 0.562989117730523, Test Loss: 0.6654694106667323, Test Accuracy: 62.00%\n",
      "Epoch 441, Loss: 0.5628829354434092, Test Loss: 0.665462206231102, Test Accuracy: 62.00%\n",
      "Epoch 442, Loss: 0.562776878109797, Test Loss: 0.6654550643965959, Test Accuracy: 62.00%\n",
      "Epoch 443, Loss: 0.5626709455319646, Test Loss: 0.6654479850429923, Test Accuracy: 62.00%\n",
      "Epoch 444, Loss: 0.5625651375125351, Test Loss: 0.6654409680502994, Test Accuracy: 62.00%\n",
      "Epoch 445, Loss: 0.5624594538544767, Test Loss: 0.6654340132987555, Test Accuracy: 62.20%\n",
      "Epoch 446, Loss: 0.5623538943611016, Test Loss: 0.6654271206688285, Test Accuracy: 62.20%\n",
      "Epoch 447, Loss: 0.5622484588360664, Test Loss: 0.6654202900412152, Test Accuracy: 62.20%\n",
      "Epoch 448, Loss: 0.5621431470833709, Test Loss: 0.665413521296841, Test Accuracy: 62.20%\n",
      "Epoch 449, Loss: 0.562037958907357, Test Loss: 0.6654068143168599, Test Accuracy: 62.20%\n",
      "Epoch 450, Loss: 0.56193289411271, Test Loss: 0.6654001689826534, Test Accuracy: 62.20%\n",
      "Epoch 451, Loss: 0.5618279525044557, Test Loss: 0.665393585175831, Test Accuracy: 62.20%\n",
      "Epoch 452, Loss: 0.5617231338879624, Test Loss: 0.665387062778229, Test Accuracy: 62.20%\n",
      "Epoch 453, Loss: 0.5616184380689376, Test Loss: 0.6653806016719104, Test Accuracy: 62.20%\n",
      "Epoch 454, Loss: 0.5615138648534302, Test Loss: 0.6653742017391646, Test Accuracy: 62.20%\n",
      "Epoch 455, Loss: 0.5614094140478282, Test Loss: 0.6653678628625075, Test Accuracy: 62.20%\n",
      "Epoch 456, Loss: 0.5613050854588589, Test Loss: 0.6653615849246796, Test Accuracy: 62.20%\n",
      "Epoch 457, Loss: 0.5612008788935879, Test Loss: 0.6653553678086475, Test Accuracy: 62.20%\n",
      "Epoch 458, Loss: 0.561096794159419, Test Loss: 0.6653492113976015, Test Accuracy: 62.20%\n",
      "Epoch 459, Loss: 0.5609928310640936, Test Loss: 0.6653431155749578, Test Accuracy: 62.20%\n",
      "Epoch 460, Loss: 0.56088898941569, Test Loss: 0.6653370802243554, Test Accuracy: 62.20%\n",
      "Epoch 461, Loss: 0.5607852690226226, Test Loss: 0.6653311052296575, Test Accuracy: 62.20%\n",
      "Epoch 462, Loss: 0.5606816696936426, Test Loss: 0.6653251904749502, Test Accuracy: 62.20%\n",
      "Epoch 463, Loss: 0.5605781912378363, Test Loss: 0.6653193358445432, Test Accuracy: 62.20%\n",
      "Epoch 464, Loss: 0.5604748334646242, Test Loss: 0.6653135412229675, Test Accuracy: 62.40%\n",
      "Epoch 465, Loss: 0.5603715961837622, Test Loss: 0.6653078064949772, Test Accuracy: 62.40%\n",
      "Epoch 466, Loss: 0.5602684792053395, Test Loss: 0.6653021315455478, Test Accuracy: 62.40%\n",
      "Epoch 467, Loss: 0.5601654823397786, Test Loss: 0.665296516259876, Test Accuracy: 62.40%\n",
      "Epoch 468, Loss: 0.560062605397835, Test Loss: 0.6652909605233794, Test Accuracy: 62.40%\n",
      "Epoch 469, Loss: 0.5599598481905963, Test Loss: 0.6652854642216964, Test Accuracy: 62.20%\n",
      "Epoch 470, Loss: 0.5598572105294822, Test Loss: 0.6652800272406858, Test Accuracy: 62.20%\n",
      "Epoch 471, Loss: 0.5597546922262434, Test Loss: 0.6652746494664251, Test Accuracy: 62.20%\n",
      "Epoch 472, Loss: 0.559652293092961, Test Loss: 0.6652693307852124, Test Accuracy: 62.20%\n",
      "Epoch 473, Loss: 0.5595500129420471, Test Loss: 0.6652640710835644, Test Accuracy: 62.20%\n",
      "Epoch 474, Loss: 0.5594478515862426, Test Loss: 0.6652588702482163, Test Accuracy: 62.20%\n",
      "Epoch 475, Loss: 0.5593458088386181, Test Loss: 0.6652537281661215, Test Accuracy: 62.20%\n",
      "Epoch 476, Loss: 0.5592438845125726, Test Loss: 0.6652486447244516, Test Accuracy: 62.20%\n",
      "Epoch 477, Loss: 0.559142078421833, Test Loss: 0.6652436198105954, Test Accuracy: 62.20%\n",
      "Epoch 478, Loss: 0.5590403903804547, Test Loss: 0.665238653312159, Test Accuracy: 62.20%\n",
      "Epoch 479, Loss: 0.5589388202028189, Test Loss: 0.6652337451169651, Test Accuracy: 62.20%\n",
      "Epoch 480, Loss: 0.5588373677036341, Test Loss: 0.6652288951130525, Test Accuracy: 62.20%\n",
      "Epoch 481, Loss: 0.5587360326979348, Test Loss: 0.6652241031886768, Test Accuracy: 62.20%\n",
      "Epoch 482, Loss: 0.558634815001081, Test Loss: 0.6652193692323084, Test Accuracy: 62.20%\n",
      "Epoch 483, Loss: 0.5585337144287571, Test Loss: 0.6652146931326329, Test Accuracy: 62.20%\n",
      "Epoch 484, Loss: 0.5584327307969726, Test Loss: 0.6652100747785513, Test Accuracy: 62.20%\n",
      "Epoch 485, Loss: 0.558331863922061, Test Loss: 0.6652055140591785, Test Accuracy: 62.20%\n",
      "Epoch 486, Loss: 0.5582311136206787, Test Loss: 0.6652010108638436, Test Accuracy: 62.20%\n",
      "Epoch 487, Loss: 0.5581304797098052, Test Loss: 0.6651965650820899, Test Accuracy: 62.20%\n",
      "Epoch 488, Loss: 0.5580299620067427, Test Loss: 0.665192176603673, Test Accuracy: 62.20%\n",
      "Epoch 489, Loss: 0.5579295603291148, Test Loss: 0.6651878453185623, Test Accuracy: 62.20%\n",
      "Epoch 490, Loss: 0.557829274494867, Test Loss: 0.6651835711169395, Test Accuracy: 62.20%\n",
      "Epoch 491, Loss: 0.5577291043222649, Test Loss: 0.6651793538891982, Test Accuracy: 62.20%\n",
      "Epoch 492, Loss: 0.5576290496298949, Test Loss: 0.6651751935259441, Test Accuracy: 62.20%\n",
      "Epoch 493, Loss: 0.5575291102366633, Test Loss: 0.6651710899179946, Test Accuracy: 62.20%\n",
      "Epoch 494, Loss: 0.5574292859617954, Test Loss: 0.665167042956377, Test Accuracy: 62.20%\n",
      "Epoch 495, Loss: 0.5573295766248351, Test Loss: 0.6651630525323305, Test Accuracy: 62.20%\n",
      "Epoch 496, Loss: 0.5572299820456451, Test Loss: 0.6651591185373046, Test Accuracy: 62.20%\n",
      "Epoch 497, Loss: 0.5571305020444056, Test Loss: 0.6651552408629576, Test Accuracy: 62.20%\n",
      "Epoch 498, Loss: 0.5570311364416136, Test Loss: 0.6651514194011583, Test Accuracy: 62.20%\n",
      "Epoch 499, Loss: 0.5569318850580833, Test Loss: 0.6651476540439841, Test Accuracy: 62.00%\n",
      "Epoch 500, Loss: 0.5568327477149448, Test Loss: 0.6651439446837221, Test Accuracy: 62.00%\n",
      "Epoch 501, Loss: 0.5567337242336443, Test Loss: 0.6651402912128664, Test Accuracy: 62.00%\n",
      "Epoch 502, Loss: 0.5566348144359425, Test Loss: 0.6651366935241204, Test Accuracy: 62.20%\n",
      "Epoch 503, Loss: 0.5565360181439151, Test Loss: 0.6651331515103949, Test Accuracy: 62.20%\n",
      "Epoch 504, Loss: 0.5564373351799521, Test Loss: 0.6651296650648074, Test Accuracy: 62.20%\n",
      "Epoch 505, Loss: 0.5563387653667567, Test Loss: 0.6651262340806829, Test Accuracy: 62.20%\n",
      "Epoch 506, Loss: 0.5562403085273456, Test Loss: 0.6651228584515526, Test Accuracy: 62.40%\n",
      "Epoch 507, Loss: 0.5561419644850477, Test Loss: 0.6651195380711545, Test Accuracy: 62.40%\n",
      "Epoch 508, Loss: 0.5560437330635046, Test Loss: 0.6651162728334318, Test Accuracy: 62.40%\n",
      "Epoch 509, Loss: 0.5559456140866685, Test Loss: 0.6651130626325331, Test Accuracy: 62.40%\n",
      "Epoch 510, Loss: 0.5558476073788035, Test Loss: 0.6651099073628126, Test Accuracy: 62.40%\n",
      "Epoch 511, Loss: 0.5557497127644839, Test Loss: 0.6651068069188288, Test Accuracy: 62.40%\n",
      "Epoch 512, Loss: 0.5556519300685939, Test Loss: 0.665103761195345, Test Accuracy: 62.40%\n",
      "Epoch 513, Loss: 0.5555542591163276, Test Loss: 0.6651007700873275, Test Accuracy: 62.40%\n",
      "Epoch 514, Loss: 0.5554566997331879, Test Loss: 0.6650978334899471, Test Accuracy: 62.40%\n",
      "Epoch 515, Loss: 0.555359251744986, Test Loss: 0.6650949512985775, Test Accuracy: 62.40%\n",
      "Epoch 516, Loss: 0.5552619149778414, Test Loss: 0.6650921234087954, Test Accuracy: 62.40%\n",
      "Epoch 517, Loss: 0.5551646892581807, Test Loss: 0.6650893497163798, Test Accuracy: 62.40%\n",
      "Epoch 518, Loss: 0.5550675744127382, Test Loss: 0.6650866301173116, Test Accuracy: 62.40%\n",
      "Epoch 519, Loss: 0.5549705702685538, Test Loss: 0.6650839645077742, Test Accuracy: 62.40%\n",
      "Epoch 520, Loss: 0.554873676652974, Test Loss: 0.6650813527841518, Test Accuracy: 62.40%\n",
      "Epoch 521, Loss: 0.5547768933936504, Test Loss: 0.6650787948430296, Test Accuracy: 62.40%\n",
      "Epoch 522, Loss: 0.5546802203185396, Test Loss: 0.6650762905811937, Test Accuracy: 62.40%\n",
      "Epoch 523, Loss: 0.5545836572559026, Test Loss: 0.6650738398956304, Test Accuracy: 62.40%\n",
      "Epoch 524, Loss: 0.5544872040343046, Test Loss: 0.665071442683526, Test Accuracy: 62.40%\n",
      "Epoch 525, Loss: 0.5543908604826138, Test Loss: 0.6650690988422663, Test Accuracy: 62.40%\n",
      "Epoch 526, Loss: 0.5542946264300016, Test Loss: 0.6650668082694362, Test Accuracy: 62.40%\n",
      "Epoch 527, Loss: 0.5541985017059419, Test Loss: 0.6650645708628194, Test Accuracy: 62.40%\n",
      "Epoch 528, Loss: 0.5541024861402101, Test Loss: 0.6650623865203983, Test Accuracy: 62.40%\n",
      "Epoch 529, Loss: 0.5540065795628835, Test Loss: 0.6650602551403536, Test Accuracy: 62.40%\n",
      "Epoch 530, Loss: 0.5539107818043398, Test Loss: 0.6650581766210629, Test Accuracy: 62.40%\n",
      "Epoch 531, Loss: 0.5538150926952576, Test Loss: 0.6650561508611021, Test Accuracy: 62.40%\n",
      "Epoch 532, Loss: 0.5537195120666151, Test Loss: 0.6650541777592435, Test Accuracy: 62.40%\n",
      "Epoch 533, Loss: 0.5536240397496895, Test Loss: 0.6650522572144564, Test Accuracy: 62.40%\n",
      "Epoch 534, Loss: 0.553528675576058, Test Loss: 0.6650503891259062, Test Accuracy: 62.40%\n",
      "Epoch 535, Loss: 0.5534334193775949, Test Loss: 0.6650485733929544, Test Accuracy: 62.40%\n",
      "Epoch 536, Loss: 0.5533382709864734, Test Loss: 0.6650468099151583, Test Accuracy: 62.40%\n",
      "Epoch 537, Loss: 0.5532432302351633, Test Loss: 0.6650450985922695, Test Accuracy: 62.40%\n",
      "Epoch 538, Loss: 0.5531482969564319, Test Loss: 0.6650434393242355, Test Accuracy: 62.40%\n",
      "Epoch 539, Loss: 0.5530534709833426, Test Loss: 0.6650418320111975, Test Accuracy: 62.40%\n",
      "Epoch 540, Loss: 0.5529587521492545, Test Loss: 0.6650402765534918, Test Accuracy: 62.40%\n",
      "Epoch 541, Loss: 0.5528641402878225, Test Loss: 0.6650387728516475, Test Accuracy: 62.40%\n",
      "Epoch 542, Loss: 0.5527696352329962, Test Loss: 0.6650373208063874, Test Accuracy: 62.40%\n",
      "Epoch 543, Loss: 0.5526752368190192, Test Loss: 0.6650359203186277, Test Accuracy: 62.40%\n",
      "Epoch 544, Loss: 0.5525809448804299, Test Loss: 0.6650345712894771, Test Accuracy: 62.40%\n",
      "Epoch 545, Loss: 0.552486759252059, Test Loss: 0.6650332736202366, Test Accuracy: 62.40%\n",
      "Epoch 546, Loss: 0.5523926797690311, Test Loss: 0.6650320272123988, Test Accuracy: 62.40%\n",
      "Epoch 547, Loss: 0.5522987062667623, Test Loss: 0.6650308319676492, Test Accuracy: 62.40%\n",
      "Epoch 548, Loss: 0.552204838580961, Test Loss: 0.6650296877878631, Test Accuracy: 62.40%\n",
      "Epoch 549, Loss: 0.5521110765476276, Test Loss: 0.6650285945751078, Test Accuracy: 62.40%\n",
      "Epoch 550, Loss: 0.5520174200030522, Test Loss: 0.6650275522316406, Test Accuracy: 62.40%\n",
      "Epoch 551, Loss: 0.5519238687838162, Test Loss: 0.6650265606599093, Test Accuracy: 62.40%\n",
      "Epoch 552, Loss: 0.5518304227267908, Test Loss: 0.6650256197625513, Test Accuracy: 62.40%\n",
      "Epoch 553, Loss: 0.5517370816691364, Test Loss: 0.6650247294423937, Test Accuracy: 62.40%\n",
      "Epoch 554, Loss: 0.5516438454483023, Test Loss: 0.6650238896024528, Test Accuracy: 62.40%\n",
      "Epoch 555, Loss: 0.5515507139020265, Test Loss: 0.6650231001459336, Test Accuracy: 62.40%\n",
      "Epoch 556, Loss: 0.5514576868683347, Test Loss: 0.6650223609762298, Test Accuracy: 62.40%\n",
      "Epoch 557, Loss: 0.5513647641855406, Test Loss: 0.665021671996923, Test Accuracy: 62.40%\n",
      "Epoch 558, Loss: 0.5512719456922438, Test Loss: 0.6650210331117824, Test Accuracy: 62.40%\n",
      "Epoch 559, Loss: 0.5511792312273315, Test Loss: 0.665020444224765, Test Accuracy: 62.40%\n",
      "Epoch 560, Loss: 0.5510866206299763, Test Loss: 0.6650199052400145, Test Accuracy: 62.40%\n",
      "Epoch 561, Loss: 0.550994113739636, Test Loss: 0.6650194160618617, Test Accuracy: 62.20%\n",
      "Epoch 562, Loss: 0.5509017103960543, Test Loss: 0.6650189765948231, Test Accuracy: 62.20%\n",
      "Epoch 563, Loss: 0.5508094104392587, Test Loss: 0.6650185867436021, Test Accuracy: 62.20%\n",
      "Epoch 564, Loss: 0.5507172137095611, Test Loss: 0.6650182464130873, Test Accuracy: 62.20%\n",
      "Epoch 565, Loss: 0.5506251200475565, Test Loss: 0.6650179555083521, Test Accuracy: 62.20%\n",
      "Epoch 566, Loss: 0.5505331292941233, Test Loss: 0.6650177139346558, Test Accuracy: 62.00%\n",
      "Epoch 567, Loss: 0.5504412412904227, Test Loss: 0.6650175215974419, Test Accuracy: 62.00%\n",
      "Epoch 568, Loss: 0.5503494558778972, Test Loss: 0.665017378402338, Test Accuracy: 62.00%\n",
      "Epoch 569, Loss: 0.5502577728982716, Test Loss: 0.665017284255156, Test Accuracy: 62.00%\n",
      "Epoch 570, Loss: 0.5501661921935516, Test Loss: 0.6650172390618913, Test Accuracy: 61.80%\n",
      "Epoch 571, Loss: 0.5500747136060233, Test Loss: 0.6650172427287221, Test Accuracy: 61.80%\n",
      "Epoch 572, Loss: 0.5499833369782534, Test Loss: 0.66501729516201, Test Accuracy: 61.80%\n",
      "Epoch 573, Loss: 0.5498920621530878, Test Loss: 0.6650173962682991, Test Accuracy: 61.80%\n",
      "Epoch 574, Loss: 0.5498008889736518, Test Loss: 0.6650175459543154, Test Accuracy: 61.80%\n",
      "Epoch 575, Loss: 0.5497098172833492, Test Loss: 0.6650177441269671, Test Accuracy: 61.80%\n",
      "Epoch 576, Loss: 0.5496188469258624, Test Loss: 0.6650179906933438, Test Accuracy: 61.80%\n",
      "Epoch 577, Loss: 0.5495279777451508, Test Loss: 0.6650182855607161, Test Accuracy: 61.60%\n",
      "Epoch 578, Loss: 0.5494372095854521, Test Loss: 0.6650186286365356, Test Accuracy: 61.60%\n",
      "Epoch 579, Loss: 0.5493465422912795, Test Loss: 0.6650190198284345, Test Accuracy: 61.40%\n",
      "Epoch 580, Loss: 0.5492559757074237, Test Loss: 0.6650194590442251, Test Accuracy: 61.40%\n",
      "Epoch 581, Loss: 0.5491655096789502, Test Loss: 0.6650199461918994, Test Accuracy: 61.40%\n",
      "Epoch 582, Loss: 0.5490751440512005, Test Loss: 0.6650204811796289, Test Accuracy: 61.40%\n",
      "Epoch 583, Loss: 0.5489848786697905, Test Loss: 0.6650210639157641, Test Accuracy: 61.40%\n",
      "Epoch 584, Loss: 0.548894713380611, Test Loss: 0.665021694308835, Test Accuracy: 61.40%\n",
      "Epoch 585, Loss: 0.5488046480298258, Test Loss: 0.6650223722675489, Test Accuracy: 61.40%\n",
      "Epoch 586, Loss: 0.5487146824638732, Test Loss: 0.6650230977007924, Test Accuracy: 61.60%\n",
      "Epoch 587, Loss: 0.5486248165294634, Test Loss: 0.6650238705176289, Test Accuracy: 61.40%\n",
      "Epoch 588, Loss: 0.5485350500735799, Test Loss: 0.6650246906272996, Test Accuracy: 61.40%\n",
      "Epoch 589, Loss: 0.5484453829434773, Test Loss: 0.6650255579392235, Test Accuracy: 61.40%\n",
      "Epoch 590, Loss: 0.5483558149866827, Test Loss: 0.6650264723629952, Test Accuracy: 61.40%\n",
      "Epoch 591, Loss: 0.5482663460509937, Test Loss: 0.6650274338083865, Test Accuracy: 61.40%\n",
      "Epoch 592, Loss: 0.5481769759844781, Test Loss: 0.6650284421853451, Test Accuracy: 61.40%\n",
      "Epoch 593, Loss: 0.5480877046354747, Test Loss: 0.6650294974039943, Test Accuracy: 61.40%\n",
      "Epoch 594, Loss: 0.5479985318525908, Test Loss: 0.6650305993746332, Test Accuracy: 61.40%\n",
      "Epoch 595, Loss: 0.5479094574847037, Test Loss: 0.6650317480077356, Test Accuracy: 61.40%\n",
      "Epoch 596, Loss: 0.5478204813809591, Test Loss: 0.6650329432139506, Test Accuracy: 61.40%\n",
      "Epoch 597, Loss: 0.5477316033907709, Test Loss: 0.6650341849041007, Test Accuracy: 61.40%\n",
      "Epoch 598, Loss: 0.5476428233638205, Test Loss: 0.6650354729891841, Test Accuracy: 61.40%\n",
      "Epoch 599, Loss: 0.5475541411500569, Test Loss: 0.6650368073803712, Test Accuracy: 61.40%\n",
      "Epoch 600, Loss: 0.5474655565996958, Test Loss: 0.6650381879890066, Test Accuracy: 61.40%\n",
      "Epoch 601, Loss: 0.5473770695632187, Test Loss: 0.6650396147266079, Test Accuracy: 61.40%\n",
      "Epoch 602, Loss: 0.5472886798913739, Test Loss: 0.6650410875048655, Test Accuracy: 61.40%\n",
      "Epoch 603, Loss: 0.5472003874351741, Test Loss: 0.6650426062356424, Test Accuracy: 61.40%\n",
      "Epoch 604, Loss: 0.5471121920458977, Test Loss: 0.6650441708309731, Test Accuracy: 61.40%\n",
      "Epoch 605, Loss: 0.547024093575087, Test Loss: 0.6650457812030646, Test Accuracy: 61.40%\n",
      "Epoch 606, Loss: 0.5469360918745484, Test Loss: 0.665047437264295, Test Accuracy: 61.40%\n",
      "Epoch 607, Loss: 0.546848186796352, Test Loss: 0.6650491389272137, Test Accuracy: 61.40%\n",
      "Epoch 608, Loss: 0.5467603781928309, Test Loss: 0.6650508861045407, Test Accuracy: 61.40%\n",
      "Epoch 609, Loss: 0.5466726659165806, Test Loss: 0.6650526787091665, Test Accuracy: 61.40%\n",
      "Epoch 610, Loss: 0.5465850498204589, Test Loss: 0.6650545166541518, Test Accuracy: 61.40%\n",
      "Epoch 611, Loss: 0.5464975297575848, Test Loss: 0.6650563998527274, Test Accuracy: 61.40%\n",
      "Epoch 612, Loss: 0.5464101055813393, Test Loss: 0.6650583282182928, Test Accuracy: 61.40%\n",
      "Epoch 613, Loss: 0.5463227771453634, Test Loss: 0.6650603016644175, Test Accuracy: 61.40%\n",
      "Epoch 614, Loss: 0.5462355443035588, Test Loss: 0.6650623201048397, Test Accuracy: 61.20%\n",
      "Epoch 615, Loss: 0.5461484069100867, Test Loss: 0.6650643834534659, Test Accuracy: 61.20%\n",
      "Epoch 616, Loss: 0.5460613648193678, Test Loss: 0.6650664916243706, Test Accuracy: 61.20%\n",
      "Epoch 617, Loss: 0.5459744178860818, Test Loss: 0.6650686445317965, Test Accuracy: 61.20%\n",
      "Epoch 618, Loss: 0.5458875659651665, Test Loss: 0.6650708420901539, Test Accuracy: 61.20%\n",
      "Epoch 619, Loss: 0.5458008089118179, Test Loss: 0.6650730842140201, Test Accuracy: 61.20%\n",
      "Epoch 620, Loss: 0.5457141465814894, Test Loss: 0.6650753708181394, Test Accuracy: 61.20%\n",
      "Epoch 621, Loss: 0.5456275788298917, Test Loss: 0.6650777018174227, Test Accuracy: 61.20%\n",
      "Epoch 622, Loss: 0.5455411055129916, Test Loss: 0.6650800771269471, Test Accuracy: 61.20%\n",
      "Epoch 623, Loss: 0.5454547264870123, Test Loss: 0.665082496661956, Test Accuracy: 61.20%\n",
      "Epoch 624, Loss: 0.5453684416084329, Test Loss: 0.6650849603378574, Test Accuracy: 61.20%\n",
      "Epoch 625, Loss: 0.5452822507339873, Test Loss: 0.665087468070226, Test Accuracy: 61.20%\n",
      "Epoch 626, Loss: 0.5451961537206647, Test Loss: 0.6650900197748004, Test Accuracy: 61.20%\n",
      "Epoch 627, Loss: 0.5451101504257078, Test Loss: 0.6650926153674847, Test Accuracy: 61.20%\n",
      "Epoch 628, Loss: 0.5450242407066139, Test Loss: 0.665095254764346, Test Accuracy: 61.20%\n",
      "Epoch 629, Loss: 0.5449384244211334, Test Loss: 0.6650979378816175, Test Accuracy: 61.20%\n",
      "Epoch 630, Loss: 0.5448527014272697, Test Loss: 0.665100664635694, Test Accuracy: 61.20%\n",
      "Epoch 631, Loss: 0.5447670715832786, Test Loss: 0.6651034349431351, Test Accuracy: 61.40%\n",
      "Epoch 632, Loss: 0.544681534747668, Test Loss: 0.6651062487206627, Test Accuracy: 61.40%\n",
      "Epoch 633, Loss: 0.5445960907791976, Test Loss: 0.665109105885162, Test Accuracy: 61.40%\n",
      "Epoch 634, Loss: 0.5445107395368778, Test Loss: 0.6651120063536803, Test Accuracy: 61.40%\n",
      "Epoch 635, Loss: 0.5444254808799702, Test Loss: 0.6651149500434271, Test Accuracy: 61.40%\n",
      "Epoch 636, Loss: 0.5443403146679863, Test Loss: 0.6651179368717741, Test Accuracy: 61.40%\n",
      "Epoch 637, Loss: 0.5442552407606874, Test Loss: 0.6651209667562538, Test Accuracy: 61.40%\n",
      "Epoch 638, Loss: 0.5441702590180844, Test Loss: 0.6651240396145601, Test Accuracy: 61.40%\n",
      "Epoch 639, Loss: 0.5440853693004368, Test Loss: 0.6651271553645485, Test Accuracy: 61.40%\n",
      "Epoch 640, Loss: 0.544000571468253, Test Loss: 0.665130313924234, Test Accuracy: 61.40%\n",
      "Epoch 641, Loss: 0.5439158653822886, Test Loss: 0.6651335152117925, Test Accuracy: 61.40%\n",
      "Epoch 642, Loss: 0.5438312509035478, Test Loss: 0.6651367591455597, Test Accuracy: 61.40%\n",
      "Epoch 643, Loss: 0.543746727893281, Test Loss: 0.665140045644031, Test Accuracy: 61.40%\n",
      "Epoch 644, Loss: 0.5436622962129858, Test Loss: 0.6651433746258609, Test Accuracy: 61.40%\n",
      "Epoch 645, Loss: 0.5435779557244059, Test Loss: 0.6651467460098632, Test Accuracy: 61.40%\n",
      "Epoch 646, Loss: 0.543493706289531, Test Loss: 0.66515015971501, Test Accuracy: 61.40%\n",
      "Epoch 647, Loss: 0.5434095477705955, Test Loss: 0.6651536156604324, Test Accuracy: 61.20%\n",
      "Epoch 648, Loss: 0.5433254800300794, Test Loss: 0.6651571137654188, Test Accuracy: 61.20%\n",
      "Epoch 649, Loss: 0.5432415029307067, Test Loss: 0.6651606539494161, Test Accuracy: 61.20%\n",
      "Epoch 650, Loss: 0.5431576163354458, Test Loss: 0.6651642361320282, Test Accuracy: 61.20%\n",
      "Epoch 651, Loss: 0.5430738201075082, Test Loss: 0.6651678602330167, Test Accuracy: 61.20%\n",
      "Epoch 652, Loss: 0.542990114110349, Test Loss: 0.6651715261722989, Test Accuracy: 61.20%\n",
      "Epoch 653, Loss: 0.5429064982076658, Test Loss: 0.6651752338699503, Test Accuracy: 61.20%\n",
      "Epoch 654, Loss: 0.5428229722633985, Test Loss: 0.6651789832462012, Test Accuracy: 61.20%\n",
      "Epoch 655, Loss: 0.5427395361417288, Test Loss: 0.6651827742214385, Test Accuracy: 61.20%\n",
      "Epoch 656, Loss: 0.5426561897070794, Test Loss: 0.6651866067162048, Test Accuracy: 61.20%\n",
      "Epoch 657, Loss: 0.5425729328241148, Test Loss: 0.6651904806511977, Test Accuracy: 61.20%\n",
      "Epoch 658, Loss: 0.5424897653577393, Test Loss: 0.66519439594727, Test Accuracy: 61.20%\n",
      "Epoch 659, Loss: 0.5424066871730976, Test Loss: 0.6651983525254294, Test Accuracy: 61.20%\n",
      "Epoch 660, Loss: 0.542323698135574, Test Loss: 0.6652023503068375, Test Accuracy: 61.20%\n",
      "Epoch 661, Loss: 0.5422407981107918, Test Loss: 0.6652063892128108, Test Accuracy: 61.20%\n",
      "Epoch 662, Loss: 0.5421579869646134, Test Loss: 0.6652104691648187, Test Accuracy: 61.20%\n",
      "Epoch 663, Loss: 0.5420752645631393, Test Loss: 0.6652145900844849, Test Accuracy: 61.20%\n",
      "Epoch 664, Loss: 0.5419926307727079, Test Loss: 0.6652187518935857, Test Accuracy: 61.20%\n",
      "Epoch 665, Loss: 0.5419100854598953, Test Loss: 0.6652229545140509, Test Accuracy: 61.20%\n",
      "Epoch 666, Loss: 0.5418276284915143, Test Loss: 0.6652271978679625, Test Accuracy: 61.20%\n",
      "Epoch 667, Loss: 0.5417452597346148, Test Loss: 0.6652314818775548, Test Accuracy: 61.20%\n",
      "Epoch 668, Loss: 0.5416629790564824, Test Loss: 0.6652358064652144, Test Accuracy: 61.20%\n",
      "Epoch 669, Loss: 0.5415807863246387, Test Loss: 0.6652401715534794, Test Accuracy: 61.20%\n",
      "Epoch 670, Loss: 0.5414986814068408, Test Loss: 0.6652445770650393, Test Accuracy: 61.20%\n",
      "Epoch 671, Loss: 0.54141666417108, Test Loss: 0.6652490229227348, Test Accuracy: 61.20%\n",
      "Epoch 672, Loss: 0.5413347344855829, Test Loss: 0.6652535090495576, Test Accuracy: 61.40%\n",
      "Epoch 673, Loss: 0.5412528922188097, Test Loss: 0.6652580353686497, Test Accuracy: 61.20%\n",
      "Epoch 674, Loss: 0.5411711372394543, Test Loss: 0.6652626018033032, Test Accuracy: 61.20%\n",
      "Epoch 675, Loss: 0.5410894694164439, Test Loss: 0.6652672082769605, Test Accuracy: 61.20%\n",
      "Epoch 676, Loss: 0.5410078886189381, Test Loss: 0.6652718547132136, Test Accuracy: 61.20%\n",
      "Epoch 677, Loss: 0.5409263947163294, Test Loss: 0.6652765410358034, Test Accuracy: 61.20%\n",
      "Epoch 678, Loss: 0.5408449875782417, Test Loss: 0.66528126716862, Test Accuracy: 61.20%\n",
      "Epoch 679, Loss: 0.5407636670745307, Test Loss: 0.665286033035703, Test Accuracy: 61.20%\n",
      "Epoch 680, Loss: 0.5406824330752831, Test Loss: 0.6652908385612395, Test Accuracy: 61.20%\n",
      "Epoch 681, Loss: 0.5406012854508162, Test Loss: 0.6652956836695653, Test Accuracy: 61.20%\n",
      "Epoch 682, Loss: 0.5405202240716777, Test Loss: 0.6653005682851639, Test Accuracy: 61.20%\n",
      "Epoch 683, Loss: 0.5404392488086446, Test Loss: 0.6653054923326667, Test Accuracy: 61.20%\n",
      "Epoch 684, Loss: 0.5403583595327238, Test Loss: 0.6653104557368515, Test Accuracy: 61.20%\n",
      "Epoch 685, Loss: 0.5402775561151513, Test Loss: 0.6653154584226445, Test Accuracy: 61.20%\n",
      "Epoch 686, Loss: 0.5401968384273912, Test Loss: 0.6653205003151174, Test Accuracy: 61.20%\n",
      "Epoch 687, Loss: 0.5401162063411358, Test Loss: 0.6653255813394889, Test Accuracy: 61.20%\n",
      "Epoch 688, Loss: 0.5400356597283049, Test Loss: 0.6653307014211239, Test Accuracy: 61.20%\n",
      "Epoch 689, Loss: 0.5399551984610466, Test Loss: 0.665335860485533, Test Accuracy: 61.20%\n",
      "Epoch 690, Loss: 0.5398748224117347, Test Loss: 0.665341058458372, Test Accuracy: 61.20%\n",
      "Epoch 691, Loss: 0.53979453145297, Test Loss: 0.6653462952654428, Test Accuracy: 61.20%\n",
      "Epoch 692, Loss: 0.5397143254575791, Test Loss: 0.6653515708326914, Test Accuracy: 61.20%\n",
      "Epoch 693, Loss: 0.5396342042986149, Test Loss: 0.6653568850862094, Test Accuracy: 61.20%\n",
      "Epoch 694, Loss: 0.5395541678493545, Test Loss: 0.665362237952232, Test Accuracy: 61.20%\n",
      "Epoch 695, Loss: 0.5394742159833007, Test Loss: 0.665367629357139, Test Accuracy: 61.20%\n",
      "Epoch 696, Loss: 0.53939434857418, Test Loss: 0.6653730592274542, Test Accuracy: 61.20%\n",
      "Epoch 697, Loss: 0.5393145654959434, Test Loss: 0.665378527489844, Test Accuracy: 61.20%\n",
      "Epoch 698, Loss: 0.5392348666227652, Test Loss: 0.6653840340711196, Test Accuracy: 61.20%\n",
      "Epoch 699, Loss: 0.5391552518290428, Test Loss: 0.6653895788982338, Test Accuracy: 61.20%\n",
      "Epoch 700, Loss: 0.5390757209893966, Test Loss: 0.665395161898283, Test Accuracy: 61.20%\n",
      "Epoch 701, Loss: 0.5389962739786692, Test Loss: 0.6654007829985056, Test Accuracy: 61.20%\n",
      "Epoch 702, Loss: 0.538916910671925, Test Loss: 0.665406442126282, Test Accuracy: 61.20%\n",
      "Epoch 703, Loss: 0.5388376309444501, Test Loss: 0.6654121392091351, Test Accuracy: 61.20%\n",
      "Epoch 704, Loss: 0.5387584346717516, Test Loss: 0.6654178741747289, Test Accuracy: 61.20%\n",
      "Epoch 705, Loss: 0.5386793217295576, Test Loss: 0.6654236469508686, Test Accuracy: 61.20%\n",
      "Epoch 706, Loss: 0.5386002919938158, Test Loss: 0.665429457465501, Test Accuracy: 61.20%\n",
      "Epoch 707, Loss: 0.5385213453406944, Test Loss: 0.6654353056467127, Test Accuracy: 61.20%\n",
      "Epoch 708, Loss: 0.5384424816465809, Test Loss: 0.665441191422732, Test Accuracy: 61.20%\n",
      "Epoch 709, Loss: 0.5383637007880822, Test Loss: 0.6654471147219263, Test Accuracy: 61.20%\n",
      "Epoch 710, Loss: 0.5382850026420231, Test Loss: 0.6654530754728034, Test Accuracy: 61.00%\n",
      "Epoch 711, Loss: 0.538206387085447, Test Loss: 0.6654590736040106, Test Accuracy: 61.00%\n",
      "Epoch 712, Loss: 0.5381278539956159, Test Loss: 0.6654651090443348, Test Accuracy: 61.00%\n",
      "Epoch 713, Loss: 0.5380494032500083, Test Loss: 0.6654711817227014, Test Accuracy: 61.00%\n",
      "Epoch 714, Loss: 0.5379710347263201, Test Loss: 0.6654772915681754, Test Accuracy: 61.00%\n",
      "Epoch 715, Loss: 0.5378927483024641, Test Loss: 0.6654834385099596, Test Accuracy: 61.00%\n",
      "Epoch 716, Loss: 0.5378145438565688, Test Loss: 0.6654896224773956, Test Accuracy: 61.00%\n",
      "Epoch 717, Loss: 0.5377364212669793, Test Loss: 0.6654958433999623, Test Accuracy: 61.00%\n",
      "Epoch 718, Loss: 0.5376583804122556, Test Loss: 0.6655021012072769, Test Accuracy: 61.00%\n",
      "Epoch 719, Loss: 0.5375804211711727, Test Loss: 0.6655083958290939, Test Accuracy: 61.00%\n",
      "Epoch 720, Loss: 0.5375025434227207, Test Loss: 0.6655147271953049, Test Accuracy: 61.00%\n",
      "Epoch 721, Loss: 0.5374247470461039, Test Loss: 0.6655210952359384, Test Accuracy: 61.00%\n",
      "Epoch 722, Loss: 0.5373470319207401, Test Loss: 0.665527499881159, Test Accuracy: 61.00%\n",
      "Epoch 723, Loss: 0.5372693979262608, Test Loss: 0.6655339410612686, Test Accuracy: 61.00%\n",
      "Epoch 724, Loss: 0.5371918449425109, Test Loss: 0.6655404187067042, Test Accuracy: 61.00%\n",
      "Epoch 725, Loss: 0.5371143728495473, Test Loss: 0.6655469327480396, Test Accuracy: 61.00%\n",
      "Epoch 726, Loss: 0.5370369815276398, Test Loss: 0.6655534831159827, Test Accuracy: 61.00%\n",
      "Epoch 727, Loss: 0.5369596708572696, Test Loss: 0.6655600697413784, Test Accuracy: 61.00%\n",
      "Epoch 728, Loss: 0.53688244071913, Test Loss: 0.6655666925552051, Test Accuracy: 61.00%\n",
      "Epoch 729, Loss: 0.536805290994125, Test Loss: 0.6655733514885763, Test Accuracy: 61.20%\n",
      "Epoch 730, Loss: 0.536728221563369, Test Loss: 0.6655800464727407, Test Accuracy: 61.20%\n",
      "Epoch 731, Loss: 0.5366512323081876, Test Loss: 0.6655867774390803, Test Accuracy: 61.20%\n",
      "Epoch 732, Loss: 0.5365743231101155, Test Loss: 0.6655935443191113, Test Accuracy: 61.20%\n",
      "Epoch 733, Loss: 0.5364974938508976, Test Loss: 0.6656003470444832, Test Accuracy: 61.20%\n",
      "Epoch 734, Loss: 0.5364207444124874, Test Loss: 0.6656071855469797, Test Accuracy: 61.20%\n",
      "Epoch 735, Loss: 0.5363440746770475, Test Loss: 0.665614059758517, Test Accuracy: 61.20%\n",
      "Epoch 736, Loss: 0.536267484526949, Test Loss: 0.6656209696111437, Test Accuracy: 61.20%\n",
      "Epoch 737, Loss: 0.5361909738447704, Test Loss: 0.6656279150370419, Test Accuracy: 61.20%\n",
      "Epoch 738, Loss: 0.5361145425132985, Test Loss: 0.6656348959685257, Test Accuracy: 61.20%\n",
      "Epoch 739, Loss: 0.536038190415527, Test Loss: 0.6656419123380409, Test Accuracy: 61.20%\n",
      "Epoch 740, Loss: 0.5359619174346563, Test Loss: 0.6656489640781658, Test Accuracy: 61.20%\n",
      "Epoch 741, Loss: 0.5358857234540936, Test Loss: 0.6656560511216086, Test Accuracy: 61.40%\n",
      "Epoch 742, Loss: 0.5358096083574517, Test Loss: 0.6656631734012111, Test Accuracy: 61.40%\n",
      "Epoch 743, Loss: 0.5357335720285497, Test Loss: 0.6656703308499442, Test Accuracy: 61.40%\n",
      "Epoch 744, Loss: 0.5356576143514112, Test Loss: 0.6656775234009105, Test Accuracy: 61.40%\n",
      "Epoch 745, Loss: 0.5355817352102656, Test Loss: 0.6656847509873425, Test Accuracy: 61.40%\n",
      "Epoch 746, Loss: 0.535505934489546, Test Loss: 0.6656920135426032, Test Accuracy: 61.40%\n",
      "Epoch 747, Loss: 0.5354302120738904, Test Loss: 0.6656993110001856, Test Accuracy: 61.40%\n",
      "Epoch 748, Loss: 0.5353545678481401, Test Loss: 0.6657066432937123, Test Accuracy: 61.40%\n",
      "Epoch 749, Loss: 0.5352790016973396, Test Loss: 0.6657140103569351, Test Accuracy: 61.40%\n",
      "Epoch 750, Loss: 0.535203513506737, Test Loss: 0.6657214121237355, Test Accuracy: 61.40%\n",
      "Epoch 751, Loss: 0.5351281031617827, Test Loss: 0.6657288485281231, Test Accuracy: 61.40%\n",
      "Epoch 752, Loss: 0.5350527705481295, Test Loss: 0.6657363195042368, Test Accuracy: 61.40%\n",
      "Epoch 753, Loss: 0.5349775155516315, Test Loss: 0.665743824986344, Test Accuracy: 61.40%\n",
      "Epoch 754, Loss: 0.5349023380583455, Test Loss: 0.6657513649088395, Test Accuracy: 61.40%\n",
      "Epoch 755, Loss: 0.5348272379545282, Test Loss: 0.6657589392062466, Test Accuracy: 61.40%\n",
      "Epoch 756, Loss: 0.5347522151266377, Test Loss: 0.665766547813216, Test Accuracy: 61.40%\n",
      "Epoch 757, Loss: 0.5346772694613321, Test Loss: 0.6657741906645258, Test Accuracy: 61.60%\n",
      "Epoch 758, Loss: 0.5346024008454701, Test Loss: 0.665781867695081, Test Accuracy: 61.60%\n",
      "Epoch 759, Loss: 0.534527609166109, Test Loss: 0.6657895788399137, Test Accuracy: 61.60%\n",
      "Epoch 760, Loss: 0.5344528943105065, Test Loss: 0.6657973240341826, Test Accuracy: 61.60%\n",
      "Epoch 761, Loss: 0.5343782561661187, Test Loss: 0.6658051032131728, Test Accuracy: 61.60%\n",
      "Epoch 762, Loss: 0.5343036946205998, Test Loss: 0.6658129163122948, Test Accuracy: 61.60%\n",
      "Epoch 763, Loss: 0.5342292095618026, Test Loss: 0.6658207632670861, Test Accuracy: 61.60%\n",
      "Epoch 764, Loss: 0.5341548008777778, Test Loss: 0.6658286440132088, Test Accuracy: 61.60%\n",
      "Epoch 765, Loss: 0.5340804684567729, Test Loss: 0.6658365584864506, Test Accuracy: 61.60%\n",
      "Epoch 766, Loss: 0.5340062121872329, Test Loss: 0.6658445066227249, Test Accuracy: 61.60%\n",
      "Epoch 767, Loss: 0.5339320319577994, Test Loss: 0.6658524883580687, Test Accuracy: 61.60%\n",
      "Epoch 768, Loss: 0.5338579276573101, Test Loss: 0.6658605036286447, Test Accuracy: 61.60%\n",
      "Epoch 769, Loss: 0.5337838991747987, Test Loss: 0.6658685523707393, Test Accuracy: 61.40%\n",
      "Epoch 770, Loss: 0.5337099463994947, Test Loss: 0.6658766345207632, Test Accuracy: 61.40%\n",
      "Epoch 771, Loss: 0.5336360692208221, Test Loss: 0.6658847500152509, Test Accuracy: 61.40%\n",
      "Epoch 772, Loss: 0.5335622675284005, Test Loss: 0.6658928987908604, Test Accuracy: 61.20%\n",
      "Epoch 773, Loss: 0.5334885412120435, Test Loss: 0.665901080784373, Test Accuracy: 61.20%\n",
      "Epoch 774, Loss: 0.533414890161759, Test Loss: 0.6659092959326935, Test Accuracy: 61.20%\n",
      "Epoch 775, Loss: 0.5333413142677484, Test Loss: 0.6659175441728489, Test Accuracy: 61.20%\n",
      "Epoch 776, Loss: 0.5332678134204066, Test Loss: 0.6659258254419888, Test Accuracy: 61.20%\n",
      "Epoch 777, Loss: 0.5331943875103214, Test Loss: 0.6659341396773859, Test Accuracy: 61.20%\n",
      "Epoch 778, Loss: 0.5331210364282737, Test Loss: 0.6659424868164345, Test Accuracy: 61.20%\n",
      "Epoch 779, Loss: 0.5330477600652359, Test Loss: 0.6659508667966504, Test Accuracy: 61.20%\n",
      "Epoch 780, Loss: 0.5329745583123727, Test Loss: 0.6659592795556714, Test Accuracy: 61.20%\n",
      "Epoch 781, Loss: 0.5329014310610407, Test Loss: 0.6659677250312566, Test Accuracy: 61.20%\n",
      "Epoch 782, Loss: 0.5328283782027867, Test Loss: 0.6659762031612863, Test Accuracy: 61.20%\n",
      "Epoch 783, Loss: 0.5327553996293495, Test Loss: 0.6659847138837616, Test Accuracy: 61.20%\n",
      "Epoch 784, Loss: 0.5326824952326578, Test Loss: 0.6659932571368039, Test Accuracy: 61.20%\n",
      "Epoch 785, Loss: 0.53260966490483, Test Loss: 0.6660018328586556, Test Accuracy: 61.20%\n",
      "Epoch 786, Loss: 0.5325369085381751, Test Loss: 0.6660104409876787, Test Accuracy: 61.20%\n",
      "Epoch 787, Loss: 0.5324642260251912, Test Loss: 0.6660190814623552, Test Accuracy: 61.20%\n",
      "Epoch 788, Loss: 0.5323916172585649, Test Loss: 0.6660277542212869, Test Accuracy: 61.20%\n",
      "Epoch 789, Loss: 0.5323190821311723, Test Loss: 0.6660364592031951, Test Accuracy: 61.20%\n",
      "Epoch 790, Loss: 0.5322466205360774, Test Loss: 0.6660451963469199, Test Accuracy: 61.20%\n",
      "Epoch 791, Loss: 0.532174232366532, Test Loss: 0.6660539655914207, Test Accuracy: 61.20%\n",
      "Epoch 792, Loss: 0.5321019175159761, Test Loss: 0.6660627668757755, Test Accuracy: 61.20%\n",
      "Epoch 793, Loss: 0.5320296758780364, Test Loss: 0.6660716001391801, Test Accuracy: 61.20%\n",
      "Epoch 794, Loss: 0.5319575073465269, Test Loss: 0.66608046532095, Test Accuracy: 61.20%\n",
      "Epoch 795, Loss: 0.531885411815448, Test Loss: 0.666089362360517, Test Accuracy: 61.20%\n",
      "Epoch 796, Loss: 0.5318133891789861, Test Loss: 0.6660982911974317, Test Accuracy: 61.20%\n",
      "Epoch 797, Loss: 0.531741439331514, Test Loss: 0.6661072517713619, Test Accuracy: 61.40%\n",
      "Epoch 798, Loss: 0.5316695621675895, Test Loss: 0.6661162440220925, Test Accuracy: 61.40%\n",
      "Epoch 799, Loss: 0.5315977575819559, Test Loss: 0.6661252678895255, Test Accuracy: 61.40%\n",
      "Epoch 800, Loss: 0.5315260254695412, Test Loss: 0.66613432331368, Test Accuracy: 61.40%\n",
      "Epoch 801, Loss: 0.5314543657254576, Test Loss: 0.6661434102346916, Test Accuracy: 61.40%\n",
      "Epoch 802, Loss: 0.531382778245002, Test Loss: 0.6661525285928112, Test Accuracy: 61.40%\n",
      "Epoch 803, Loss: 0.5313112629236547, Test Loss: 0.6661616783284072, Test Accuracy: 61.40%\n",
      "Epoch 804, Loss: 0.5312398196570792, Test Loss: 0.6661708593819632, Test Accuracy: 61.40%\n",
      "Epoch 805, Loss: 0.5311684483411225, Test Loss: 0.6661800716940781, Test Accuracy: 61.40%\n",
      "Epoch 806, Loss: 0.5310971488718144, Test Loss: 0.666189315205467, Test Accuracy: 61.40%\n",
      "Epoch 807, Loss: 0.5310259211453665, Test Loss: 0.6661985898569591, Test Accuracy: 61.40%\n",
      "Epoch 808, Loss: 0.5309547650581729, Test Loss: 0.6662078955894994, Test Accuracy: 61.40%\n",
      "Epoch 809, Loss: 0.5308836805068095, Test Loss: 0.6662172323441472, Test Accuracy: 61.20%\n",
      "Epoch 810, Loss: 0.530812667388033, Test Loss: 0.6662266000620762, Test Accuracy: 61.20%\n",
      "Epoch 811, Loss: 0.5307417255987817, Test Loss: 0.6662359986845746, Test Accuracy: 61.20%\n",
      "Epoch 812, Loss: 0.5306708550361746, Test Loss: 0.6662454281530442, Test Accuracy: 61.20%\n",
      "Epoch 813, Loss: 0.5306000555975106, Test Loss: 0.6662548884090005, Test Accuracy: 61.20%\n",
      "Epoch 814, Loss: 0.5305293271802684, Test Loss: 0.6662643793940731, Test Accuracy: 61.20%\n",
      "Epoch 815, Loss: 0.5304586696821072, Test Loss: 0.6662739010500045, Test Accuracy: 61.00%\n",
      "Epoch 816, Loss: 0.5303880830008647, Test Loss: 0.6662834533186501, Test Accuracy: 61.00%\n",
      "Epoch 817, Loss: 0.530317567034558, Test Loss: 0.6662930361419787, Test Accuracy: 61.00%\n",
      "Epoch 818, Loss: 0.530247121681383, Test Loss: 0.6663026494620707, Test Accuracy: 61.00%\n",
      "Epoch 819, Loss: 0.5301767468397133, Test Loss: 0.6663122932211201, Test Accuracy: 61.00%\n",
      "Epoch 820, Loss: 0.5301064424081009, Test Loss: 0.6663219673614323, Test Accuracy: 61.00%\n",
      "Epoch 821, Loss: 0.5300362082852754, Test Loss: 0.6663316718254246, Test Accuracy: 61.00%\n",
      "Epoch 822, Loss: 0.5299660443701434, Test Loss: 0.6663414065556266, Test Accuracy: 61.00%\n",
      "Epoch 823, Loss: 0.5298959505617888, Test Loss: 0.6663511714946784, Test Accuracy: 61.00%\n",
      "Epoch 824, Loss: 0.5298259267594722, Test Loss: 0.6663609665853323, Test Accuracy: 61.00%\n",
      "Epoch 825, Loss: 0.5297559728626297, Test Loss: 0.6663707917704511, Test Accuracy: 61.00%\n",
      "Epoch 826, Loss: 0.5296860887708741, Test Loss: 0.6663806469930085, Test Accuracy: 61.00%\n",
      "Epoch 827, Loss: 0.5296162743839938, Test Loss: 0.6663905321960887, Test Accuracy: 61.00%\n",
      "Epoch 828, Loss: 0.5295465296019523, Test Loss: 0.6664004473228863, Test Accuracy: 61.00%\n",
      "Epoch 829, Loss: 0.5294768543248877, Test Loss: 0.6664103923167061, Test Accuracy: 61.00%\n",
      "Epoch 830, Loss: 0.5294072484531134, Test Loss: 0.6664203671209628, Test Accuracy: 61.00%\n",
      "Epoch 831, Loss: 0.5293377118871165, Test Loss: 0.6664303716791806, Test Accuracy: 61.00%\n",
      "Epoch 832, Loss: 0.5292682445275585, Test Loss: 0.6664404059349933, Test Accuracy: 61.00%\n",
      "Epoch 833, Loss: 0.5291988462752742, Test Loss: 0.666450469832144, Test Accuracy: 61.00%\n",
      "Epoch 834, Loss: 0.5291295170312722, Test Loss: 0.6664605633144844, Test Accuracy: 61.00%\n",
      "Epoch 835, Loss: 0.5290602566967332, Test Loss: 0.6664706863259756, Test Accuracy: 61.00%\n",
      "Epoch 836, Loss: 0.5289910651730113, Test Loss: 0.6664808388106865, Test Accuracy: 61.00%\n",
      "Epoch 837, Loss: 0.5289219423616326, Test Loss: 0.6664910207127954, Test Accuracy: 61.00%\n",
      "Epoch 838, Loss: 0.5288528881642954, Test Loss: 0.6665012319765878, Test Accuracy: 61.00%\n",
      "Epoch 839, Loss: 0.5287839024828694, Test Loss: 0.6665114725464574, Test Accuracy: 61.00%\n",
      "Epoch 840, Loss: 0.5287149852193957, Test Loss: 0.6665217423669058, Test Accuracy: 61.00%\n",
      "Epoch 841, Loss: 0.5286461362760867, Test Loss: 0.6665320413825415, Test Accuracy: 61.00%\n",
      "Epoch 842, Loss: 0.528577355555325, Test Loss: 0.666542369538081, Test Accuracy: 61.00%\n",
      "Epoch 843, Loss: 0.5285086429596642, Test Loss: 0.6665527267783475, Test Accuracy: 61.00%\n",
      "Epoch 844, Loss: 0.5284399983918272, Test Loss: 0.6665631130482708, Test Accuracy: 61.00%\n",
      "Epoch 845, Loss: 0.5283714217547071, Test Loss: 0.6665735282928876, Test Accuracy: 61.00%\n",
      "Epoch 846, Loss: 0.5283029129513663, Test Loss: 0.6665839724573407, Test Accuracy: 61.20%\n",
      "Epoch 847, Loss: 0.5282344718850364, Test Loss: 0.6665944454868793, Test Accuracy: 61.20%\n",
      "Epoch 848, Loss: 0.5281660984591176, Test Loss: 0.6666049473268586, Test Accuracy: 61.20%\n",
      "Epoch 849, Loss: 0.5280977925771784, Test Loss: 0.6666154779227398, Test Accuracy: 61.20%\n",
      "Epoch 850, Loss: 0.5280295541429557, Test Loss: 0.6666260372200884, Test Accuracy: 61.20%\n",
      "Epoch 851, Loss: 0.5279613830603542, Test Loss: 0.6666366251645767, Test Accuracy: 61.20%\n",
      "Epoch 852, Loss: 0.5278932792334455, Test Loss: 0.6666472417019813, Test Accuracy: 61.20%\n",
      "Epoch 853, Loss: 0.5278252425664695, Test Loss: 0.6666578867781838, Test Accuracy: 61.20%\n",
      "Epoch 854, Loss: 0.5277572729638316, Test Loss: 0.6666685603391703, Test Accuracy: 61.20%\n",
      "Epoch 855, Loss: 0.5276893703301048, Test Loss: 0.6666792623310319, Test Accuracy: 61.20%\n",
      "Epoch 856, Loss: 0.5276215345700277, Test Loss: 0.6666899926999635, Test Accuracy: 61.20%\n",
      "Epoch 857, Loss: 0.5275537655885051, Test Loss: 0.6667007513922638, Test Accuracy: 61.20%\n",
      "Epoch 858, Loss: 0.5274860632906072, Test Loss: 0.6667115383543363, Test Accuracy: 61.20%\n",
      "Epoch 859, Loss: 0.5274184275815696, Test Loss: 0.6667223535326869, Test Accuracy: 61.20%\n",
      "Epoch 860, Loss: 0.5273508583667927, Test Loss: 0.6667331968739257, Test Accuracy: 61.20%\n",
      "Epoch 861, Loss: 0.5272833555518418, Test Loss: 0.6667440683247657, Test Accuracy: 61.20%\n",
      "Epoch 862, Loss: 0.527215919042446, Test Loss: 0.6667549678320228, Test Accuracy: 61.20%\n",
      "Epoch 863, Loss: 0.5271485487444991, Test Loss: 0.6667658953426161, Test Accuracy: 61.20%\n",
      "Epoch 864, Loss: 0.527081244564058, Test Loss: 0.6667768508035666, Test Accuracy: 61.20%\n",
      "Epoch 865, Loss: 0.5270140064073435, Test Loss: 0.6667878341619983, Test Accuracy: 61.20%\n",
      "Epoch 866, Loss: 0.5269468341807392, Test Loss: 0.6667988453651367, Test Accuracy: 61.20%\n",
      "Epoch 867, Loss: 0.5268797277907913, Test Loss: 0.6668098843603099, Test Accuracy: 61.20%\n",
      "Epoch 868, Loss: 0.5268126871442087, Test Loss: 0.666820951094947, Test Accuracy: 61.20%\n",
      "Epoch 869, Loss: 0.5267457121478625, Test Loss: 0.6668320455165795, Test Accuracy: 61.20%\n",
      "Epoch 870, Loss: 0.5266788027087855, Test Loss: 0.6668431675728395, Test Accuracy: 61.20%\n",
      "Epoch 871, Loss: 0.5266119587341722, Test Loss: 0.6668543172114604, Test Accuracy: 61.20%\n",
      "Epoch 872, Loss: 0.526545180131378, Test Loss: 0.6668654943802769, Test Accuracy: 61.20%\n",
      "Epoch 873, Loss: 0.5264784668079197, Test Loss: 0.6668766990272236, Test Accuracy: 61.20%\n",
      "Epoch 874, Loss: 0.5264118186714741, Test Loss: 0.6668879311003363, Test Accuracy: 61.20%\n",
      "Epoch 875, Loss: 0.5263452356298789, Test Loss: 0.6668991905477506, Test Accuracy: 61.20%\n",
      "Epoch 876, Loss: 0.5262787175911315, Test Loss: 0.6669104773177027, Test Accuracy: 61.20%\n",
      "Epoch 877, Loss: 0.5262122644633893, Test Loss: 0.6669217913585284, Test Accuracy: 61.20%\n",
      "Epoch 878, Loss: 0.5261458761549684, Test Loss: 0.6669331326186629, Test Accuracy: 61.20%\n",
      "Epoch 879, Loss: 0.5260795525743447, Test Loss: 0.6669445010466413, Test Accuracy: 61.20%\n",
      "Epoch 880, Loss: 0.5260132936301527, Test Loss: 0.666955896591098, Test Accuracy: 61.20%\n",
      "Epoch 881, Loss: 0.5259470992311852, Test Loss: 0.666967319200766, Test Accuracy: 61.20%\n",
      "Epoch 882, Loss: 0.5258809692863932, Test Loss: 0.6669787688244775, Test Accuracy: 61.40%\n",
      "Epoch 883, Loss: 0.525814903704886, Test Loss: 0.6669902454111636, Test Accuracy: 61.40%\n",
      "Epoch 884, Loss: 0.52574890239593, Test Loss: 0.6670017489098533, Test Accuracy: 61.40%\n",
      "Epoch 885, Loss: 0.5256829652689491, Test Loss: 0.6670132792696744, Test Accuracy: 61.40%\n",
      "Epoch 886, Loss: 0.5256170922335242, Test Loss: 0.6670248364398524, Test Accuracy: 61.40%\n",
      "Epoch 887, Loss: 0.5255512831993928, Test Loss: 0.6670364203697108, Test Accuracy: 61.40%\n",
      "Epoch 888, Loss: 0.5254855380764488, Test Loss: 0.6670480310086707, Test Accuracy: 61.40%\n",
      "Epoch 889, Loss: 0.5254198567747422, Test Loss: 0.6670596683062506, Test Accuracy: 61.20%\n",
      "Epoch 890, Loss: 0.5253542392044788, Test Loss: 0.667071332212067, Test Accuracy: 61.20%\n",
      "Epoch 891, Loss: 0.52528868527602, Test Loss: 0.6670830226758322, Test Accuracy: 61.20%\n",
      "Epoch 892, Loss: 0.5252231948998822, Test Loss: 0.6670947396473567, Test Accuracy: 61.20%\n",
      "Epoch 893, Loss: 0.525157767986737, Test Loss: 0.6671064830765462, Test Accuracy: 61.20%\n",
      "Epoch 894, Loss: 0.5250924044474101, Test Loss: 0.6671182529134043, Test Accuracy: 61.20%\n",
      "Epoch 895, Loss: 0.5250271041928821, Test Loss: 0.6671300491080304, Test Accuracy: 61.20%\n",
      "Epoch 896, Loss: 0.5249618671342873, Test Loss: 0.6671418716106197, Test Accuracy: 61.00%\n",
      "Epoch 897, Loss: 0.5248966931829137, Test Loss: 0.6671537203714631, Test Accuracy: 61.00%\n",
      "Epoch 898, Loss: 0.524831582250203, Test Loss: 0.6671655953409482, Test Accuracy: 61.00%\n",
      "Epoch 899, Loss: 0.5247665342477497, Test Loss: 0.6671774964695569, Test Accuracy: 61.00%\n",
      "Epoch 900, Loss: 0.5247015490873013, Test Loss: 0.6671894237078675, Test Accuracy: 61.00%\n",
      "Epoch 901, Loss: 0.524636626680758, Test Loss: 0.6672013770065526, Test Accuracy: 61.00%\n",
      "Epoch 902, Loss: 0.5245717669401719, Test Loss: 0.6672133563163798, Test Accuracy: 61.00%\n",
      "Epoch 903, Loss: 0.5245069697777476, Test Loss: 0.6672253615882122, Test Accuracy: 61.00%\n",
      "Epoch 904, Loss: 0.5244422351058411, Test Loss: 0.6672373927730065, Test Accuracy: 61.00%\n",
      "Epoch 905, Loss: 0.5243775628369596, Test Loss: 0.6672494498218142, Test Accuracy: 61.00%\n",
      "Epoch 906, Loss: 0.5243129528837618, Test Loss: 0.6672615326857809, Test Accuracy: 61.00%\n",
      "Epoch 907, Loss: 0.5242484051590569, Test Loss: 0.6672736413161462, Test Accuracy: 61.00%\n",
      "Epoch 908, Loss: 0.5241839195758048, Test Loss: 0.6672857756642434, Test Accuracy: 61.00%\n",
      "Epoch 909, Loss: 0.5241194960471158, Test Loss: 0.667297935681499, Test Accuracy: 61.00%\n",
      "Epoch 910, Loss: 0.5240551344862499, Test Loss: 0.6673101213194335, Test Accuracy: 61.00%\n",
      "Epoch 911, Loss: 0.5239908348066168, Test Loss: 0.6673223325296606, Test Accuracy: 61.00%\n",
      "Epoch 912, Loss: 0.5239265969217757, Test Loss: 0.6673345692638863, Test Accuracy: 61.00%\n",
      "Epoch 913, Loss: 0.5238624207454349, Test Loss: 0.66734683147391, Test Accuracy: 61.00%\n",
      "Epoch 914, Loss: 0.5237983061914515, Test Loss: 0.6673591191116237, Test Accuracy: 61.00%\n",
      "Epoch 915, Loss: 0.523734253173831, Test Loss: 0.6673714321290118, Test Accuracy: 61.00%\n",
      "Epoch 916, Loss: 0.5236702616067276, Test Loss: 0.6673837704781508, Test Accuracy: 61.00%\n",
      "Epoch 917, Loss: 0.5236063314044428, Test Loss: 0.6673961341112091, Test Accuracy: 61.00%\n",
      "Epoch 918, Loss: 0.5235424624814262, Test Loss: 0.6674085229804475, Test Accuracy: 61.00%\n",
      "Epoch 919, Loss: 0.5234786547522751, Test Loss: 0.6674209370382183, Test Accuracy: 61.00%\n",
      "Epoch 920, Loss: 0.5234149081317333, Test Loss: 0.6674333762369649, Test Accuracy: 61.00%\n",
      "Epoch 921, Loss: 0.5233512225346916, Test Loss: 0.6674458405292223, Test Accuracy: 61.20%\n",
      "Epoch 922, Loss: 0.5232875978761877, Test Loss: 0.6674583298676168, Test Accuracy: 61.20%\n",
      "Epoch 923, Loss: 0.5232240340714056, Test Loss: 0.6674708442048655, Test Accuracy: 61.20%\n",
      "Epoch 924, Loss: 0.5231605310356747, Test Loss: 0.667483383493776, Test Accuracy: 61.20%\n",
      "Epoch 925, Loss: 0.5230970886844708, Test Loss: 0.6674959476872468, Test Accuracy: 61.40%\n",
      "Epoch 926, Loss: 0.5230337069334149, Test Loss: 0.6675085367382668, Test Accuracy: 61.40%\n",
      "Epoch 927, Loss: 0.5229703856982727, Test Loss: 0.6675211505999151, Test Accuracy: 61.40%\n",
      "Epoch 928, Loss: 0.5229071248949559, Test Loss: 0.6675337892253603, Test Accuracy: 61.40%\n",
      "Epoch 929, Loss: 0.5228439244395199, Test Loss: 0.6675464525678616, Test Accuracy: 61.60%\n",
      "Epoch 930, Loss: 0.5227807842481648, Test Loss: 0.6675591405807674, Test Accuracy: 61.60%\n",
      "Epoch 931, Loss: 0.5227177042372343, Test Loss: 0.6675718532175156, Test Accuracy: 61.60%\n",
      "Epoch 932, Loss: 0.5226546843232168, Test Loss: 0.6675845904316334, Test Accuracy: 61.60%\n",
      "Epoch 933, Loss: 0.5225917244227436, Test Loss: 0.6675973521767374, Test Accuracy: 61.60%\n",
      "Epoch 934, Loss: 0.5225288244525892, Test Loss: 0.6676101384065326, Test Accuracy: 61.60%\n",
      "Epoch 935, Loss: 0.5224659843296714, Test Loss: 0.6676229490748133, Test Accuracy: 61.60%\n",
      "Epoch 936, Loss: 0.5224032039710506, Test Loss: 0.6676357841354618, Test Accuracy: 61.60%\n",
      "Epoch 937, Loss: 0.5223404832939291, Test Loss: 0.6676486435424491, Test Accuracy: 61.60%\n",
      "Epoch 938, Loss: 0.5222778222156526, Test Loss: 0.6676615272498347, Test Accuracy: 61.60%\n",
      "Epoch 939, Loss: 0.5222152206537071, Test Loss: 0.6676744352117653, Test Accuracy: 61.60%\n",
      "Epoch 940, Loss: 0.5221526785257217, Test Loss: 0.6676873673824762, Test Accuracy: 61.60%\n",
      "Epoch 941, Loss: 0.5220901957494658, Test Loss: 0.6677003237162901, Test Accuracy: 61.60%\n",
      "Epoch 942, Loss: 0.5220277722428505, Test Loss: 0.6677133041676171, Test Accuracy: 61.80%\n",
      "Epoch 943, Loss: 0.5219654079239272, Test Loss: 0.6677263086909545, Test Accuracy: 61.80%\n",
      "Epoch 944, Loss: 0.5219031027108882, Test Loss: 0.6677393372408874, Test Accuracy: 61.80%\n",
      "Epoch 945, Loss: 0.5218408565220662, Test Loss: 0.667752389772087, Test Accuracy: 61.80%\n",
      "Epoch 946, Loss: 0.5217786692759334, Test Loss: 0.6677654662393114, Test Accuracy: 61.80%\n",
      "Epoch 947, Loss: 0.5217165408911021, Test Loss: 0.6677785665974061, Test Accuracy: 61.80%\n",
      "Epoch 948, Loss: 0.521654471286324, Test Loss: 0.6677916908013021, Test Accuracy: 61.80%\n",
      "Epoch 949, Loss: 0.52159246038049, Test Loss: 0.6678048388060166, Test Accuracy: 61.80%\n",
      "Epoch 950, Loss: 0.5215305080926298, Test Loss: 0.6678180105666539, Test Accuracy: 61.80%\n",
      "Epoch 951, Loss: 0.521468614341912, Test Loss: 0.6678312060384034, Test Accuracy: 61.80%\n",
      "Epoch 952, Loss: 0.5214067790476435, Test Loss: 0.6678444251765404, Test Accuracy: 62.00%\n",
      "Epoch 953, Loss: 0.5213450021292696, Test Loss: 0.6678576679364253, Test Accuracy: 62.00%\n",
      "Epoch 954, Loss: 0.5212832835063728, Test Loss: 0.6678709342735046, Test Accuracy: 62.00%\n",
      "Epoch 955, Loss: 0.5212216230986737, Test Loss: 0.6678842241433097, Test Accuracy: 62.00%\n",
      "Epoch 956, Loss: 0.5211600208260305, Test Loss: 0.6678975375014568, Test Accuracy: 62.00%\n",
      "Epoch 957, Loss: 0.5210984766084379, Test Loss: 0.6679108743036472, Test Accuracy: 62.00%\n",
      "Epoch 958, Loss: 0.5210369903660279, Test Loss: 0.6679242345056668, Test Accuracy: 62.00%\n",
      "Epoch 959, Loss: 0.5209755620190688, Test Loss: 0.6679376180633863, Test Accuracy: 62.00%\n",
      "Epoch 960, Loss: 0.5209141914879655, Test Loss: 0.6679510249327598, Test Accuracy: 62.00%\n",
      "Epoch 961, Loss: 0.5208528786932586, Test Loss: 0.6679644550698269, Test Accuracy: 62.00%\n",
      "Epoch 962, Loss: 0.5207916235556245, Test Loss: 0.66797790843071, Test Accuracy: 62.00%\n",
      "Epoch 963, Loss: 0.5207304259958756, Test Loss: 0.6679913849716157, Test Accuracy: 62.00%\n",
      "Epoch 964, Loss: 0.5206692859349588, Test Loss: 0.6680048846488349, Test Accuracy: 62.00%\n",
      "Epoch 965, Loss: 0.520608203293957, Test Loss: 0.668018407418741, Test Accuracy: 62.00%\n",
      "Epoch 966, Loss: 0.520547177994087, Test Loss: 0.6680319532377911, Test Accuracy: 62.00%\n",
      "Epoch 967, Loss: 0.5204862099567005, Test Loss: 0.6680455220625259, Test Accuracy: 62.00%\n",
      "Epoch 968, Loss: 0.5204252991032833, Test Loss: 0.668059113849568, Test Accuracy: 62.00%\n",
      "Epoch 969, Loss: 0.5203644453554553, Test Loss: 0.6680727285556236, Test Accuracy: 62.00%\n",
      "Epoch 970, Loss: 0.52030364863497, Test Loss: 0.6680863661374815, Test Accuracy: 62.00%\n",
      "Epoch 971, Loss: 0.5202429088637147, Test Loss: 0.6681000265520127, Test Accuracy: 62.00%\n",
      "Epoch 972, Loss: 0.5201822259637094, Test Loss: 0.6681137097561707, Test Accuracy: 62.00%\n",
      "Epoch 973, Loss: 0.5201215998571075, Test Loss: 0.6681274157069907, Test Accuracy: 62.00%\n",
      "Epoch 974, Loss: 0.5200610304661949, Test Loss: 0.6681411443615908, Test Accuracy: 62.00%\n",
      "Epoch 975, Loss: 0.52000051771339, Test Loss: 0.6681548956771695, Test Accuracy: 62.00%\n",
      "Epoch 976, Loss: 0.5199400615212435, Test Loss: 0.6681686696110078, Test Accuracy: 62.00%\n",
      "Epoch 977, Loss: 0.5198796618124379, Test Loss: 0.6681824661204685, Test Accuracy: 62.00%\n",
      "Epoch 978, Loss: 0.5198193185097876, Test Loss: 0.668196285162995, Test Accuracy: 62.00%\n",
      "Epoch 979, Loss: 0.5197590315362381, Test Loss: 0.6682101266961119, Test Accuracy: 62.00%\n",
      "Epoch 980, Loss: 0.5196988008148667, Test Loss: 0.6682239906774249, Test Accuracy: 62.00%\n",
      "Epoch 981, Loss: 0.5196386262688812, Test Loss: 0.6682378770646207, Test Accuracy: 62.00%\n",
      "Epoch 982, Loss: 0.51957850782162, Test Loss: 0.6682517858154661, Test Accuracy: 62.00%\n",
      "Epoch 983, Loss: 0.5195184453965521, Test Loss: 0.668265716887809, Test Accuracy: 62.00%\n",
      "Epoch 984, Loss: 0.5194584389172772, Test Loss: 0.6682796702395772, Test Accuracy: 62.00%\n",
      "Epoch 985, Loss: 0.519398488307524, Test Loss: 0.6682936458287786, Test Accuracy: 62.00%\n",
      "Epoch 986, Loss: 0.5193385934911516, Test Loss: 0.6683076436135013, Test Accuracy: 62.00%\n",
      "Epoch 987, Loss: 0.5192787543921483, Test Loss: 0.6683216635519131, Test Accuracy: 62.00%\n",
      "Epoch 988, Loss: 0.5192189709346321, Test Loss: 0.6683357056022615, Test Accuracy: 62.00%\n",
      "Epoch 989, Loss: 0.519159243042849, Test Loss: 0.6683497697228734, Test Accuracy: 62.00%\n",
      "Epoch 990, Loss: 0.5190995706411747, Test Loss: 0.6683638558721551, Test Accuracy: 62.00%\n",
      "Epoch 991, Loss: 0.5190399536541126, Test Loss: 0.668377964008592, Test Accuracy: 62.00%\n",
      "Epoch 992, Loss: 0.5189803920062949, Test Loss: 0.6683920940907486, Test Accuracy: 62.00%\n",
      "Epoch 993, Loss: 0.5189208856224815, Test Loss: 0.668406246077268, Test Accuracy: 62.00%\n",
      "Epoch 994, Loss: 0.5188614344275603, Test Loss: 0.6684204199268722, Test Accuracy: 62.00%\n",
      "Epoch 995, Loss: 0.518802038346546, Test Loss: 0.6684346155983619, Test Accuracy: 62.00%\n",
      "Epoch 996, Loss: 0.5187426973045817, Test Loss: 0.6684488330506158, Test Accuracy: 62.00%\n",
      "Epoch 997, Loss: 0.5186834112269365, Test Loss: 0.6684630722425907, Test Accuracy: 62.00%\n",
      "Epoch 998, Loss: 0.5186241800390067, Test Loss: 0.668477333133322, Test Accuracy: 62.00%\n",
      "Epoch 999, Loss: 0.518565003666315, Test Loss: 0.6684916156819227, Test Accuracy: 62.00%\n",
      "Final Loss: 0.518565003666315, Test Loss: 0.6684916156819227, Test Accuracy: 62.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# x: data_amount x features\n",
    "# y: data_amount x 1\n",
    "# alpha: learning rate\n",
    "def train(X, y, iterations=100, learning_rate=0.01, r_lambda=0.001):\n",
    "    # inital weights, 0s\n",
    "    # weights = np.random.rand(num_features)\n",
    "    weights = np.zeros((num_features))\n",
    "    # weights = np.random.uniform(-0.025, 0.025, num_features)\n",
    "    loss_history = []\n",
    "    test_loss_history = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # predictions from model\n",
    "        \n",
    "        # compute loss\n",
    "        loss = BCE_loss_fn(X, y, weights, r_lambda)\n",
    "        \n",
    "        # compute gradients\n",
    "        gradient = compute_gradient(X, y, weights, r_lambda)\n",
    "        # gradient = compute_gradient_SGD(X, y, weights, random.randint(0, len(y) - 1), 0.1)\n",
    "        \n",
    "        # update weights\n",
    "        weights -= learning_rate * gradient\n",
    "        # testing on test dataset\n",
    "        test_predictions = f(X_test, weights)\n",
    "        test_loss = BCE_loss_fn(X_test, y_test, weights, r_lambda)\n",
    "        test_acc = accuracy(test_predictions, y_test)\n",
    "                \n",
    "        # print iteration\n",
    "        print(f'Epoch {i}, Loss: {loss}, Test Loss: {test_loss}, Test Accuracy: {test_acc*100:.2f}%')\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            loss_history.append(loss)\n",
    "            test_loss_history.append(test_loss)\n",
    "    \n",
    "    \n",
    "    print(f'Final Loss: {loss}, Test Loss: {test_loss}, Test Accuracy: {test_acc*100:.2f}%')\n",
    "    return weights, loss_history, test_loss_history\n",
    "\n",
    "trained_weights, loss_history, test_loss_history = train(X_train, y_train, 1000, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "id": "135927d8-d3ca-4bd7-a863-60c5e1591754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels, threshold=0.5):\n",
    "    correct_predictions = 0\n",
    "    for i in range(len(predictions)):\n",
    "        pred = 1 if predictions[i] >= 0.5 else 0\n",
    "        if round(predictions[i]) == labels[i]:\n",
    "            correct_predictions += 1\n",
    "    accuracy = correct_predictions / len(labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "74e05ec9-3413-4b22-93ab-ef5d3f9fe71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(0, len(loss_history[5:])) * 10, loss_history[5:], c='red', label='Train Loss')\n",
    "plt.scatter(np.arange(0, len(test_loss_history[5:])) * 10, test_loss_history[5:], c='blue', label='Test Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')  # Replace with your x-axis label\n",
    "plt.ylabel('Loss')  # Replace with your y-axis label\n",
    "plt.title('Loss History Overtime')  # Replace with your graph title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "daa3dbe5-59ec-43fa-a5ed-85a1278d321a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_batches(X, y, batch_size=10):\n",
    "    indexes = np.arange(0, len(X))\n",
    "\n",
    "    random.shuffle(indexes)\n",
    "\n",
    "    batch_Xs = []\n",
    "    batch_ys = []\n",
    "    \n",
    "    # print(\"# of batches: \", len(X) / batch_size)\n",
    "    for i in range(int(len(X) / batch_size)):\n",
    "        batch_indexes = indexes[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        batch_X = X[batch_indexes]\n",
    "        batch_Xs.append(batch_X)\n",
    "        \n",
    "        batch_y = y[batch_indexes]\n",
    "        batch_ys.append(batch_y)\n",
    "        \n",
    "    return batch_Xs, batch_ys\n",
    "        \n",
    "# batch_X, batch_y = get_batches(X_train, y_train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "83015b3b-92e7-4ea0-bc84-a4c96ed55b7f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931471805599452, Test Loss: 0.6664195893871218, Train Accuracy: 63.39%, Test Accuracy: 61.50%\n",
      "Epoch 1, Loss: 0.6486483459219123, Test Loss: 0.6672711596401271, Train Accuracy: 63.39%, Test Accuracy: 61.50%\n",
      "Epoch 2, Loss: 0.6414218007485603, Test Loss: 0.6683667618571443, Train Accuracy: 63.39%, Test Accuracy: 61.50%\n",
      "Epoch 3, Loss: 0.6359525230967479, Test Loss: 0.6697421888169945, Train Accuracy: 63.33%, Test Accuracy: 61.00%\n",
      "Epoch 4, Loss: 0.631537831735545, Test Loss: 0.6713266485872518, Train Accuracy: 63.17%, Test Accuracy: 61.00%\n",
      "Epoch 5, Loss: 0.6279257720828062, Test Loss: 0.673031095634268, Train Accuracy: 62.78%, Test Accuracy: 61.50%\n",
      "Epoch 6, Loss: 0.6249328983351643, Test Loss: 0.6747875719174701, Train Accuracy: 62.28%, Test Accuracy: 61.50%\n",
      "Epoch 7, Loss: 0.6224216351500604, Test Loss: 0.6765484023386672, Train Accuracy: 61.89%, Test Accuracy: 60.50%\n",
      "Epoch 8, Loss: 0.6202882012095291, Test Loss: 0.6782810809884193, Train Accuracy: 62.22%, Test Accuracy: 59.50%\n",
      "Epoch 9, Loss: 0.6184537511059369, Test Loss: 0.6799639782487955, Train Accuracy: 61.78%, Test Accuracy: 59.00%\n",
      "Epoch 10, Loss: 0.6168578998436962, Test Loss: 0.6815831933908884, Train Accuracy: 59.44%, Test Accuracy: 60.00%\n",
      "Epoch 11, Loss: 0.6154540074063205, Test Loss: 0.6831303006767775, Train Accuracy: 61.22%, Test Accuracy: 60.50%\n",
      "Epoch 12, Loss: 0.6142057410690032, Test Loss: 0.6846007400908385, Train Accuracy: 61.44%, Test Accuracy: 60.50%\n",
      "Epoch 13, Loss: 0.613084558806435, Test Loss: 0.6859926666268765, Train Accuracy: 59.11%, Test Accuracy: 60.50%\n",
      "Epoch 14, Loss: 0.6120678559853893, Test Loss: 0.6873061255581373, Train Accuracy: 61.44%, Test Accuracy: 60.50%\n",
      "Epoch 15, Loss: 0.6111375908782487, Test Loss: 0.6885424601138382, Train Accuracy: 60.06%, Test Accuracy: 60.50%\n",
      "Epoch 16, Loss: 0.6102792574562486, Test Loss: 0.6897038855022083, Train Accuracy: 59.83%, Test Accuracy: 60.00%\n",
      "Epoch 17, Loss: 0.6094811115867764, Test Loss: 0.6907931824972491, Train Accuracy: 60.72%, Test Accuracy: 59.50%\n",
      "Epoch 18, Loss: 0.6087335834128192, Test Loss: 0.6918134773132829, Train Accuracy: 58.78%, Test Accuracy: 59.00%\n",
      "Epoch 19, Loss: 0.6080288275364314, Test Loss: 0.6927680839831086, Train Accuracy: 59.94%, Test Accuracy: 59.00%\n",
      "Epoch 20, Loss: 0.6073603759780275, Test Loss: 0.6936603921544712, Train Accuracy: 59.89%, Test Accuracy: 59.50%\n",
      "Epoch 21, Loss: 0.6067228683788976, Test Loss: 0.6944937879709469, Train Accuracy: 59.17%, Test Accuracy: 60.50%\n",
      "Epoch 22, Loss: 0.606111840703793, Test Loss: 0.6952715990913704, Train Accuracy: 58.89%, Test Accuracy: 60.50%\n",
      "Epoch 23, Loss: 0.6055235585841972, Test Loss: 0.6959970573308385, Train Accuracy: 58.22%, Test Accuracy: 59.50%\n",
      "Epoch 24, Loss: 0.6049548849787548, Test Loss: 0.6966732741569683, Train Accuracy: 61.44%, Test Accuracy: 59.50%\n",
      "Epoch 25, Loss: 0.604403174404742, Test Loss: 0.6973032255434191, Train Accuracy: 58.56%, Test Accuracy: 59.50%\n",
      "Epoch 26, Loss: 0.6038661878862533, Test Loss: 0.697889743606115, Train Accuracy: 60.78%, Test Accuracy: 59.50%\n",
      "Epoch 27, Loss: 0.6033420241631009, Test Loss: 0.6984355131230433, Train Accuracy: 58.72%, Test Accuracy: 58.50%\n",
      "Epoch 28, Loss: 0.6028290637451611, Test Loss: 0.698943071534677, Train Accuracy: 59.67%, Test Accuracy: 58.50%\n",
      "Epoch 29, Loss: 0.6023259231768965, Test Loss: 0.6994148113879719, Train Accuracy: 59.22%, Test Accuracy: 58.00%\n",
      "Epoch 30, Loss: 0.6018314174653064, Test Loss: 0.6998529844576521, Train Accuracy: 60.11%, Test Accuracy: 58.00%\n",
      "Epoch 31, Loss: 0.6013445290715892, Test Loss: 0.7002597069794825, Train Accuracy: 59.22%, Test Accuracy: 58.00%\n",
      "Epoch 32, Loss: 0.6008643822085562, Test Loss: 0.7006369655797594, Train Accuracy: 58.72%, Test Accuracy: 57.50%\n",
      "Epoch 33, Loss: 0.6003902214487821, Test Loss: 0.7009866235967402, Train Accuracy: 57.61%, Test Accuracy: 57.00%\n",
      "Epoch 34, Loss: 0.5999213938520075, Test Loss: 0.7013104275729574, Train Accuracy: 61.00%, Test Accuracy: 57.00%\n",
      "Epoch 35, Loss: 0.5994573339788178, Test Loss: 0.7016100137595163, Train Accuracy: 60.50%, Test Accuracy: 56.50%\n",
      "Epoch 36, Loss: 0.5989975512817595, Test Loss: 0.7018869145199003, Train Accuracy: 58.61%, Test Accuracy: 56.50%\n",
      "Epoch 37, Loss: 0.5985416194628225, Test Loss: 0.702142564555426, Train Accuracy: 59.22%, Test Accuracy: 56.50%\n",
      "Epoch 38, Loss: 0.5980891674636397, Test Loss: 0.7023783069002547, Train Accuracy: 57.89%, Test Accuracy: 57.00%\n",
      "Epoch 39, Loss: 0.59763987181636, Test Loss: 0.7025953986529702, Train Accuracy: 59.67%, Test Accuracy: 57.00%\n",
      "Epoch 40, Loss: 0.5971934501324446, Test Loss: 0.7027950164258076, Train Accuracy: 59.56%, Test Accuracy: 57.00%\n",
      "Epoch 41, Loss: 0.5967496555462375, Test Loss: 0.7029782615029309, Train Accuracy: 60.06%, Test Accuracy: 57.00%\n",
      "Epoch 42, Loss: 0.5963082719621411, Test Loss: 0.7031461647065987, Train Accuracy: 60.61%, Test Accuracy: 56.50%\n",
      "Epoch 43, Loss: 0.5958691099801657, Test Loss: 0.7032996909753753, Train Accuracy: 58.11%, Test Accuracy: 56.50%\n",
      "Epoch 44, Loss: 0.5954320033957244, Test Loss: 0.7034397436622396, Train Accuracy: 58.61%, Test Accuracy: 56.50%\n",
      "Epoch 45, Loss: 0.5949968061868282, Test Loss: 0.7035671685629394, Train Accuracy: 58.33%, Test Accuracy: 56.50%\n",
      "Epoch 46, Loss: 0.5945633899159908, Test Loss: 0.7036827576865275, Train Accuracy: 58.67%, Test Accuracy: 56.50%\n",
      "Epoch 47, Loss: 0.5941316414858382, Test Loss: 0.7037872527809447, Train Accuracy: 59.28%, Test Accuracy: 56.50%\n",
      "Epoch 48, Loss: 0.5937014611970609, Test Loss: 0.7038813486269501, Train Accuracy: 59.89%, Test Accuracy: 56.50%\n",
      "Epoch 49, Loss: 0.593272761065358, Test Loss: 0.7039656961137737, Train Accuracy: 58.78%, Test Accuracy: 56.50%\n",
      "Epoch 50, Loss: 0.5928454633606786, Test Loss: 0.704040905109691, Train Accuracy: 59.78%, Test Accuracy: 57.00%\n",
      "Epoch 51, Loss: 0.592419499337635, Test Loss: 0.7041075471403662, Train Accuracy: 57.28%, Test Accuracy: 57.00%\n",
      "Epoch 52, Loss: 0.5919948081306066, Test Loss: 0.7041661578873277, Train Accuracy: 59.06%, Test Accuracy: 57.00%\n",
      "Epoch 53, Loss: 0.591571335790973, Test Loss: 0.7042172395183968, Train Accuracy: 58.72%, Test Accuracy: 57.00%\n",
      "Epoch 54, Loss: 0.5911490344472011, Test Loss: 0.704261262861271, Train Accuracy: 57.17%, Test Accuracy: 57.00%\n",
      "Epoch 55, Loss: 0.5907278615712834, Test Loss: 0.7042986694308669, Train Accuracy: 58.39%, Test Accuracy: 57.00%\n",
      "Epoch 56, Loss: 0.5903077793373862, Test Loss: 0.7043298733203806, Train Accuracy: 58.56%, Test Accuracy: 57.00%\n",
      "Epoch 57, Loss: 0.5898887540605435, Test Loss: 0.7043552629654155, Train Accuracy: 57.00%, Test Accuracy: 57.00%\n",
      "Epoch 58, Loss: 0.5894707557049426, Test Loss: 0.7043752027899302, Train Accuracy: 59.17%, Test Accuracy: 57.00%\n",
      "Epoch 59, Loss: 0.5890537574527778, Test Loss: 0.7043900347421634, Train Accuracy: 58.72%, Test Accuracy: 57.50%\n",
      "Epoch 60, Loss: 0.5886377353258836, Test Loss: 0.7044000797281673, Train Accuracy: 58.00%, Test Accuracy: 57.50%\n",
      "Epoch 61, Loss: 0.5882226678534173, Test Loss: 0.7044056389500284, Train Accuracy: 58.39%, Test Accuracy: 57.50%\n",
      "Epoch 62, Loss: 0.5878085357797526, Test Loss: 0.7044069951553871, Train Accuracy: 59.11%, Test Accuracy: 57.50%\n",
      "Epoch 63, Loss: 0.5873953218075326, Test Loss: 0.7044044138043839, Train Accuracy: 58.39%, Test Accuracy: 57.50%\n",
      "Epoch 64, Loss: 0.5869830103714847, Test Loss: 0.7043981441597384, Train Accuracy: 58.50%, Test Accuracy: 57.50%\n",
      "Epoch 65, Loss: 0.5865715874391827, Test Loss: 0.704388420305256, Train Accuracy: 57.28%, Test Accuracy: 57.50%\n",
      "Epoch 66, Loss: 0.5861610403354315, Test Loss: 0.7043754620976804, Train Accuracy: 58.61%, Test Accuracy: 57.50%\n",
      "Epoch 67, Loss: 0.5857513575873777, Test Loss: 0.7043594760564639, Train Accuracy: 57.22%, Test Accuracy: 57.50%\n",
      "Epoch 68, Loss: 0.5853425287878178, Test Loss: 0.7043406561956874, Train Accuracy: 59.00%, Test Accuracy: 57.50%\n",
      "Epoch 69, Loss: 0.5849345444745014, Test Loss: 0.7043191848020797, Train Accuracy: 58.00%, Test Accuracy: 57.50%\n",
      "Epoch 70, Loss: 0.5845273960234972, Test Loss: 0.7042952331627823, Train Accuracy: 57.67%, Test Accuracy: 57.50%\n",
      "Epoch 71, Loss: 0.5841210755549358, Test Loss: 0.7042689622462643, Train Accuracy: 58.17%, Test Accuracy: 57.50%\n",
      "Epoch 72, Loss: 0.58371557584965, Test Loss: 0.7042405233395367, Train Accuracy: 58.44%, Test Accuracy: 57.50%\n",
      "Epoch 73, Loss: 0.5833108902754199, Test Loss: 0.704210058644604, Train Accuracy: 58.11%, Test Accuracy: 57.50%\n",
      "Epoch 74, Loss: 0.5829070127216854, Test Loss: 0.7041777018368705, Train Accuracy: 58.83%, Test Accuracy: 57.00%\n",
      "Epoch 75, Loss: 0.5825039375417251, Test Loss: 0.7041435785880421, Train Accuracy: 58.33%, Test Accuracy: 57.00%\n",
      "Epoch 76, Loss: 0.5821016595014339, Test Loss: 0.7041078070558728, Train Accuracy: 56.83%, Test Accuracy: 57.00%\n",
      "Epoch 77, Loss: 0.5817001737339182, Test Loss: 0.7040704983429511, Train Accuracy: 58.22%, Test Accuracy: 57.00%\n",
      "Epoch 78, Loss: 0.5812994756992415, Test Loss: 0.7040317569265622, Train Accuracy: 59.28%, Test Accuracy: 57.00%\n",
      "Epoch 79, Loss: 0.5808995611487143, Test Loss: 0.7039916810615264, Train Accuracy: 57.83%, Test Accuracy: 56.50%\n",
      "Epoch 80, Loss: 0.5805004260932111, Test Loss: 0.7039503631577787, Train Accuracy: 58.61%, Test Accuracy: 56.50%\n",
      "Epoch 81, Loss: 0.5801020667750441, Test Loss: 0.7039078901343356, Train Accuracy: 58.61%, Test Accuracy: 56.50%\n",
      "Epoch 82, Loss: 0.5797044796429913, Test Loss: 0.7038643437511811, Train Accuracy: 58.33%, Test Accuracy: 56.50%\n",
      "Epoch 83, Loss: 0.5793076613301134, Test Loss: 0.7038198009205042, Train Accuracy: 58.67%, Test Accuracy: 56.50%\n",
      "Epoch 84, Loss: 0.5789116086340447, Test Loss: 0.703774333998615, Train Accuracy: 59.89%, Test Accuracy: 56.50%\n",
      "Epoch 85, Loss: 0.5785163184994757, Test Loss: 0.7037280110597846, Train Accuracy: 58.94%, Test Accuracy: 56.50%\n",
      "Epoch 86, Loss: 0.5781217880025793, Test Loss: 0.7036808961531673, Train Accuracy: 57.28%, Test Accuracy: 56.50%\n",
      "Epoch 87, Loss: 0.5777280143371591, Test Loss: 0.7036330495438855, Train Accuracy: 57.44%, Test Accuracy: 56.50%\n",
      "Epoch 88, Loss: 0.5773349948023297, Test Loss: 0.7035845279392836, Train Accuracy: 60.39%, Test Accuracy: 56.50%\n",
      "Epoch 89, Loss: 0.5769427267915525, Test Loss: 0.7035353847012997, Train Accuracy: 59.00%, Test Accuracy: 56.50%\n",
      "Epoch 90, Loss: 0.5765512077828774, Test Loss: 0.7034856700458273, Train Accuracy: 59.44%, Test Accuracy: 56.50%\n",
      "Epoch 91, Loss: 0.5761604353302553, Test Loss: 0.7034354312298935, Train Accuracy: 57.00%, Test Accuracy: 56.50%\n",
      "Epoch 92, Loss: 0.5757704070558018, Test Loss: 0.7033847127274194, Train Accuracy: 59.61%, Test Accuracy: 56.50%\n",
      "Epoch 93, Loss: 0.5753811206429057, Test Loss: 0.7033335563942813, Train Accuracy: 58.83%, Test Accuracy: 56.50%\n",
      "Epoch 94, Loss: 0.5749925738300885, Test Loss: 0.7032820016233421, Train Accuracy: 57.72%, Test Accuracy: 56.50%\n",
      "Epoch 95, Loss: 0.5746047644055341, Test Loss: 0.7032300854900817, Train Accuracy: 58.67%, Test Accuracy: 57.00%\n",
      "Epoch 96, Loss: 0.5742176902022095, Test Loss: 0.7031778428894109, Train Accuracy: 58.06%, Test Accuracy: 57.00%\n",
      "Epoch 97, Loss: 0.5738313490935174, Test Loss: 0.7031253066642205, Train Accuracy: 59.00%, Test Accuracy: 57.00%\n",
      "Epoch 98, Loss: 0.5734457389894176, Test Loss: 0.7030725077261748, Train Accuracy: 58.06%, Test Accuracy: 57.00%\n",
      "Epoch 99, Loss: 0.5730608578329677, Test Loss: 0.7030194751692338, Train Accuracy: 57.94%, Test Accuracy: 57.00%\n",
      "Epoch 100, Loss: 0.5726767035972359, Test Loss: 0.7029662363763519, Train Accuracy: 59.17%, Test Accuracy: 57.00%\n",
      "Epoch 101, Loss: 0.5722932742825478, Test Loss: 0.7029128171197735, Train Accuracy: 57.94%, Test Accuracy: 57.00%\n",
      "Epoch 102, Loss: 0.5719105679140274, Test Loss: 0.7028592416553208, Train Accuracy: 57.11%, Test Accuracy: 57.00%\n",
      "Epoch 103, Loss: 0.5715285825394022, Test Loss: 0.7028055328110437, Train Accuracy: 58.89%, Test Accuracy: 57.00%\n",
      "Epoch 104, Loss: 0.5711473162270424, Test Loss: 0.7027517120705755, Train Accuracy: 59.00%, Test Accuracy: 57.00%\n",
      "Epoch 105, Loss: 0.570766767064212, Test Loss: 0.7026977996515182, Train Accuracy: 58.06%, Test Accuracy: 57.00%\n",
      "Epoch 106, Loss: 0.5703869331555037, Test Loss: 0.7026438145791665, Train Accuracy: 58.22%, Test Accuracy: 57.00%\n",
      "Epoch 107, Loss: 0.5700078126214407, Test Loss: 0.7025897747558443, Train Accuracy: 58.22%, Test Accuracy: 57.00%\n",
      "Epoch 108, Loss: 0.5696294035972304, Test Loss: 0.7025356970261334, Train Accuracy: 59.28%, Test Accuracy: 57.00%\n",
      "Epoch 109, Loss: 0.5692517042316445, Test Loss: 0.7024815972382322, Train Accuracy: 58.83%, Test Accuracy: 57.00%\n",
      "Epoch 110, Loss: 0.5688747126860235, Test Loss: 0.7024274903016888, Train Accuracy: 57.78%, Test Accuracy: 57.00%\n",
      "Epoch 111, Loss: 0.5684984271333826, Test Loss: 0.7023733902417194, Train Accuracy: 58.44%, Test Accuracy: 57.00%\n",
      "Epoch 112, Loss: 0.5681228457576132, Test Loss: 0.7023193102503265, Train Accuracy: 58.33%, Test Accuracy: 57.00%\n",
      "Epoch 113, Loss: 0.5677479667527686, Test Loss: 0.7022652627344046, Train Accuracy: 58.72%, Test Accuracy: 57.00%\n",
      "Epoch 114, Loss: 0.5673737883224242, Test Loss: 0.7022112593610145, Train Accuracy: 60.33%, Test Accuracy: 57.00%\n",
      "Epoch 115, Loss: 0.5670003086791057, Test Loss: 0.7021573111000028, Train Accuracy: 59.67%, Test Accuracy: 57.00%\n",
      "Epoch 116, Loss: 0.5666275260437758, Test Loss: 0.7021034282641176, Train Accuracy: 58.44%, Test Accuracy: 57.00%\n",
      "Epoch 117, Loss: 0.5662554386453755, Test Loss: 0.7020496205467767, Train Accuracy: 58.06%, Test Accuracy: 57.00%\n",
      "Epoch 118, Loss: 0.5658840447204135, Test Loss: 0.7019958970576263, Train Accuracy: 58.33%, Test Accuracy: 57.00%\n",
      "Epoch 119, Loss: 0.5655133425125967, Test Loss: 0.7019422663560229, Train Accuracy: 59.33%, Test Accuracy: 57.00%\n",
      "Epoch 120, Loss: 0.5651433302725006, Test Loss: 0.7018887364825604, Train Accuracy: 58.33%, Test Accuracy: 57.00%\n",
      "Epoch 121, Loss: 0.5647740062572738, Test Loss: 0.7018353149887644, Train Accuracy: 59.44%, Test Accuracy: 57.00%\n",
      "Epoch 122, Loss: 0.5644053687303708, Test Loss: 0.7017820089650538, Train Accuracy: 58.17%, Test Accuracy: 57.00%\n",
      "Epoch 123, Loss: 0.5640374159613155, Test Loss: 0.7017288250670835, Train Accuracy: 59.33%, Test Accuracy: 57.00%\n",
      "Epoch 124, Loss: 0.5636701462254865, Test Loss: 0.7016757695405528, Train Accuracy: 59.44%, Test Accuracy: 57.00%\n",
      "Epoch 125, Loss: 0.5633035578039253, Test Loss: 0.7016228482445814, Train Accuracy: 58.22%, Test Accuracy: 57.50%\n",
      "Epoch 126, Loss: 0.5629376489831642, Test Loss: 0.7015700666737288, Train Accuracy: 58.44%, Test Accuracy: 57.50%\n",
      "Epoch 127, Loss: 0.5625724180550716, Test Loss: 0.7015174299787427, Train Accuracy: 57.11%, Test Accuracy: 57.50%\n",
      "Epoch 128, Loss: 0.5622078633167118, Test Loss: 0.7014649429861086, Train Accuracy: 58.00%, Test Accuracy: 57.50%\n",
      "Epoch 129, Loss: 0.5618439830702209, Test Loss: 0.7014126102164738, Train Accuracy: 58.83%, Test Accuracy: 57.50%\n",
      "Epoch 130, Loss: 0.561480775622694, Test Loss: 0.7013604359020087, Train Accuracy: 57.17%, Test Accuracy: 58.00%\n",
      "Epoch 131, Loss: 0.5611182392860836, Test Loss: 0.7013084240027702, Train Accuracy: 59.72%, Test Accuracy: 58.00%\n",
      "Epoch 132, Loss: 0.560756372377108, Test Loss: 0.7012565782221265, Train Accuracy: 58.56%, Test Accuracy: 58.00%\n",
      "Epoch 133, Loss: 0.5603951732171697, Test Loss: 0.7012049020212942, Train Accuracy: 58.39%, Test Accuracy: 57.50%\n",
      "Epoch 134, Loss: 0.5600346401322807, Test Loss: 0.7011533986330448, Train Accuracy: 59.50%, Test Accuracy: 57.50%\n",
      "Epoch 135, Loss: 0.5596747714529955, Test Loss: 0.7011020710746265, Train Accuracy: 57.94%, Test Accuracy: 57.50%\n",
      "Epoch 136, Loss: 0.5593155655143512, Test Loss: 0.7010509221599449, Train Accuracy: 58.72%, Test Accuracy: 57.50%\n",
      "Epoch 137, Loss: 0.558957020655812, Test Loss: 0.7009999545110515, Train Accuracy: 58.50%, Test Accuracy: 57.50%\n",
      "Epoch 138, Loss: 0.55859913522122, Test Loss: 0.7009491705689748, Train Accuracy: 57.56%, Test Accuracy: 57.50%\n",
      "Epoch 139, Loss: 0.5582419075587506, Test Loss: 0.7008985726039354, Train Accuracy: 58.94%, Test Accuracy: 57.50%\n",
      "Epoch 140, Loss: 0.5578853360208713, Test Loss: 0.7008481627249793, Train Accuracy: 57.94%, Test Accuracy: 58.00%\n",
      "Epoch 141, Loss: 0.5575294189643059, Test Loss: 0.7007979428890644, Train Accuracy: 56.39%, Test Accuracy: 57.50%\n",
      "Epoch 142, Loss: 0.5571741547499991, Test Loss: 0.7007479149096304, Train Accuracy: 58.56%, Test Accuracy: 57.50%\n",
      "Epoch 143, Loss: 0.556819541743088, Test Loss: 0.7006980804646831, Train Accuracy: 59.28%, Test Accuracy: 57.50%\n",
      "Epoch 144, Loss: 0.5564655783128727, Test Loss: 0.7006484411044218, Train Accuracy: 58.22%, Test Accuracy: 57.50%\n",
      "Epoch 145, Loss: 0.5561122628327915, Test Loss: 0.7005989982584331, Train Accuracy: 57.83%, Test Accuracy: 57.50%\n",
      "Epoch 146, Loss: 0.5557595936803976, Test Loss: 0.7005497532424796, Train Accuracy: 57.94%, Test Accuracy: 57.50%\n",
      "Epoch 147, Loss: 0.5554075692373379, Test Loss: 0.7005007072649062, Train Accuracy: 57.39%, Test Accuracy: 57.50%\n",
      "Epoch 148, Loss: 0.5550561878893328, Test Loss: 0.7004518614326823, Train Accuracy: 57.61%, Test Accuracy: 57.50%\n",
      "Epoch 149, Loss: 0.554705448026159, Test Loss: 0.700403216757107, Train Accuracy: 57.28%, Test Accuracy: 57.50%\n",
      "Epoch 150, Loss: 0.554355348041632, Test Loss: 0.700354774159191, Train Accuracy: 57.28%, Test Accuracy: 57.50%\n",
      "Epoch 151, Loss: 0.5540058863335916, Test Loss: 0.7003065344747367, Train Accuracy: 58.83%, Test Accuracy: 57.50%\n",
      "Epoch 152, Loss: 0.5536570613038867, Test Loss: 0.7002584984591338, Train Accuracy: 58.06%, Test Accuracy: 57.50%\n",
      "Epoch 153, Loss: 0.5533088713583629, Test Loss: 0.7002106667918845, Train Accuracy: 57.67%, Test Accuracy: 57.50%\n",
      "Epoch 154, Loss: 0.5529613149068495, Test Loss: 0.7001630400808765, Train Accuracy: 58.33%, Test Accuracy: 57.50%\n",
      "Epoch 155, Loss: 0.5526143903631481, Test Loss: 0.7001156188664156, Train Accuracy: 58.06%, Test Accuracy: 57.50%\n",
      "Epoch 156, Loss: 0.5522680961450218, Test Loss: 0.700068403625035, Train Accuracy: 59.61%, Test Accuracy: 57.50%\n",
      "Epoch 157, Loss: 0.5519224306741852, Test Loss: 0.7000213947730884, Train Accuracy: 57.06%, Test Accuracy: 57.50%\n",
      "Epoch 158, Loss: 0.5515773923762943, Test Loss: 0.6999745926701464, Train Accuracy: 59.50%, Test Accuracy: 57.50%\n",
      "Epoch 159, Loss: 0.5512329796809378, Test Loss: 0.6999279976222003, Train Accuracy: 57.28%, Test Accuracy: 57.50%\n",
      "Epoch 160, Loss: 0.5508891910216281, Test Loss: 0.69988160988469, Train Accuracy: 59.11%, Test Accuracy: 57.50%\n",
      "Epoch 161, Loss: 0.5505460248357933, Test Loss: 0.6998354296653616, Train Accuracy: 58.50%, Test Accuracy: 57.50%\n",
      "Epoch 162, Loss: 0.5502034795647691, Test Loss: 0.6997894571269679, Train Accuracy: 58.50%, Test Accuracy: 57.50%\n",
      "Epoch 163, Loss: 0.5498615536537913, Test Loss: 0.6997436923898173, Train Accuracy: 58.39%, Test Accuracy: 57.50%\n",
      "Epoch 164, Loss: 0.5495202455519885, Test Loss: 0.6996981355341823, Train Accuracy: 58.67%, Test Accuracy: 57.50%\n",
      "Epoch 165, Loss: 0.5491795537123754, Test Loss: 0.6996527866025738, Train Accuracy: 60.33%, Test Accuracy: 57.50%\n",
      "Epoch 166, Loss: 0.5488394765918453, Test Loss: 0.6996076456018916, Train Accuracy: 58.61%, Test Accuracy: 57.50%\n",
      "Epoch 167, Loss: 0.548500012651164, Test Loss: 0.6995627125054523, Train Accuracy: 60.33%, Test Accuracy: 57.50%\n",
      "Epoch 168, Loss: 0.5481611603549632, Test Loss: 0.699517987254908, Train Accuracy: 58.39%, Test Accuracy: 57.50%\n",
      "Epoch 169, Loss: 0.5478229181717343, Test Loss: 0.6994734697620586, Train Accuracy: 58.33%, Test Accuracy: 57.50%\n",
      "Epoch 170, Loss: 0.5474852845738222, Test Loss: 0.6994291599105631, Train Accuracy: 58.22%, Test Accuracy: 57.50%\n",
      "Epoch 171, Loss: 0.5471482580374191, Test Loss: 0.6993850575575574, Train Accuracy: 57.50%, Test Accuracy: 57.50%\n",
      "Epoch 172, Loss: 0.5468118370425588, Test Loss: 0.6993411625351826, Train Accuracy: 57.39%, Test Accuracy: 57.50%\n",
      "Epoch 173, Loss: 0.5464760200731109, Test Loss: 0.6992974746520304, Train Accuracy: 57.39%, Test Accuracy: 57.50%\n",
      "Epoch 174, Loss: 0.5461408056167749, Test Loss: 0.6992539936945061, Train Accuracy: 59.28%, Test Accuracy: 57.50%\n",
      "Epoch 175, Loss: 0.5458061921650746, Test Loss: 0.6992107194281206, Train Accuracy: 58.06%, Test Accuracy: 57.50%\n",
      "Epoch 176, Loss: 0.5454721782133521, Test Loss: 0.6991676515987089, Train Accuracy: 57.28%, Test Accuracy: 57.50%\n",
      "Epoch 177, Loss: 0.5451387622607627, Test Loss: 0.6991247899335817, Train Accuracy: 57.78%, Test Accuracy: 57.50%\n",
      "Epoch 178, Loss: 0.5448059428102693, Test Loss: 0.6990821341426161, Train Accuracy: 57.56%, Test Accuracy: 57.50%\n",
      "Epoch 179, Loss: 0.5444737183686362, Test Loss: 0.6990396839192832, Train Accuracy: 59.56%, Test Accuracy: 57.50%\n",
      "Epoch 180, Loss: 0.5441420874464247, Test Loss: 0.6989974389416233, Train Accuracy: 56.61%, Test Accuracy: 57.50%\n",
      "Epoch 181, Loss: 0.5438110485579865, Test Loss: 0.6989553988731647, Train Accuracy: 58.00%, Test Accuracy: 57.50%\n",
      "Epoch 182, Loss: 0.5434806002214589, Test Loss: 0.6989135633637937, Train Accuracy: 57.78%, Test Accuracy: 57.50%\n",
      "Epoch 183, Loss: 0.5431507409587596, Test Loss: 0.6988719320505768, Train Accuracy: 58.89%, Test Accuracy: 57.50%\n",
      "Epoch 184, Loss: 0.54282146929558, Test Loss: 0.6988305045585382, Train Accuracy: 57.67%, Test Accuracy: 57.50%\n",
      "Epoch 185, Loss: 0.5424927837613809, Test Loss: 0.6987892805013949, Train Accuracy: 57.67%, Test Accuracy: 57.50%\n",
      "Epoch 186, Loss: 0.542164682889387, Test Loss: 0.6987482594822514, Train Accuracy: 57.50%, Test Accuracy: 57.50%\n",
      "Epoch 187, Loss: 0.5418371652165809, Test Loss: 0.6987074410942569, Train Accuracy: 57.83%, Test Accuracy: 57.50%\n",
      "Epoch 188, Loss: 0.5415102292836973, Test Loss: 0.6986668249212268, Train Accuracy: 56.94%, Test Accuracy: 57.50%\n",
      "Epoch 189, Loss: 0.5411838736352187, Test Loss: 0.6986264105382298, Train Accuracy: 59.67%, Test Accuracy: 57.50%\n",
      "Epoch 190, Loss: 0.540858096819369, Test Loss: 0.6985861975121443, Train Accuracy: 56.72%, Test Accuracy: 57.50%\n",
      "Epoch 191, Loss: 0.5405328973881081, Test Loss: 0.6985461854021829, Train Accuracy: 56.67%, Test Accuracy: 57.50%\n",
      "Epoch 192, Loss: 0.5402082738971263, Test Loss: 0.69850637376039, Train Accuracy: 57.89%, Test Accuracy: 57.50%\n",
      "Epoch 193, Loss: 0.5398842249058394, Test Loss: 0.6984667621321111, Train Accuracy: 58.50%, Test Accuracy: 57.50%\n",
      "Epoch 194, Loss: 0.5395607489773822, Test Loss: 0.6984273500564381, Train Accuracy: 56.11%, Test Accuracy: 57.50%\n",
      "Epoch 195, Loss: 0.5392378446786031, Test Loss: 0.6983881370666285, Train Accuracy: 58.00%, Test Accuracy: 57.50%\n",
      "Epoch 196, Loss: 0.5389155105800594, Test Loss: 0.6983491226905042, Train Accuracy: 57.00%, Test Accuracy: 57.50%\n",
      "Epoch 197, Loss: 0.5385937452560101, Test Loss: 0.6983103064508265, Train Accuracy: 57.83%, Test Accuracy: 57.50%\n",
      "Epoch 198, Loss: 0.5382725472844117, Test Loss: 0.698271687865652, Train Accuracy: 57.72%, Test Accuracy: 57.50%\n",
      "Epoch 199, Loss: 0.5379519152469115, Test Loss: 0.6982332664486692, Train Accuracy: 57.61%, Test Accuracy: 57.50%\n",
      "Epoch 200, Loss: 0.5376318477288425, Test Loss: 0.6981950417095164, Train Accuracy: 58.94%, Test Accuracy: 57.50%\n",
      "Epoch 201, Loss: 0.5373123433192172, Test Loss: 0.6981570131540833, Train Accuracy: 58.17%, Test Accuracy: 57.50%\n",
      "Epoch 202, Loss: 0.536993400610722, Test Loss: 0.6981191802847942, Train Accuracy: 58.28%, Test Accuracy: 57.50%\n",
      "Epoch 203, Loss: 0.5366750181997114, Test Loss: 0.6980815426008791, Train Accuracy: 57.78%, Test Accuracy: 57.50%\n",
      "Epoch 204, Loss: 0.5363571946862026, Test Loss: 0.6980440995986268, Train Accuracy: 59.33%, Test Accuracy: 57.50%\n",
      "Epoch 205, Loss: 0.5360399286738686, Test Loss: 0.6980068507716269, Train Accuracy: 58.89%, Test Accuracy: 57.50%\n",
      "Epoch 206, Loss: 0.5357232187700336, Test Loss: 0.6979697956109974, Train Accuracy: 58.11%, Test Accuracy: 57.50%\n",
      "Epoch 207, Loss: 0.535407063585666, Test Loss: 0.6979329336055997, Train Accuracy: 58.61%, Test Accuracy: 57.50%\n",
      "Epoch 208, Loss: 0.535091461735373, Test Loss: 0.6978962642422434, Train Accuracy: 57.28%, Test Accuracy: 57.50%\n",
      "Epoch 209, Loss: 0.5347764118373947, Test Loss: 0.6978597870058781, Train Accuracy: 59.67%, Test Accuracy: 57.50%\n",
      "Epoch 210, Loss: 0.5344619125135979, Test Loss: 0.6978235013797773, Train Accuracy: 57.67%, Test Accuracy: 57.50%\n",
      "Epoch 211, Loss: 0.53414796238947, Test Loss: 0.6977874068457092, Train Accuracy: 56.17%, Test Accuracy: 57.50%\n",
      "Epoch 212, Loss: 0.5338345600941136, Test Loss: 0.6977515028841016, Train Accuracy: 59.44%, Test Accuracy: 57.50%\n",
      "Epoch 213, Loss: 0.5335217042602393, Test Loss: 0.6977157889741948, Train Accuracy: 55.94%, Test Accuracy: 57.50%\n",
      "Epoch 214, Loss: 0.5332093935241605, Test Loss: 0.6976802645941883, Train Accuracy: 57.28%, Test Accuracy: 57.50%\n",
      "Epoch 215, Loss: 0.5328976265257872, Test Loss: 0.6976449292213794, Train Accuracy: 58.28%, Test Accuracy: 57.50%\n",
      "Epoch 216, Loss: 0.5325864019086195, Test Loss: 0.6976097823322931, Train Accuracy: 56.17%, Test Accuracy: 57.50%\n",
      "Epoch 217, Loss: 0.5322757183197416, Test Loss: 0.6975748234028049, Train Accuracy: 59.78%, Test Accuracy: 57.50%\n",
      "Epoch 218, Loss: 0.5319655744098158, Test Loss: 0.6975400519082592, Train Accuracy: 57.61%, Test Accuracy: 57.50%\n",
      "Epoch 219, Loss: 0.5316559688330758, Test Loss: 0.6975054673235794, Train Accuracy: 56.67%, Test Accuracy: 57.50%\n",
      "Epoch 220, Loss: 0.5313469002473206, Test Loss: 0.6974710691233709, Train Accuracy: 58.72%, Test Accuracy: 57.50%\n",
      "Epoch 221, Loss: 0.5310383673139089, Test Loss: 0.6974368567820213, Train Accuracy: 57.11%, Test Accuracy: 57.50%\n",
      "Epoch 222, Loss: 0.5307303686977516, Test Loss: 0.6974028297737931, Train Accuracy: 57.89%, Test Accuracy: 57.50%\n",
      "Epoch 223, Loss: 0.5304229030673066, Test Loss: 0.6973689875729129, Train Accuracy: 57.67%, Test Accuracy: 57.50%\n",
      "Epoch 224, Loss: 0.5301159690945718, Test Loss: 0.697335329653653, Train Accuracy: 57.78%, Test Accuracy: 57.50%\n",
      "Epoch 225, Loss: 0.5298095654550787, Test Loss: 0.6973018554904118, Train Accuracy: 58.50%, Test Accuracy: 57.50%\n",
      "Epoch 226, Loss: 0.5295036908278866, Test Loss: 0.6972685645577883, Train Accuracy: 57.78%, Test Accuracy: 57.50%\n",
      "Epoch 227, Loss: 0.5291983438955753, Test Loss: 0.6972354563306515, Train Accuracy: 57.89%, Test Accuracy: 57.50%\n",
      "Epoch 228, Loss: 0.5288935233442396, Test Loss: 0.6972025302842073, Train Accuracy: 58.06%, Test Accuracy: 57.50%\n",
      "Epoch 229, Loss: 0.528589227863482, Test Loss: 0.6971697858940625, Train Accuracy: 56.72%, Test Accuracy: 57.50%\n",
      "Epoch 230, Loss: 0.5282854561464064, Test Loss: 0.6971372226362825, Train Accuracy: 56.56%, Test Accuracy: 57.50%\n",
      "Epoch 231, Loss: 0.5279822068896125, Test Loss: 0.6971048399874488, Train Accuracy: 57.94%, Test Accuracy: 57.00%\n",
      "Epoch 232, Loss: 0.5276794787931879, Test Loss: 0.6970726374247107, Train Accuracy: 56.44%, Test Accuracy: 57.00%\n",
      "Epoch 233, Loss: 0.5273772705607023, Test Loss: 0.6970406144258366, Train Accuracy: 56.72%, Test Accuracy: 57.00%\n",
      "Epoch 234, Loss: 0.5270755808992008, Test Loss: 0.6970087704692606, Train Accuracy: 59.22%, Test Accuracy: 57.00%\n",
      "Epoch 235, Loss: 0.5267744085191977, Test Loss: 0.6969771050341268, Train Accuracy: 58.06%, Test Accuracy: 57.00%\n",
      "Epoch 236, Loss: 0.5264737521346685, Test Loss: 0.6969456176003317, Train Accuracy: 57.06%, Test Accuracy: 57.00%\n",
      "Epoch 237, Loss: 0.5261736104630454, Test Loss: 0.6969143076485643, Train Accuracy: 58.50%, Test Accuracy: 57.00%\n",
      "Epoch 238, Loss: 0.5258739822252089, Test Loss: 0.6968831746603428, Train Accuracy: 57.39%, Test Accuracy: 57.00%\n",
      "Epoch 239, Loss: 0.5255748661454817, Test Loss: 0.69685221811805, Train Accuracy: 57.22%, Test Accuracy: 57.00%\n",
      "Epoch 240, Loss: 0.5252762609516218, Test Loss: 0.6968214375049671, Train Accuracy: 58.17%, Test Accuracy: 57.00%\n",
      "Epoch 241, Loss: 0.5249781653748169, Test Loss: 0.6967908323053047, Train Accuracy: 57.39%, Test Accuracy: 57.00%\n",
      "Epoch 242, Loss: 0.5246805781496758, Test Loss: 0.6967604020042324, Train Accuracy: 59.56%, Test Accuracy: 57.00%\n",
      "Epoch 243, Loss: 0.5243834980142232, Test Loss: 0.6967301460879066, Train Accuracy: 59.89%, Test Accuracy: 57.00%\n",
      "Epoch 244, Loss: 0.5240869237098923, Test Loss: 0.6967000640434966, Train Accuracy: 58.39%, Test Accuracy: 57.00%\n",
      "Epoch 245, Loss: 0.5237908539815177, Test Loss: 0.6966701553592096, Train Accuracy: 56.61%, Test Accuracy: 57.00%\n",
      "Epoch 246, Loss: 0.5234952875773294, Test Loss: 0.6966404195243133, Train Accuracy: 57.83%, Test Accuracy: 57.00%\n",
      "Epoch 247, Loss: 0.5232002232489457, Test Loss: 0.6966108560291585, Train Accuracy: 58.50%, Test Accuracy: 57.00%\n",
      "Epoch 248, Loss: 0.5229056597513655, Test Loss: 0.6965814643651989, Train Accuracy: 57.39%, Test Accuracy: 57.00%\n",
      "Epoch 249, Loss: 0.5226115958429631, Test Loss: 0.6965522440250104, Train Accuracy: 55.89%, Test Accuracy: 57.00%\n",
      "Epoch 250, Loss: 0.5223180302854796, Test Loss: 0.6965231945023098, Train Accuracy: 58.33%, Test Accuracy: 57.00%\n",
      "Epoch 251, Loss: 0.5220249618440175, Test Loss: 0.6964943152919713, Train Accuracy: 57.28%, Test Accuracy: 57.00%\n",
      "Epoch 252, Loss: 0.5217323892870327, Test Loss: 0.6964656058900419, Train Accuracy: 57.78%, Test Accuracy: 57.00%\n",
      "Epoch 253, Loss: 0.5214403113863282, Test Loss: 0.6964370657937572, Train Accuracy: 56.78%, Test Accuracy: 57.00%\n",
      "Epoch 254, Loss: 0.5211487269170472, Test Loss: 0.6964086945015546, Train Accuracy: 57.39%, Test Accuracy: 57.00%\n",
      "Epoch 255, Loss: 0.5208576346576655, Test Loss: 0.6963804915130873, Train Accuracy: 55.50%, Test Accuracy: 57.00%\n",
      "Epoch 256, Loss: 0.5205670333899857, Test Loss: 0.6963524563292348, Train Accuracy: 57.39%, Test Accuracy: 57.00%\n",
      "Epoch 257, Loss: 0.520276921899129, Test Loss: 0.696324588452116, Train Accuracy: 58.67%, Test Accuracy: 57.00%\n",
      "Epoch 258, Loss: 0.519987298973529, Test Loss: 0.6962968873850989, Train Accuracy: 58.28%, Test Accuracy: 57.00%\n",
      "Epoch 259, Loss: 0.5196981634049245, Test Loss: 0.6962693526328101, Train Accuracy: 58.33%, Test Accuracy: 57.00%\n",
      "Epoch 260, Loss: 0.5194095139883523, Test Loss: 0.6962419837011453, Train Accuracy: 58.33%, Test Accuracy: 57.00%\n",
      "Epoch 261, Loss: 0.5191213495221408, Test Loss: 0.6962147800972767, Train Accuracy: 55.72%, Test Accuracy: 57.00%\n",
      "Epoch 262, Loss: 0.5188336688079025, Test Loss: 0.6961877413296604, Train Accuracy: 58.06%, Test Accuracy: 57.00%\n",
      "Epoch 263, Loss: 0.5185464706505265, Test Loss: 0.6961608669080457, Train Accuracy: 57.00%, Test Accuracy: 57.00%\n",
      "Epoch 264, Loss: 0.5182597538581726, Test Loss: 0.6961341563434797, Train Accuracy: 57.83%, Test Accuracy: 57.00%\n",
      "Epoch 265, Loss: 0.5179735172422634, Test Loss: 0.696107609148315, Train Accuracy: 56.28%, Test Accuracy: 57.00%\n",
      "Epoch 266, Loss: 0.5176877596174773, Test Loss: 0.6960812248362146, Train Accuracy: 56.50%, Test Accuracy: 57.00%\n",
      "Epoch 267, Loss: 0.5174024798017417, Test Loss: 0.6960550029221574, Train Accuracy: 56.50%, Test Accuracy: 57.50%\n",
      "Epoch 268, Loss: 0.517117676616226, Test Loss: 0.6960289429224426, Train Accuracy: 57.94%, Test Accuracy: 57.50%\n",
      "Epoch 269, Loss: 0.516833348885334, Test Loss: 0.6960030443546953, Train Accuracy: 59.17%, Test Accuracy: 57.50%\n",
      "Epoch 270, Loss: 0.5165494954366973, Test Loss: 0.6959773067378688, Train Accuracy: 57.17%, Test Accuracy: 57.50%\n",
      "Epoch 271, Loss: 0.5162661151011677, Test Loss: 0.6959517295922492, Train Accuracy: 57.50%, Test Accuracy: 57.50%\n",
      "Epoch 272, Loss: 0.5159832067128108, Test Loss: 0.6959263124394581, Train Accuracy: 57.22%, Test Accuracy: 57.50%\n",
      "Epoch 273, Loss: 0.5157007691088981, Test Loss: 0.6959010548024562, Train Accuracy: 56.89%, Test Accuracy: 57.50%\n",
      "Epoch 274, Loss: 0.5154188011299001, Test Loss: 0.6958759562055448, Train Accuracy: 56.78%, Test Accuracy: 57.50%\n",
      "Epoch 275, Loss: 0.5151373016194796, Test Loss: 0.6958510161743686, Train Accuracy: 56.78%, Test Accuracy: 57.50%\n",
      "Epoch 276, Loss: 0.5148562694244839, Test Loss: 0.6958262342359177, Train Accuracy: 56.78%, Test Accuracy: 57.50%\n",
      "Epoch 277, Loss: 0.514575703394938, Test Loss: 0.6958016099185289, Train Accuracy: 57.06%, Test Accuracy: 57.50%\n",
      "Epoch 278, Loss: 0.5142956023840374, Test Loss: 0.6957771427518873, Train Accuracy: 56.11%, Test Accuracy: 57.50%\n",
      "Epoch 279, Loss: 0.5140159652481407, Test Loss: 0.6957528322670272, Train Accuracy: 58.17%, Test Accuracy: 57.50%\n",
      "Epoch 280, Loss: 0.513736790846763, Test Loss: 0.6957286779963335, Train Accuracy: 57.00%, Test Accuracy: 57.50%\n",
      "Epoch 281, Loss: 0.513458078042568, Test Loss: 0.6957046794735416, Train Accuracy: 58.78%, Test Accuracy: 57.50%\n",
      "Epoch 282, Loss: 0.5131798257013613, Test Loss: 0.6956808362337381, Train Accuracy: 58.22%, Test Accuracy: 57.50%\n",
      "Epoch 283, Loss: 0.5129020326920826, Test Loss: 0.6956571478133614, Train Accuracy: 58.67%, Test Accuracy: 57.50%\n",
      "Epoch 284, Loss: 0.5126246978867995, Test Loss: 0.6956336137502018, Train Accuracy: 57.17%, Test Accuracy: 57.50%\n",
      "Epoch 285, Loss: 0.5123478201606994, Test Loss: 0.6956102335834001, Train Accuracy: 57.22%, Test Accuracy: 57.50%\n",
      "Epoch 286, Loss: 0.5120713983920825, Test Loss: 0.6955870068534492, Train Accuracy: 57.28%, Test Accuracy: 57.50%\n",
      "Epoch 287, Loss: 0.5117954314623552, Test Loss: 0.6955639331021918, Train Accuracy: 58.94%, Test Accuracy: 57.50%\n",
      "Epoch 288, Loss: 0.5115199182560218, Test Loss: 0.6955410118728212, Train Accuracy: 58.06%, Test Accuracy: 58.00%\n",
      "Epoch 289, Loss: 0.5112448576606781, Test Loss: 0.6955182427098796, Train Accuracy: 56.33%, Test Accuracy: 58.00%\n",
      "Epoch 290, Loss: 0.5109702485670038, Test Loss: 0.6954956251592574, Train Accuracy: 57.50%, Test Accuracy: 58.00%\n",
      "Epoch 291, Loss: 0.5106960898687555, Test Loss: 0.6954731587681923, Train Accuracy: 57.06%, Test Accuracy: 58.00%\n",
      "Epoch 292, Loss: 0.5104223804627595, Test Loss: 0.695450843085268, Train Accuracy: 57.06%, Test Accuracy: 58.00%\n",
      "Epoch 293, Loss: 0.5101491192489038, Test Loss: 0.6954286776604129, Train Accuracy: 58.61%, Test Accuracy: 58.00%\n",
      "Epoch 294, Loss: 0.5098763051301323, Test Loss: 0.6954066620448986, Train Accuracy: 57.06%, Test Accuracy: 58.00%\n",
      "Epoch 295, Loss: 0.509603937012436, Test Loss: 0.6953847957913385, Train Accuracy: 58.17%, Test Accuracy: 58.00%\n",
      "Epoch 296, Loss: 0.5093320138048469, Test Loss: 0.6953630784536862, Train Accuracy: 56.28%, Test Accuracy: 58.00%\n",
      "Epoch 297, Loss: 0.5090605344194302, Test Loss: 0.6953415095872332, Train Accuracy: 58.72%, Test Accuracy: 58.00%\n",
      "Epoch 298, Loss: 0.5087894977712772, Test Loss: 0.6953200887486077, Train Accuracy: 57.28%, Test Accuracy: 58.00%\n",
      "Epoch 299, Loss: 0.5085189027784982, Test Loss: 0.6952988154957734, Train Accuracy: 58.94%, Test Accuracy: 58.00%\n",
      "Epoch 300, Loss: 0.5082487483622146, Test Loss: 0.6952776893880253, Train Accuracy: 56.67%, Test Accuracy: 58.00%\n",
      "Epoch 301, Loss: 0.5079790334465527, Test Loss: 0.6952567099859895, Train Accuracy: 58.22%, Test Accuracy: 58.00%\n",
      "Epoch 302, Loss: 0.5077097569586355, Test Loss: 0.6952358768516211, Train Accuracy: 58.22%, Test Accuracy: 58.00%\n",
      "Epoch 303, Loss: 0.5074409178285759, Test Loss: 0.6952151895482004, Train Accuracy: 58.39%, Test Accuracy: 58.00%\n",
      "Epoch 304, Loss: 0.5071725149894696, Test Loss: 0.6951946476403321, Train Accuracy: 59.89%, Test Accuracy: 58.50%\n",
      "Epoch 305, Loss: 0.5069045473773873, Test Loss: 0.6951742506939428, Train Accuracy: 58.89%, Test Accuracy: 58.50%\n",
      "Epoch 306, Loss: 0.506637013931368, Test Loss: 0.6951539982762773, Train Accuracy: 56.94%, Test Accuracy: 58.50%\n",
      "Epoch 307, Loss: 0.5063699135934112, Test Loss: 0.6951338899558982, Train Accuracy: 57.39%, Test Accuracy: 58.50%\n",
      "Epoch 308, Loss: 0.5061032453084704, Test Loss: 0.6951139253026812, Train Accuracy: 57.17%, Test Accuracy: 58.50%\n",
      "Epoch 309, Loss: 0.505837008024445, Test Loss: 0.6950941038878148, Train Accuracy: 57.56%, Test Accuracy: 58.50%\n",
      "Epoch 310, Loss: 0.5055712006921735, Test Loss: 0.6950744252837953, Train Accuracy: 56.56%, Test Accuracy: 58.50%\n",
      "Epoch 311, Loss: 0.5053058222654265, Test Loss: 0.695054889064426, Train Accuracy: 56.78%, Test Accuracy: 58.50%\n",
      "Epoch 312, Loss: 0.505040871700899, Test Loss: 0.6950354948048139, Train Accuracy: 57.44%, Test Accuracy: 58.50%\n",
      "Epoch 313, Loss: 0.504776347958203, Test Loss: 0.6950162420813665, Train Accuracy: 57.17%, Test Accuracy: 58.50%\n",
      "Epoch 314, Loss: 0.5045122499998609, Test Loss: 0.6949971304717897, Train Accuracy: 57.06%, Test Accuracy: 58.50%\n",
      "Epoch 315, Loss: 0.504248576791298, Test Loss: 0.6949781595550846, Train Accuracy: 57.56%, Test Accuracy: 58.50%\n",
      "Epoch 316, Loss: 0.5039853273008346, Test Loss: 0.6949593289115444, Train Accuracy: 57.17%, Test Accuracy: 58.50%\n",
      "Epoch 317, Loss: 0.5037225004996799, Test Loss: 0.6949406381227524, Train Accuracy: 58.61%, Test Accuracy: 58.50%\n",
      "Epoch 318, Loss: 0.503460095361924, Test Loss: 0.6949220867715783, Train Accuracy: 56.72%, Test Accuracy: 58.50%\n",
      "Epoch 319, Loss: 0.5031981108645309, Test Loss: 0.6949036744421755, Train Accuracy: 58.06%, Test Accuracy: 58.50%\n",
      "Epoch 320, Loss: 0.5029365459873312, Test Loss: 0.6948854007199778, Train Accuracy: 56.83%, Test Accuracy: 58.50%\n",
      "Epoch 321, Loss: 0.5026753997130147, Test Loss: 0.6948672651916974, Train Accuracy: 56.83%, Test Accuracy: 58.50%\n",
      "Epoch 322, Loss: 0.5024146710271234, Test Loss: 0.6948492674453206, Train Accuracy: 58.28%, Test Accuracy: 58.50%\n",
      "Epoch 323, Loss: 0.5021543589180447, Test Loss: 0.6948314070701055, Train Accuracy: 57.94%, Test Accuracy: 58.50%\n",
      "Epoch 324, Loss: 0.5018944623770033, Test Loss: 0.6948136836565791, Train Accuracy: 57.28%, Test Accuracy: 58.50%\n",
      "Epoch 325, Loss: 0.5016349803980543, Test Loss: 0.6947960967965333, Train Accuracy: 57.61%, Test Accuracy: 59.00%\n",
      "Epoch 326, Loss: 0.5013759119780766, Test Loss: 0.6947786460830233, Train Accuracy: 58.06%, Test Accuracy: 59.00%\n",
      "Epoch 327, Loss: 0.5011172561167646, Test Loss: 0.6947613311103626, Train Accuracy: 59.17%, Test Accuracy: 59.00%\n",
      "Epoch 328, Loss: 0.5008590118166222, Test Loss: 0.6947441514741215, Train Accuracy: 58.11%, Test Accuracy: 59.00%\n",
      "Epoch 329, Loss: 0.5006011780829543, Test Loss: 0.694727106771123, Train Accuracy: 57.67%, Test Accuracy: 59.00%\n",
      "Epoch 330, Loss: 0.500343753923861, Test Loss: 0.6947101965994402, Train Accuracy: 58.11%, Test Accuracy: 59.00%\n",
      "Epoch 331, Loss: 0.5000867383502291, Test Loss: 0.6946934205583927, Train Accuracy: 56.50%, Test Accuracy: 59.00%\n",
      "Epoch 332, Loss: 0.4998301303757259, Test Loss: 0.6946767782485432, Train Accuracy: 57.44%, Test Accuracy: 59.00%\n",
      "Epoch 333, Loss: 0.4995739290167915, Test Loss: 0.6946602692716953, Train Accuracy: 58.22%, Test Accuracy: 59.00%\n",
      "Epoch 334, Loss: 0.49931813329263186, Test Loss: 0.6946438932308895, Train Accuracy: 58.11%, Test Accuracy: 59.00%\n",
      "Epoch 335, Loss: 0.49906274222521146, Test Loss: 0.6946276497303995, Train Accuracy: 57.33%, Test Accuracy: 59.00%\n",
      "Epoch 336, Loss: 0.4988077548392461, Test Loss: 0.6946115383757302, Train Accuracy: 56.67%, Test Accuracy: 59.00%\n",
      "Epoch 337, Loss: 0.49855317016219614, Test Loss: 0.6945955587736137, Train Accuracy: 57.89%, Test Accuracy: 59.00%\n",
      "Epoch 338, Loss: 0.49829898722425886, Test Loss: 0.6945797105320061, Train Accuracy: 58.11%, Test Accuracy: 59.00%\n",
      "Epoch 339, Loss: 0.49804520505836153, Test Loss: 0.6945639932600843, Train Accuracy: 58.44%, Test Accuracy: 59.00%\n",
      "Epoch 340, Loss: 0.49779182270015426, Test Loss: 0.6945484065682429, Train Accuracy: 58.39%, Test Accuracy: 59.00%\n",
      "Epoch 341, Loss: 0.49753883918800296, Test Loss: 0.6945329500680906, Train Accuracy: 56.89%, Test Accuracy: 59.00%\n",
      "Epoch 342, Loss: 0.49728625356298195, Test Loss: 0.694517623372447, Train Accuracy: 57.72%, Test Accuracy: 59.50%\n",
      "Epoch 343, Loss: 0.4970340648688672, Test Loss: 0.69450242609534, Train Accuracy: 58.61%, Test Accuracy: 59.50%\n",
      "Epoch 344, Loss: 0.4967822721521289, Test Loss: 0.6944873578520013, Train Accuracy: 58.06%, Test Accuracy: 59.50%\n",
      "Epoch 345, Loss: 0.4965308744619245, Test Loss: 0.694472418258864, Train Accuracy: 59.06%, Test Accuracy: 59.50%\n",
      "Epoch 346, Loss: 0.4962798708500915, Test Loss: 0.694457606933559, Train Accuracy: 56.89%, Test Accuracy: 59.50%\n",
      "Epoch 347, Loss: 0.49602926037114065, Test Loss: 0.6944429234949118, Train Accuracy: 57.56%, Test Accuracy: 60.00%\n",
      "Epoch 348, Loss: 0.49577904208224843, Test Loss: 0.6944283675629392, Train Accuracy: 56.67%, Test Accuracy: 60.00%\n",
      "Epoch 349, Loss: 0.49552921504325026, Test Loss: 0.6944139387588462, Train Accuracy: 57.06%, Test Accuracy: 60.00%\n",
      "Epoch 350, Loss: 0.4952797783166335, Test Loss: 0.6943996367050215, Train Accuracy: 57.56%, Test Accuracy: 60.00%\n",
      "Epoch 351, Loss: 0.49503073096753003, Test Loss: 0.6943854610250362, Train Accuracy: 56.89%, Test Accuracy: 60.00%\n",
      "Epoch 352, Loss: 0.49478207206370967, Test Loss: 0.694371411343639, Train Accuracy: 57.11%, Test Accuracy: 60.00%\n",
      "Epoch 353, Loss: 0.4945338006755724, Test Loss: 0.6943574872867531, Train Accuracy: 57.72%, Test Accuracy: 60.00%\n",
      "Epoch 354, Loss: 0.4942859158761424, Test Loss: 0.6943436884814738, Train Accuracy: 59.28%, Test Accuracy: 60.00%\n",
      "Epoch 355, Loss: 0.4940384167410601, Test Loss: 0.6943300145560635, Train Accuracy: 57.78%, Test Accuracy: 60.00%\n",
      "Epoch 356, Loss: 0.4937913023485754, Test Loss: 0.6943164651399504, Train Accuracy: 56.11%, Test Accuracy: 60.00%\n",
      "Epoch 357, Loss: 0.4935445717795408, Test Loss: 0.6943030398637235, Train Accuracy: 56.00%, Test Accuracy: 60.00%\n",
      "Epoch 358, Loss: 0.49329822411740437, Test Loss: 0.6942897383591302, Train Accuracy: 57.78%, Test Accuracy: 60.00%\n",
      "Epoch 359, Loss: 0.4930522584482027, Test Loss: 0.6942765602590731, Train Accuracy: 57.67%, Test Accuracy: 60.00%\n",
      "Epoch 360, Loss: 0.4928066738605537, Test Loss: 0.694263505197606, Train Accuracy: 55.44%, Test Accuracy: 60.00%\n",
      "Epoch 361, Loss: 0.49256146944565016, Test Loss: 0.6942505728099309, Train Accuracy: 58.06%, Test Accuracy: 60.00%\n",
      "Epoch 362, Loss: 0.492316644297252, Test Loss: 0.694237762732395, Train Accuracy: 58.83%, Test Accuracy: 60.00%\n",
      "Epoch 363, Loss: 0.4920721975116803, Test Loss: 0.6942250746024868, Train Accuracy: 57.39%, Test Accuracy: 60.00%\n",
      "Epoch 364, Loss: 0.4918281281878093, Test Loss: 0.694212508058834, Train Accuracy: 58.06%, Test Accuracy: 60.00%\n",
      "Epoch 365, Loss: 0.4915844354270601, Test Loss: 0.6942000627411983, Train Accuracy: 56.17%, Test Accuracy: 60.00%\n",
      "Epoch 366, Loss: 0.4913411183333936, Test Loss: 0.6941877382904741, Train Accuracy: 57.28%, Test Accuracy: 60.00%\n",
      "Epoch 367, Loss: 0.4910981760133037, Test Loss: 0.6941755343486835, Train Accuracy: 55.89%, Test Accuracy: 60.00%\n",
      "Epoch 368, Loss: 0.4908556075758098, Test Loss: 0.6941634505589745, Train Accuracy: 54.89%, Test Accuracy: 60.00%\n",
      "Epoch 369, Loss: 0.49061341213245085, Test Loss: 0.6941514865656164, Train Accuracy: 58.00%, Test Accuracy: 60.00%\n",
      "Epoch 370, Loss: 0.4903715887972775, Test Loss: 0.6941396420139975, Train Accuracy: 56.56%, Test Accuracy: 60.00%\n",
      "Epoch 371, Loss: 0.49013013668684574, Test Loss: 0.6941279165506217, Train Accuracy: 55.78%, Test Accuracy: 60.00%\n",
      "Epoch 372, Loss: 0.48988905492021, Test Loss: 0.6941163098231038, Train Accuracy: 58.11%, Test Accuracy: 60.00%\n",
      "Epoch 373, Loss: 0.4896483426189162, Test Loss: 0.6941048214801693, Train Accuracy: 57.28%, Test Accuracy: 60.00%\n",
      "Epoch 374, Loss: 0.4894079989069948, Test Loss: 0.6940934511716472, Train Accuracy: 56.39%, Test Accuracy: 60.00%\n",
      "Epoch 375, Loss: 0.489168022910954, Test Loss: 0.6940821985484703, Train Accuracy: 56.83%, Test Accuracy: 60.00%\n",
      "Epoch 376, Loss: 0.4889284137597729, Test Loss: 0.6940710632626699, Train Accuracy: 59.56%, Test Accuracy: 60.00%\n",
      "Epoch 377, Loss: 0.488689170584895, Test Loss: 0.6940600449673724, Train Accuracy: 56.44%, Test Accuracy: 60.00%\n",
      "Epoch 378, Loss: 0.4884502925202209, Test Loss: 0.6940491433167979, Train Accuracy: 56.83%, Test Accuracy: 60.00%\n",
      "Epoch 379, Loss: 0.4882117787021015, Test Loss: 0.694038357966255, Train Accuracy: 57.50%, Test Accuracy: 60.00%\n",
      "Epoch 380, Loss: 0.4879736282693316, Test Loss: 0.6940276885721383, Train Accuracy: 58.17%, Test Accuracy: 60.00%\n",
      "Epoch 381, Loss: 0.48773584036314305, Test Loss: 0.6940171347919254, Train Accuracy: 57.61%, Test Accuracy: 60.00%\n",
      "Epoch 382, Loss: 0.4874984141271976, Test Loss: 0.6940066962841732, Train Accuracy: 56.83%, Test Accuracy: 60.00%\n",
      "Epoch 383, Loss: 0.48726134870758026, Test Loss: 0.6939963727085154, Train Accuracy: 54.94%, Test Accuracy: 60.00%\n",
      "Epoch 384, Loss: 0.48702464325279293, Test Loss: 0.6939861637256581, Train Accuracy: 56.83%, Test Accuracy: 60.50%\n",
      "Epoch 385, Loss: 0.4867882969137472, Test Loss: 0.6939760689973781, Train Accuracy: 58.28%, Test Accuracy: 60.50%\n",
      "Epoch 386, Loss: 0.48655230884375794, Test Loss: 0.6939660881865177, Train Accuracy: 57.11%, Test Accuracy: 60.50%\n",
      "Epoch 387, Loss: 0.48631667819853636, Test Loss: 0.6939562209569838, Train Accuracy: 57.11%, Test Accuracy: 60.50%\n",
      "Epoch 388, Loss: 0.48608140413618317, Test Loss: 0.6939464669737427, Train Accuracy: 57.83%, Test Accuracy: 60.50%\n",
      "Epoch 389, Loss: 0.4858464858171825, Test Loss: 0.6939368259028182, Train Accuracy: 58.11%, Test Accuracy: 60.50%\n",
      "Epoch 390, Loss: 0.4856119224043945, Test Loss: 0.6939272974112879, Train Accuracy: 59.44%, Test Accuracy: 60.50%\n",
      "Epoch 391, Loss: 0.48537771306304917, Test Loss: 0.6939178811672798, Train Accuracy: 57.94%, Test Accuracy: 60.50%\n",
      "Epoch 392, Loss: 0.48514385696073925, Test Loss: 0.6939085768399693, Train Accuracy: 57.61%, Test Accuracy: 60.50%\n",
      "Epoch 393, Loss: 0.48491035326741394, Test Loss: 0.6938993840995766, Train Accuracy: 56.33%, Test Accuracy: 60.50%\n",
      "Epoch 394, Loss: 0.4846772011553723, Test Loss: 0.6938903026173628, Train Accuracy: 56.33%, Test Accuracy: 60.50%\n",
      "Epoch 395, Loss: 0.4844443997992563, Test Loss: 0.6938813320656265, Train Accuracy: 57.39%, Test Accuracy: 60.50%\n",
      "Epoch 396, Loss: 0.48421194837604425, Test Loss: 0.6938724721177019, Train Accuracy: 57.17%, Test Accuracy: 60.50%\n",
      "Epoch 397, Loss: 0.48397984606504446, Test Loss: 0.6938637224479538, Train Accuracy: 56.00%, Test Accuracy: 60.50%\n",
      "Epoch 398, Loss: 0.48374809204788854, Test Loss: 0.6938550827317767, Train Accuracy: 57.72%, Test Accuracy: 60.50%\n",
      "Epoch 399, Loss: 0.48351668550852456, Test Loss: 0.6938465526455895, Train Accuracy: 57.06%, Test Accuracy: 60.50%\n",
      "Epoch 400, Loss: 0.4832856256332108, Test Loss: 0.6938381318668334, Train Accuracy: 56.22%, Test Accuracy: 60.50%\n",
      "Epoch 401, Loss: 0.48305491161050934, Test Loss: 0.6938298200739692, Train Accuracy: 57.39%, Test Accuracy: 60.50%\n",
      "Epoch 402, Loss: 0.48282454263127866, Test Loss: 0.6938216169464735, Train Accuracy: 58.17%, Test Accuracy: 60.50%\n",
      "Epoch 403, Loss: 0.4825945178886684, Test Loss: 0.6938135221648352, Train Accuracy: 56.50%, Test Accuracy: 60.50%\n",
      "Epoch 404, Loss: 0.48236483657811163, Test Loss: 0.6938055354105535, Train Accuracy: 56.11%, Test Accuracy: 60.50%\n",
      "Epoch 405, Loss: 0.4821354978973191, Test Loss: 0.693797656366134, Train Accuracy: 56.67%, Test Accuracy: 60.50%\n",
      "Epoch 406, Loss: 0.4819065010462724, Test Loss: 0.6937898847150856, Train Accuracy: 55.72%, Test Accuracy: 60.50%\n",
      "Epoch 407, Loss: 0.48167784522721757, Test Loss: 0.693782220141918, Train Accuracy: 56.61%, Test Accuracy: 60.50%\n",
      "Epoch 408, Loss: 0.48144952964465876, Test Loss: 0.6937746623321382, Train Accuracy: 56.50%, Test Accuracy: 60.50%\n",
      "Epoch 409, Loss: 0.4812215535053517, Test Loss: 0.6937672109722471, Train Accuracy: 58.17%, Test Accuracy: 60.50%\n",
      "Epoch 410, Loss: 0.4809939160182969, Test Loss: 0.6937598657497369, Train Accuracy: 56.83%, Test Accuracy: 60.50%\n",
      "Epoch 411, Loss: 0.48076661639473367, Test Loss: 0.6937526263530881, Train Accuracy: 56.61%, Test Accuracy: 60.50%\n",
      "Epoch 412, Loss: 0.48053965384813374, Test Loss: 0.6937454924717662, Train Accuracy: 57.44%, Test Accuracy: 60.50%\n",
      "Epoch 413, Loss: 0.4803130275941943, Test Loss: 0.6937384637962181, Train Accuracy: 58.00%, Test Accuracy: 60.50%\n",
      "Epoch 414, Loss: 0.4800867368508323, Test Loss: 0.6937315400178704, Train Accuracy: 56.17%, Test Accuracy: 60.50%\n",
      "Epoch 415, Loss: 0.4798607808381776, Test Loss: 0.6937247208291255, Train Accuracy: 56.06%, Test Accuracy: 60.50%\n",
      "Epoch 416, Loss: 0.4796351587785667, Test Loss: 0.6937180059233583, Train Accuracy: 57.72%, Test Accuracy: 60.50%\n",
      "Epoch 417, Loss: 0.4794098698965365, Test Loss: 0.6937113949949133, Train Accuracy: 56.06%, Test Accuracy: 60.50%\n",
      "Epoch 418, Loss: 0.47918491341881764, Test Loss: 0.6937048877391027, Train Accuracy: 58.61%, Test Accuracy: 60.50%\n",
      "Epoch 419, Loss: 0.47896028857432876, Test Loss: 0.6936984838522016, Train Accuracy: 56.61%, Test Accuracy: 60.50%\n",
      "Epoch 420, Loss: 0.4787359945941695, Test Loss: 0.6936921830314461, Train Accuracy: 56.83%, Test Accuracy: 60.50%\n",
      "Epoch 421, Loss: 0.47851203071161463, Test Loss: 0.6936859849750304, Train Accuracy: 57.06%, Test Accuracy: 60.50%\n",
      "Epoch 422, Loss: 0.47828839616210783, Test Loss: 0.6936798893821033, Train Accuracy: 56.61%, Test Accuracy: 60.50%\n",
      "Epoch 423, Loss: 0.4780650901832549, Test Loss: 0.6936738959527651, Train Accuracy: 56.28%, Test Accuracy: 60.50%\n",
      "Epoch 424, Loss: 0.4778421120148182, Test Loss: 0.6936680043880652, Train Accuracy: 58.56%, Test Accuracy: 60.50%\n",
      "Epoch 425, Loss: 0.47761946089870944, Test Loss: 0.6936622143899988, Train Accuracy: 57.89%, Test Accuracy: 60.50%\n",
      "Epoch 426, Loss: 0.4773971360789847, Test Loss: 0.6936565256615036, Train Accuracy: 56.89%, Test Accuracy: 60.50%\n",
      "Epoch 427, Loss: 0.4771751368018371, Test Loss: 0.6936509379064577, Train Accuracy: 56.67%, Test Accuracy: 60.50%\n",
      "Epoch 428, Loss: 0.47695346231559105, Test Loss: 0.6936454508296758, Train Accuracy: 56.56%, Test Accuracy: 60.50%\n",
      "Epoch 429, Loss: 0.47673211187069614, Test Loss: 0.6936400641369066, Train Accuracy: 57.56%, Test Accuracy: 60.50%\n",
      "Epoch 430, Loss: 0.4765110847197207, Test Loss: 0.6936347775348302, Train Accuracy: 56.44%, Test Accuracy: 60.50%\n",
      "Epoch 431, Loss: 0.4762903801173458, Test Loss: 0.693629590731054, Train Accuracy: 57.72%, Test Accuracy: 60.50%\n",
      "Epoch 432, Loss: 0.47606999732035915, Test Loss: 0.6936245034341113, Train Accuracy: 57.78%, Test Accuracy: 60.50%\n",
      "Epoch 433, Loss: 0.4758499355876486, Test Loss: 0.6936195153534577, Train Accuracy: 57.11%, Test Accuracy: 60.50%\n",
      "Epoch 434, Loss: 0.4756301941801965, Test Loss: 0.6936146261994673, Train Accuracy: 54.28%, Test Accuracy: 60.50%\n",
      "Epoch 435, Loss: 0.475410772361073, Test Loss: 0.6936098356834316, Train Accuracy: 58.17%, Test Accuracy: 60.50%\n",
      "Epoch 436, Loss: 0.4751916693954308, Test Loss: 0.6936051435175551, Train Accuracy: 56.89%, Test Accuracy: 60.50%\n",
      "Epoch 437, Loss: 0.4749728845504981, Test Loss: 0.6936005494149532, Train Accuracy: 58.22%, Test Accuracy: 60.50%\n",
      "Epoch 438, Loss: 0.4747544170955729, Test Loss: 0.6935960530896483, Train Accuracy: 56.78%, Test Accuracy: 60.50%\n",
      "Epoch 439, Loss: 0.4745362663020175, Test Loss: 0.693591654256569, Train Accuracy: 58.00%, Test Accuracy: 60.50%\n",
      "Epoch 440, Loss: 0.47431843144325153, Test Loss: 0.6935873526315446, Train Accuracy: 55.28%, Test Accuracy: 60.50%\n",
      "Epoch 441, Loss: 0.4741009117947463, Test Loss: 0.6935831479313044, Train Accuracy: 58.39%, Test Accuracy: 60.50%\n",
      "Epoch 442, Loss: 0.473883706634019, Test Loss: 0.6935790398734732, Train Accuracy: 56.78%, Test Accuracy: 60.50%\n",
      "Epoch 443, Loss: 0.47366681524062637, Test Loss: 0.6935750281765702, Train Accuracy: 56.44%, Test Accuracy: 60.50%\n",
      "Epoch 444, Loss: 0.4734502368961589, Test Loss: 0.6935711125600045, Train Accuracy: 56.83%, Test Accuracy: 60.50%\n",
      "Epoch 445, Loss: 0.4732339708842347, Test Loss: 0.6935672927440726, Train Accuracy: 56.56%, Test Accuracy: 61.00%\n",
      "Epoch 446, Loss: 0.4730180164904936, Test Loss: 0.6935635684499569, Train Accuracy: 56.06%, Test Accuracy: 61.00%\n",
      "Epoch 447, Loss: 0.47280237300259126, Test Loss: 0.6935599393997209, Train Accuracy: 56.17%, Test Accuracy: 61.00%\n",
      "Epoch 448, Loss: 0.47258703971019317, Test Loss: 0.6935564053163082, Train Accuracy: 58.06%, Test Accuracy: 61.00%\n",
      "Epoch 449, Loss: 0.4723720159049685, Test Loss: 0.6935529659235382, Train Accuracy: 57.06%, Test Accuracy: 61.00%\n",
      "Epoch 450, Loss: 0.4721573008805847, Test Loss: 0.6935496209461043, Train Accuracy: 57.78%, Test Accuracy: 61.00%\n",
      "Epoch 451, Loss: 0.47194289393270117, Test Loss: 0.6935463701095705, Train Accuracy: 57.67%, Test Accuracy: 61.00%\n",
      "Epoch 452, Loss: 0.4717287943589635, Test Loss: 0.6935432131403694, Train Accuracy: 55.28%, Test Accuracy: 61.00%\n",
      "Epoch 453, Loss: 0.47151500145899755, Test Loss: 0.693540149765798, Train Accuracy: 55.61%, Test Accuracy: 61.00%\n",
      "Epoch 454, Loss: 0.47130151453440366, Test Loss: 0.6935371797140167, Train Accuracy: 57.28%, Test Accuracy: 61.00%\n",
      "Epoch 455, Loss: 0.471088332888751, Test Loss: 0.6935343027140454, Train Accuracy: 56.72%, Test Accuracy: 61.00%\n",
      "Epoch 456, Loss: 0.47087545582757134, Test Loss: 0.6935315184957606, Train Accuracy: 56.17%, Test Accuracy: 61.00%\n",
      "Epoch 457, Loss: 0.4706628826583533, Test Loss: 0.693528826789893, Train Accuracy: 57.17%, Test Accuracy: 61.00%\n",
      "Epoch 458, Loss: 0.4704506126905369, Test Loss: 0.6935262273280256, Train Accuracy: 56.61%, Test Accuracy: 61.00%\n",
      "Epoch 459, Loss: 0.4702386452355074, Test Loss: 0.6935237198425895, Train Accuracy: 56.22%, Test Accuracy: 61.00%\n",
      "Epoch 460, Loss: 0.47002697960658985, Test Loss: 0.6935213040668619, Train Accuracy: 58.67%, Test Accuracy: 61.00%\n",
      "Epoch 461, Loss: 0.46981561511904285, Test Loss: 0.6935189797349632, Train Accuracy: 58.00%, Test Accuracy: 60.50%\n",
      "Epoch 462, Loss: 0.4696045510900534, Test Loss: 0.693516746581855, Train Accuracy: 54.11%, Test Accuracy: 60.50%\n",
      "Epoch 463, Loss: 0.46939378683873056, Test Loss: 0.6935146043433359, Train Accuracy: 57.22%, Test Accuracy: 60.50%\n",
      "Epoch 464, Loss: 0.46918332168610033, Test Loss: 0.6935125527560402, Train Accuracy: 56.17%, Test Accuracy: 60.50%\n",
      "Epoch 465, Loss: 0.4689731549550994, Test Loss: 0.6935105915574346, Train Accuracy: 57.22%, Test Accuracy: 60.50%\n",
      "Epoch 466, Loss: 0.46876328597057004, Test Loss: 0.6935087204858155, Train Accuracy: 56.72%, Test Accuracy: 60.50%\n",
      "Epoch 467, Loss: 0.4685537140592538, Test Loss: 0.6935069392803065, Train Accuracy: 58.50%, Test Accuracy: 60.50%\n",
      "Epoch 468, Loss: 0.468344438549786, Test Loss: 0.6935052476808555, Train Accuracy: 57.39%, Test Accuracy: 60.50%\n",
      "Epoch 469, Loss: 0.46813545877269064, Test Loss: 0.6935036454282326, Train Accuracy: 56.06%, Test Accuracy: 60.50%\n",
      "Epoch 470, Loss: 0.4679267740603742, Test Loss: 0.6935021322640259, Train Accuracy: 56.33%, Test Accuracy: 60.50%\n",
      "Epoch 471, Loss: 0.4677183837471198, Test Loss: 0.6935007079306414, Train Accuracy: 56.11%, Test Accuracy: 60.50%\n",
      "Epoch 472, Loss: 0.4675102871690827, Test Loss: 0.6934993721712982, Train Accuracy: 58.00%, Test Accuracy: 60.50%\n",
      "Epoch 473, Loss: 0.4673024836642833, Test Loss: 0.6934981247300263, Train Accuracy: 57.00%, Test Accuracy: 60.50%\n",
      "Epoch 474, Loss: 0.46709497257260235, Test Loss: 0.6934969653516646, Train Accuracy: 55.17%, Test Accuracy: 60.50%\n",
      "Epoch 475, Loss: 0.46688775323577547, Test Loss: 0.6934958937818582, Train Accuracy: 55.44%, Test Accuracy: 60.50%\n",
      "Epoch 476, Loss: 0.46668082499738733, Test Loss: 0.6934949097670546, Train Accuracy: 57.67%, Test Accuracy: 60.50%\n",
      "Epoch 477, Loss: 0.4664741872028661, Test Loss: 0.6934940130545033, Train Accuracy: 54.00%, Test Accuracy: 60.50%\n",
      "Epoch 478, Loss: 0.4662678391994781, Test Loss: 0.6934932033922506, Train Accuracy: 55.67%, Test Accuracy: 60.50%\n",
      "Epoch 479, Loss: 0.46606178033632206, Test Loss: 0.6934924805291388, Train Accuracy: 56.22%, Test Accuracy: 60.50%\n",
      "Epoch 480, Loss: 0.4658560099643237, Test Loss: 0.6934918442148037, Train Accuracy: 55.89%, Test Accuracy: 60.50%\n",
      "Epoch 481, Loss: 0.46565052743623053, Test Loss: 0.6934912941996708, Train Accuracy: 55.78%, Test Accuracy: 60.50%\n",
      "Epoch 482, Loss: 0.46544533210660627, Test Loss: 0.6934908302349533, Train Accuracy: 57.22%, Test Accuracy: 60.50%\n",
      "Epoch 483, Loss: 0.4652404233318248, Test Loss: 0.6934904520726497, Train Accuracy: 55.67%, Test Accuracy: 60.50%\n",
      "Epoch 484, Loss: 0.4650358004700655, Test Loss: 0.6934901594655415, Train Accuracy: 55.33%, Test Accuracy: 60.50%\n",
      "Epoch 485, Loss: 0.4648314628813077, Test Loss: 0.6934899521671896, Train Accuracy: 57.22%, Test Accuracy: 61.00%\n",
      "Epoch 486, Loss: 0.4646274099273248, Test Loss: 0.6934898299319333, Train Accuracy: 59.22%, Test Accuracy: 61.00%\n",
      "Epoch 487, Loss: 0.4644236409716795, Test Loss: 0.6934897925148862, Train Accuracy: 56.67%, Test Accuracy: 61.00%\n",
      "Epoch 488, Loss: 0.4642201553797176, Test Loss: 0.6934898396719347, Train Accuracy: 55.33%, Test Accuracy: 61.00%\n",
      "Epoch 489, Loss: 0.4640169525185638, Test Loss: 0.693489971159735, Train Accuracy: 57.00%, Test Accuracy: 61.00%\n",
      "Epoch 490, Loss: 0.4638140317571151, Test Loss: 0.693490186735711, Train Accuracy: 58.89%, Test Accuracy: 60.50%\n",
      "Epoch 491, Loss: 0.4636113924660363, Test Loss: 0.6934904861580509, Train Accuracy: 57.78%, Test Accuracy: 60.50%\n",
      "Epoch 492, Loss: 0.46340903401775435, Test Loss: 0.6934908691857063, Train Accuracy: 56.89%, Test Accuracy: 60.50%\n",
      "Epoch 493, Loss: 0.4632069557864533, Test Loss: 0.6934913355783879, Train Accuracy: 56.11%, Test Accuracy: 60.50%\n",
      "Epoch 494, Loss: 0.4630051571480685, Test Loss: 0.6934918850965645, Train Accuracy: 56.11%, Test Accuracy: 60.50%\n",
      "Epoch 495, Loss: 0.4628036374802817, Test Loss: 0.693492517501459, Train Accuracy: 55.67%, Test Accuracy: 60.50%\n",
      "Epoch 496, Loss: 0.46260239616251575, Test Loss: 0.6934932325550475, Train Accuracy: 56.44%, Test Accuracy: 60.50%\n",
      "Epoch 497, Loss: 0.4624014325759294, Test Loss: 0.6934940300200562, Train Accuracy: 56.39%, Test Accuracy: 60.50%\n",
      "Epoch 498, Loss: 0.4622007461034117, Test Loss: 0.6934949096599583, Train Accuracy: 56.50%, Test Accuracy: 60.50%\n",
      "Epoch 499, Loss: 0.46200033612957725, Test Loss: 0.6934958712389725, Train Accuracy: 57.72%, Test Accuracy: 60.50%\n",
      "Epoch 500, Loss: 0.4618002020407606, Test Loss: 0.69349691452206, Train Accuracy: 57.28%, Test Accuracy: 60.50%\n",
      "Epoch 501, Loss: 0.4616003432250113, Test Loss: 0.6934980392749229, Train Accuracy: 57.44%, Test Accuracy: 60.50%\n",
      "Epoch 502, Loss: 0.4614007590720887, Test Loss: 0.6934992452639999, Train Accuracy: 58.11%, Test Accuracy: 60.50%\n",
      "Epoch 503, Loss: 0.4612014489734564, Test Loss: 0.6935005322564658, Train Accuracy: 57.11%, Test Accuracy: 60.50%\n",
      "Epoch 504, Loss: 0.4610024123222778, Test Loss: 0.6935019000202288, Train Accuracy: 56.22%, Test Accuracy: 60.50%\n",
      "Epoch 505, Loss: 0.4608036485134102, Test Loss: 0.6935033483239265, Train Accuracy: 56.44%, Test Accuracy: 60.50%\n",
      "Epoch 506, Loss: 0.46060515694340026, Test Loss: 0.6935048769369255, Train Accuracy: 55.89%, Test Accuracy: 60.50%\n",
      "Epoch 507, Loss: 0.4604069370104785, Test Loss: 0.6935064856293183, Train Accuracy: 56.22%, Test Accuracy: 60.50%\n",
      "Epoch 508, Loss: 0.46020898811455435, Test Loss: 0.6935081741719202, Train Accuracy: 58.11%, Test Accuracy: 60.50%\n",
      "Epoch 509, Loss: 0.4600113096572112, Test Loss: 0.6935099423362675, Train Accuracy: 55.39%, Test Accuracy: 60.50%\n",
      "Epoch 510, Loss: 0.45981390104170095, Test Loss: 0.6935117898946157, Train Accuracy: 57.39%, Test Accuracy: 60.50%\n",
      "Epoch 511, Loss: 0.4596167616729394, Test Loss: 0.6935137166199362, Train Accuracy: 57.83%, Test Accuracy: 60.00%\n",
      "Epoch 512, Loss: 0.4594198909575008, Test Loss: 0.6935157222859141, Train Accuracy: 57.17%, Test Accuracy: 60.00%\n",
      "Epoch 513, Loss: 0.45922328830361303, Test Loss: 0.6935178066669464, Train Accuracy: 57.83%, Test Accuracy: 60.00%\n",
      "Epoch 514, Loss: 0.4590269531211527, Test Loss: 0.6935199695381388, Train Accuracy: 58.06%, Test Accuracy: 60.00%\n",
      "Epoch 515, Loss: 0.4588308848216398, Test Loss: 0.6935222106753046, Train Accuracy: 57.50%, Test Accuracy: 60.00%\n",
      "Epoch 516, Loss: 0.458635082818233, Test Loss: 0.6935245298549612, Train Accuracy: 55.33%, Test Accuracy: 60.00%\n",
      "Epoch 517, Loss: 0.45843954652572466, Test Loss: 0.6935269268543276, Train Accuracy: 57.28%, Test Accuracy: 60.00%\n",
      "Epoch 518, Loss: 0.4582442753605356, Test Loss: 0.693529401451324, Train Accuracy: 58.17%, Test Accuracy: 60.00%\n",
      "Epoch 519, Loss: 0.4580492687407102, Test Loss: 0.693531953424567, Train Accuracy: 56.17%, Test Accuracy: 60.00%\n",
      "Epoch 520, Loss: 0.45785452608591226, Test Loss: 0.6935345825533692, Train Accuracy: 56.50%, Test Accuracy: 60.00%\n",
      "Epoch 521, Loss: 0.45766004681741845, Test Loss: 0.6935372886177356, Train Accuracy: 57.28%, Test Accuracy: 60.00%\n",
      "Epoch 522, Loss: 0.4574658303581152, Test Loss: 0.6935400713983622, Train Accuracy: 57.50%, Test Accuracy: 60.00%\n",
      "Epoch 523, Loss: 0.4572718761324926, Test Loss: 0.6935429306766335, Train Accuracy: 57.06%, Test Accuracy: 60.00%\n",
      "Epoch 524, Loss: 0.4570781835666397, Test Loss: 0.6935458662346199, Train Accuracy: 55.72%, Test Accuracy: 60.00%\n",
      "Epoch 525, Loss: 0.45688475208824014, Test Loss: 0.6935488778550757, Train Accuracy: 58.28%, Test Accuracy: 60.00%\n",
      "Epoch 526, Loss: 0.4566915811265669, Test Loss: 0.6935519653214367, Train Accuracy: 57.11%, Test Accuracy: 60.00%\n",
      "Epoch 527, Loss: 0.4564986701124776, Test Loss: 0.6935551284178182, Train Accuracy: 58.78%, Test Accuracy: 60.00%\n",
      "Epoch 528, Loss: 0.45630601847840935, Test Loss: 0.6935583669290125, Train Accuracy: 56.44%, Test Accuracy: 60.00%\n",
      "Epoch 529, Loss: 0.4561136256583745, Test Loss: 0.6935616806404867, Train Accuracy: 57.00%, Test Accuracy: 60.00%\n",
      "Epoch 530, Loss: 0.4559214910879554, Test Loss: 0.6935650693383806, Train Accuracy: 56.78%, Test Accuracy: 60.00%\n",
      "Epoch 531, Loss: 0.45572961420429975, Test Loss: 0.6935685328095041, Train Accuracy: 55.61%, Test Accuracy: 60.00%\n",
      "Epoch 532, Loss: 0.45553799444611587, Test Loss: 0.6935720708413359, Train Accuracy: 56.28%, Test Accuracy: 59.50%\n",
      "Epoch 533, Loss: 0.4553466312536679, Test Loss: 0.6935756832220196, Train Accuracy: 56.50%, Test Accuracy: 59.50%\n",
      "Epoch 534, Loss: 0.45515552406877113, Test Loss: 0.6935793697403638, Train Accuracy: 57.28%, Test Accuracy: 59.50%\n",
      "Epoch 535, Loss: 0.45496467233478705, Test Loss: 0.6935831301858372, Train Accuracy: 57.28%, Test Accuracy: 59.50%\n",
      "Epoch 536, Loss: 0.4547740754966188, Test Loss: 0.6935869643485691, Train Accuracy: 56.39%, Test Accuracy: 59.50%\n",
      "Epoch 537, Loss: 0.4545837330007065, Test Loss: 0.6935908720193451, Train Accuracy: 56.06%, Test Accuracy: 59.50%\n",
      "Epoch 538, Loss: 0.4543936442950225, Test Loss: 0.6935948529896063, Train Accuracy: 55.00%, Test Accuracy: 59.50%\n",
      "Epoch 539, Loss: 0.4542038088290666, Test Loss: 0.6935989070514463, Train Accuracy: 57.22%, Test Accuracy: 59.50%\n",
      "Epoch 540, Loss: 0.45401422605386177, Test Loss: 0.6936030339976095, Train Accuracy: 56.89%, Test Accuracy: 59.50%\n",
      "Epoch 541, Loss: 0.45382489542194876, Test Loss: 0.6936072336214885, Train Accuracy: 56.56%, Test Accuracy: 59.50%\n",
      "Epoch 542, Loss: 0.45363581638738243, Test Loss: 0.6936115057171225, Train Accuracy: 56.67%, Test Accuracy: 59.50%\n",
      "Epoch 543, Loss: 0.4534469884057261, Test Loss: 0.6936158500791944, Train Accuracy: 56.28%, Test Accuracy: 59.50%\n",
      "Epoch 544, Loss: 0.45325841093404795, Test Loss: 0.6936202665030295, Train Accuracy: 57.28%, Test Accuracy: 59.50%\n",
      "Epoch 545, Loss: 0.4530700834309154, Test Loss: 0.6936247547845932, Train Accuracy: 55.61%, Test Accuracy: 59.50%\n",
      "Epoch 546, Loss: 0.4528820053563916, Test Loss: 0.6936293147204882, Train Accuracy: 55.28%, Test Accuracy: 59.50%\n",
      "Epoch 547, Loss: 0.4526941761720299, Test Loss: 0.6936339461079528, Train Accuracy: 56.94%, Test Accuracy: 59.50%\n",
      "Epoch 548, Loss: 0.45250659534086973, Test Loss: 0.6936386487448593, Train Accuracy: 57.39%, Test Accuracy: 59.50%\n",
      "Epoch 549, Loss: 0.45231926232743225, Test Loss: 0.693643422429711, Train Accuracy: 55.17%, Test Accuracy: 59.50%\n",
      "Epoch 550, Loss: 0.45213217659771543, Test Loss: 0.6936482669616404, Train Accuracy: 56.50%, Test Accuracy: 59.50%\n",
      "Epoch 551, Loss: 0.4519453376191897, Test Loss: 0.6936531821404079, Train Accuracy: 56.06%, Test Accuracy: 59.50%\n",
      "Epoch 552, Loss: 0.45175874486079354, Test Loss: 0.6936581677663983, Train Accuracy: 58.06%, Test Accuracy: 59.50%\n",
      "Epoch 553, Loss: 0.45157239779292857, Test Loss: 0.6936632236406198, Train Accuracy: 57.94%, Test Accuracy: 59.50%\n",
      "Epoch 554, Loss: 0.45138629588745594, Test Loss: 0.6936683495647015, Train Accuracy: 57.39%, Test Accuracy: 59.50%\n",
      "Epoch 555, Loss: 0.45120043861769066, Test Loss: 0.6936735453408912, Train Accuracy: 55.06%, Test Accuracy: 59.50%\n",
      "Epoch 556, Loss: 0.4510148254583983, Test Loss: 0.6936788107720537, Train Accuracy: 55.67%, Test Accuracy: 59.50%\n",
      "Epoch 557, Loss: 0.4508294558857899, Test Loss: 0.6936841456616688, Train Accuracy: 56.00%, Test Accuracy: 59.50%\n",
      "Epoch 558, Loss: 0.4506443293775175, Test Loss: 0.6936895498138287, Train Accuracy: 56.89%, Test Accuracy: 59.50%\n",
      "Epoch 559, Loss: 0.45045944541267013, Test Loss: 0.6936950230332366, Train Accuracy: 58.44%, Test Accuracy: 59.50%\n",
      "Epoch 560, Loss: 0.4502748034717692, Test Loss: 0.6937005651252042, Train Accuracy: 56.17%, Test Accuracy: 59.50%\n",
      "Epoch 561, Loss: 0.4500904030367639, Test Loss: 0.6937061758956498, Train Accuracy: 56.06%, Test Accuracy: 59.50%\n",
      "Epoch 562, Loss: 0.44990624359102727, Test Loss: 0.693711855151096, Train Accuracy: 59.17%, Test Accuracy: 59.50%\n",
      "Epoch 563, Loss: 0.4497223246193514, Test Loss: 0.6937176026986686, Train Accuracy: 56.72%, Test Accuracy: 59.50%\n",
      "Epoch 564, Loss: 0.4495386456079435, Test Loss: 0.6937234183460937, Train Accuracy: 57.06%, Test Accuracy: 59.50%\n",
      "Epoch 565, Loss: 0.44935520604442103, Test Loss: 0.693729301901696, Train Accuracy: 54.94%, Test Accuracy: 59.50%\n",
      "Epoch 566, Loss: 0.44917200541780794, Test Loss: 0.6937352531743965, Train Accuracy: 58.22%, Test Accuracy: 59.50%\n",
      "Epoch 567, Loss: 0.4489890432185301, Test Loss: 0.6937412719737114, Train Accuracy: 55.89%, Test Accuracy: 59.50%\n",
      "Epoch 568, Loss: 0.44880631893841094, Test Loss: 0.6937473581097489, Train Accuracy: 55.83%, Test Accuracy: 59.50%\n",
      "Epoch 569, Loss: 0.44862383207066703, Test Loss: 0.6937535113932077, Train Accuracy: 55.72%, Test Accuracy: 59.50%\n",
      "Epoch 570, Loss: 0.4484415821099045, Test Loss: 0.693759731635376, Train Accuracy: 54.06%, Test Accuracy: 59.50%\n",
      "Epoch 571, Loss: 0.4482595685521138, Test Loss: 0.6937660186481281, Train Accuracy: 57.06%, Test Accuracy: 59.50%\n",
      "Epoch 572, Loss: 0.4480777908946662, Test Loss: 0.6937723722439231, Train Accuracy: 57.06%, Test Accuracy: 59.50%\n",
      "Epoch 573, Loss: 0.44789624863630934, Test Loss: 0.6937787922358025, Train Accuracy: 57.00%, Test Accuracy: 59.50%\n",
      "Epoch 574, Loss: 0.44771494127716277, Test Loss: 0.6937852784373895, Train Accuracy: 57.00%, Test Accuracy: 59.50%\n",
      "Epoch 575, Loss: 0.44753386831871417, Test Loss: 0.6937918306628853, Train Accuracy: 57.00%, Test Accuracy: 59.50%\n",
      "Epoch 576, Loss: 0.4473530292638147, Test Loss: 0.6937984487270689, Train Accuracy: 56.44%, Test Accuracy: 59.50%\n",
      "Epoch 577, Loss: 0.4471724236166752, Test Loss: 0.6938051324452934, Train Accuracy: 56.89%, Test Accuracy: 59.50%\n",
      "Epoch 578, Loss: 0.4469920508828618, Test Loss: 0.6938118816334855, Train Accuracy: 56.50%, Test Accuracy: 59.50%\n",
      "Epoch 579, Loss: 0.44681191056929165, Test Loss: 0.6938186961081434, Train Accuracy: 55.61%, Test Accuracy: 59.50%\n",
      "Epoch 580, Loss: 0.4466320021842294, Test Loss: 0.6938255756863339, Train Accuracy: 56.72%, Test Accuracy: 59.50%\n",
      "Epoch 581, Loss: 0.4464523252372821, Test Loss: 0.6938325201856912, Train Accuracy: 57.61%, Test Accuracy: 59.50%\n",
      "Epoch 582, Loss: 0.44627287923939585, Test Loss: 0.693839529424416, Train Accuracy: 56.83%, Test Accuracy: 59.50%\n",
      "Epoch 583, Loss: 0.44609366370285153, Test Loss: 0.6938466032212713, Train Accuracy: 57.83%, Test Accuracy: 59.50%\n",
      "Epoch 584, Loss: 0.44591467814126023, Test Loss: 0.6938537413955825, Train Accuracy: 56.83%, Test Accuracy: 59.50%\n",
      "Epoch 585, Loss: 0.44573592206956, Test Loss: 0.693860943767235, Train Accuracy: 56.17%, Test Accuracy: 59.50%\n",
      "Epoch 586, Loss: 0.44555739500401076, Test Loss: 0.693868210156671, Train Accuracy: 55.28%, Test Accuracy: 59.50%\n",
      "Epoch 587, Loss: 0.4453790964621914, Test Loss: 0.69387554038489, Train Accuracy: 56.00%, Test Accuracy: 59.50%\n",
      "Epoch 588, Loss: 0.44520102596299477, Test Loss: 0.6938829342734455, Train Accuracy: 58.00%, Test Accuracy: 59.50%\n",
      "Epoch 589, Loss: 0.4450231830266241, Test Loss: 0.6938903916444431, Train Accuracy: 58.44%, Test Accuracy: 59.50%\n",
      "Epoch 590, Loss: 0.4448455671745887, Test Loss: 0.6938979123205388, Train Accuracy: 53.89%, Test Accuracy: 59.50%\n",
      "Epoch 591, Loss: 0.44466817792970037, Test Loss: 0.6939054961249376, Train Accuracy: 55.11%, Test Accuracy: 59.50%\n",
      "Epoch 592, Loss: 0.4444910148160692, Test Loss: 0.6939131428813912, Train Accuracy: 56.89%, Test Accuracy: 59.50%\n",
      "Epoch 593, Loss: 0.4443140773590993, Test Loss: 0.6939208524141963, Train Accuracy: 57.11%, Test Accuracy: 59.50%\n",
      "Epoch 594, Loss: 0.4441373650854851, Test Loss: 0.6939286245481927, Train Accuracy: 57.22%, Test Accuracy: 59.50%\n",
      "Epoch 595, Loss: 0.4439608775232078, Test Loss: 0.6939364591087619, Train Accuracy: 57.22%, Test Accuracy: 59.50%\n",
      "Epoch 596, Loss: 0.4437846142015303, Test Loss: 0.6939443559218245, Train Accuracy: 55.28%, Test Accuracy: 59.50%\n",
      "Epoch 597, Loss: 0.4436085746509943, Test Loss: 0.6939523148138391, Train Accuracy: 55.50%, Test Accuracy: 59.50%\n",
      "Epoch 598, Loss: 0.4434327584034162, Test Loss: 0.6939603356118001, Train Accuracy: 58.72%, Test Accuracy: 59.50%\n",
      "Epoch 599, Loss: 0.44325716499188267, Test Loss: 0.6939684181432365, Train Accuracy: 56.06%, Test Accuracy: 59.50%\n",
      "Epoch 600, Loss: 0.4430817939507472, Test Loss: 0.693976562236209, Train Accuracy: 56.61%, Test Accuracy: 59.50%\n",
      "Epoch 601, Loss: 0.4429066448156262, Test Loss: 0.6939847677193094, Train Accuracy: 59.17%, Test Accuracy: 59.50%\n",
      "Epoch 602, Loss: 0.44273171712339476, Test Loss: 0.693993034421658, Train Accuracy: 57.39%, Test Accuracy: 59.50%\n",
      "Epoch 603, Loss: 0.4425570104121833, Test Loss: 0.6940013621729022, Train Accuracy: 56.50%, Test Accuracy: 59.50%\n",
      "Epoch 604, Loss: 0.4423825242213734, Test Loss: 0.6940097508032147, Train Accuracy: 56.06%, Test Accuracy: 59.50%\n",
      "Epoch 605, Loss: 0.44220825809159375, Test Loss: 0.6940182001432921, Train Accuracy: 59.44%, Test Accuracy: 59.50%\n",
      "Epoch 606, Loss: 0.44203421156471695, Test Loss: 0.6940267100243518, Train Accuracy: 55.89%, Test Accuracy: 59.50%\n",
      "Epoch 607, Loss: 0.44186038418385515, Test Loss: 0.6940352802781321, Train Accuracy: 57.06%, Test Accuracy: 59.50%\n",
      "Epoch 608, Loss: 0.4416867754933564, Test Loss: 0.6940439107368891, Train Accuracy: 55.39%, Test Accuracy: 59.50%\n",
      "Epoch 609, Loss: 0.4415133850388007, Test Loss: 0.6940526012333958, Train Accuracy: 56.00%, Test Accuracy: 59.50%\n",
      "Epoch 610, Loss: 0.44134021236699694, Test Loss: 0.6940613516009395, Train Accuracy: 55.89%, Test Accuracy: 59.50%\n",
      "Epoch 611, Loss: 0.4411672570259781, Test Loss: 0.694070161673321, Train Accuracy: 53.89%, Test Accuracy: 59.50%\n",
      "Epoch 612, Loss: 0.4409945185649978, Test Loss: 0.6940790312848523, Train Accuracy: 57.50%, Test Accuracy: 59.50%\n",
      "Epoch 613, Loss: 0.44082199653452725, Test Loss: 0.6940879602703552, Train Accuracy: 55.94%, Test Accuracy: 59.50%\n",
      "Epoch 614, Loss: 0.44064969048625074, Test Loss: 0.6940969484651586, Train Accuracy: 57.06%, Test Accuracy: 59.50%\n",
      "Epoch 615, Loss: 0.44047759997306196, Test Loss: 0.6941059957050991, Train Accuracy: 56.61%, Test Accuracy: 59.50%\n",
      "Epoch 616, Loss: 0.4403057245490608, Test Loss: 0.6941151018265166, Train Accuracy: 55.94%, Test Accuracy: 59.50%\n",
      "Epoch 617, Loss: 0.4401340637695492, Test Loss: 0.6941242666662544, Train Accuracy: 54.83%, Test Accuracy: 59.50%\n",
      "Epoch 618, Loss: 0.4399626171910275, Test Loss: 0.6941334900616567, Train Accuracy: 58.61%, Test Accuracy: 59.50%\n",
      "Epoch 619, Loss: 0.4397913843711909, Test Loss: 0.6941427718505675, Train Accuracy: 54.78%, Test Accuracy: 59.50%\n",
      "Epoch 620, Loss: 0.4396203648689258, Test Loss: 0.6941521118713284, Train Accuracy: 57.44%, Test Accuracy: 59.50%\n",
      "Epoch 621, Loss: 0.4394495582443061, Test Loss: 0.694161509962777, Train Accuracy: 55.56%, Test Accuracy: 59.50%\n",
      "Epoch 622, Loss: 0.43927896405858924, Test Loss: 0.6941709659642459, Train Accuracy: 55.89%, Test Accuracy: 59.50%\n",
      "Epoch 623, Loss: 0.4391085818742133, Test Loss: 0.6941804797155597, Train Accuracy: 56.78%, Test Accuracy: 59.00%\n",
      "Epoch 624, Loss: 0.43893841125479266, Test Loss: 0.694190051057035, Train Accuracy: 56.11%, Test Accuracy: 59.00%\n",
      "Epoch 625, Loss: 0.43876845176511486, Test Loss: 0.6941996798294774, Train Accuracy: 57.67%, Test Accuracy: 59.00%\n",
      "Epoch 626, Loss: 0.43859870297113657, Test Loss: 0.6942093658741804, Train Accuracy: 57.67%, Test Accuracy: 59.00%\n",
      "Epoch 627, Loss: 0.4384291644399804, Test Loss: 0.6942191090329242, Train Accuracy: 54.56%, Test Accuracy: 59.00%\n",
      "Epoch 628, Loss: 0.43825983573993116, Test Loss: 0.6942289091479731, Train Accuracy: 54.94%, Test Accuracy: 59.00%\n",
      "Epoch 629, Loss: 0.43809071644043235, Test Loss: 0.6942387660620745, Train Accuracy: 56.28%, Test Accuracy: 59.00%\n",
      "Epoch 630, Loss: 0.43792180611208237, Test Loss: 0.694248679618457, Train Accuracy: 53.83%, Test Accuracy: 59.00%\n",
      "Epoch 631, Loss: 0.43775310432663117, Test Loss: 0.69425864966083, Train Accuracy: 57.44%, Test Accuracy: 59.00%\n",
      "Epoch 632, Loss: 0.437584610656977, Test Loss: 0.6942686760333797, Train Accuracy: 58.89%, Test Accuracy: 59.00%\n",
      "Epoch 633, Loss: 0.4374163246771623, Test Loss: 0.6942787585807693, Train Accuracy: 57.22%, Test Accuracy: 59.00%\n",
      "Epoch 634, Loss: 0.4372482459623705, Test Loss: 0.6942888971481375, Train Accuracy: 56.78%, Test Accuracy: 59.00%\n",
      "Epoch 635, Loss: 0.43708037408892275, Test Loss: 0.6942990915810958, Train Accuracy: 57.56%, Test Accuracy: 59.00%\n",
      "Epoch 636, Loss: 0.43691270863427384, Test Loss: 0.6943093417257277, Train Accuracy: 58.11%, Test Accuracy: 59.00%\n",
      "Epoch 637, Loss: 0.4367452491770092, Test Loss: 0.6943196474285862, Train Accuracy: 55.44%, Test Accuracy: 59.00%\n",
      "Epoch 638, Loss: 0.4365779952968415, Test Loss: 0.6943300085366941, Train Accuracy: 58.22%, Test Accuracy: 59.00%\n",
      "Epoch 639, Loss: 0.43641094657460683, Test Loss: 0.6943404248975408, Train Accuracy: 55.11%, Test Accuracy: 59.00%\n",
      "Epoch 640, Loss: 0.43624410259226126, Test Loss: 0.6943508963590804, Train Accuracy: 57.06%, Test Accuracy: 59.00%\n",
      "Epoch 641, Loss: 0.43607746293287775, Test Loss: 0.6943614227697325, Train Accuracy: 55.50%, Test Accuracy: 59.00%\n",
      "Epoch 642, Loss: 0.4359110271806426, Test Loss: 0.6943720039783773, Train Accuracy: 56.11%, Test Accuracy: 59.00%\n",
      "Epoch 643, Loss: 0.4357447949208517, Test Loss: 0.6943826398343569, Train Accuracy: 54.61%, Test Accuracy: 59.00%\n",
      "Epoch 644, Loss: 0.4355787657399079, Test Loss: 0.6943933301874727, Train Accuracy: 57.06%, Test Accuracy: 59.00%\n",
      "Epoch 645, Loss: 0.4354129392253164, Test Loss: 0.6944040748879834, Train Accuracy: 54.67%, Test Accuracy: 59.00%\n",
      "Epoch 646, Loss: 0.4352473149656828, Test Loss: 0.6944148737866043, Train Accuracy: 57.67%, Test Accuracy: 59.50%\n",
      "Epoch 647, Loss: 0.4350818925507086, Test Loss: 0.6944257267345045, Train Accuracy: 57.28%, Test Accuracy: 59.50%\n",
      "Epoch 648, Loss: 0.4349166715711883, Test Loss: 0.694436633583308, Train Accuracy: 55.44%, Test Accuracy: 59.50%\n",
      "Epoch 649, Loss: 0.43475165161900625, Test Loss: 0.6944475941850885, Train Accuracy: 57.44%, Test Accuracy: 59.50%\n",
      "Epoch 650, Loss: 0.4345868322871329, Test Loss: 0.694458608392371, Train Accuracy: 57.11%, Test Accuracy: 59.50%\n",
      "Epoch 651, Loss: 0.43442221316962165, Test Loss: 0.6944696760581288, Train Accuracy: 56.67%, Test Accuracy: 59.50%\n",
      "Epoch 652, Loss: 0.43425779386160546, Test Loss: 0.6944807970357825, Train Accuracy: 57.33%, Test Accuracy: 59.50%\n",
      "Epoch 653, Loss: 0.4340935739592938, Test Loss: 0.6944919711791977, Train Accuracy: 55.72%, Test Accuracy: 59.50%\n",
      "Epoch 654, Loss: 0.43392955305996905, Test Loss: 0.6945031983426847, Train Accuracy: 55.83%, Test Accuracy: 59.50%\n",
      "Epoch 655, Loss: 0.4337657307619833, Test Loss: 0.6945144783809962, Train Accuracy: 55.83%, Test Accuracy: 59.50%\n",
      "Epoch 656, Loss: 0.4336021066647552, Test Loss: 0.6945258111493265, Train Accuracy: 55.50%, Test Accuracy: 59.50%\n",
      "Epoch 657, Loss: 0.4334386803687667, Test Loss: 0.6945371965033089, Train Accuracy: 56.94%, Test Accuracy: 59.50%\n",
      "Epoch 658, Loss: 0.43327545147555935, Test Loss: 0.6945486342990155, Train Accuracy: 56.39%, Test Accuracy: 59.50%\n",
      "Epoch 659, Loss: 0.43311241958773167, Test Loss: 0.6945601243929547, Train Accuracy: 56.17%, Test Accuracy: 59.50%\n",
      "Epoch 660, Loss: 0.43294958430893565, Test Loss: 0.69457166664207, Train Accuracy: 57.94%, Test Accuracy: 59.50%\n",
      "Epoch 661, Loss: 0.43278694524387346, Test Loss: 0.6945832609037396, Train Accuracy: 56.72%, Test Accuracy: 59.50%\n",
      "Epoch 662, Loss: 0.43262450199829433, Test Loss: 0.6945949070357733, Train Accuracy: 55.61%, Test Accuracy: 59.50%\n",
      "Epoch 663, Loss: 0.4324622541789913, Test Loss: 0.6946066048964121, Train Accuracy: 56.61%, Test Accuracy: 59.50%\n",
      "Epoch 664, Loss: 0.43230020139379793, Test Loss: 0.6946183543443263, Train Accuracy: 56.94%, Test Accuracy: 59.50%\n",
      "Epoch 665, Loss: 0.4321383432515855, Test Loss: 0.6946301552386146, Train Accuracy: 55.17%, Test Accuracy: 59.50%\n",
      "Epoch 666, Loss: 0.43197667936225936, Test Loss: 0.6946420074388016, Train Accuracy: 57.17%, Test Accuracy: 59.50%\n",
      "Epoch 667, Loss: 0.43181520933675605, Test Loss: 0.6946539108048381, Train Accuracy: 55.83%, Test Accuracy: 59.50%\n",
      "Epoch 668, Loss: 0.4316539327870401, Test Loss: 0.6946658651970978, Train Accuracy: 56.06%, Test Accuracy: 59.50%\n",
      "Epoch 669, Loss: 0.4314928493261008, Test Loss: 0.694677870476377, Train Accuracy: 56.28%, Test Accuracy: 59.50%\n",
      "Epoch 670, Loss: 0.4313319585679492, Test Loss: 0.6946899265038929, Train Accuracy: 55.78%, Test Accuracy: 59.50%\n",
      "Epoch 671, Loss: 0.43117126012761486, Test Loss: 0.6947020331412829, Train Accuracy: 56.44%, Test Accuracy: 59.50%\n",
      "Epoch 672, Loss: 0.4310107536211428, Test Loss: 0.6947141902506011, Train Accuracy: 56.33%, Test Accuracy: 59.00%\n",
      "Epoch 673, Loss: 0.4308504386655905, Test Loss: 0.6947263976943197, Train Accuracy: 56.22%, Test Accuracy: 59.00%\n",
      "Epoch 674, Loss: 0.4306903148790244, Test Loss: 0.6947386553353252, Train Accuracy: 58.78%, Test Accuracy: 59.00%\n",
      "Epoch 675, Loss: 0.4305303818805176, Test Loss: 0.6947509630369189, Train Accuracy: 55.61%, Test Accuracy: 59.00%\n",
      "Epoch 676, Loss: 0.4303706392901459, Test Loss: 0.694763320662814, Train Accuracy: 56.89%, Test Accuracy: 59.00%\n",
      "Epoch 677, Loss: 0.4302110867289852, Test Loss: 0.6947757280771352, Train Accuracy: 56.44%, Test Accuracy: 59.00%\n",
      "Epoch 678, Loss: 0.4300517238191086, Test Loss: 0.6947881851444169, Train Accuracy: 57.89%, Test Accuracy: 59.00%\n",
      "Epoch 679, Loss: 0.4298925501835831, Test Loss: 0.6948006917296016, Train Accuracy: 57.00%, Test Accuracy: 59.00%\n",
      "Epoch 680, Loss: 0.42973356544646624, Test Loss: 0.6948132476980396, Train Accuracy: 55.67%, Test Accuracy: 59.00%\n",
      "Epoch 681, Loss: 0.42957476923280397, Test Loss: 0.6948258529154865, Train Accuracy: 56.44%, Test Accuracy: 59.00%\n",
      "Epoch 682, Loss: 0.42941616116862685, Test Loss: 0.6948385072481019, Train Accuracy: 57.11%, Test Accuracy: 59.00%\n",
      "Epoch 683, Loss: 0.4292577408809472, Test Loss: 0.694851210562449, Train Accuracy: 54.11%, Test Accuracy: 59.00%\n",
      "Epoch 684, Loss: 0.4290995079977565, Test Loss: 0.6948639627254923, Train Accuracy: 57.39%, Test Accuracy: 59.00%\n",
      "Epoch 685, Loss: 0.42894146214802187, Test Loss: 0.6948767636045967, Train Accuracy: 55.61%, Test Accuracy: 59.00%\n",
      "Epoch 686, Loss: 0.42878360296168344, Test Loss: 0.694889613067526, Train Accuracy: 55.56%, Test Accuracy: 59.00%\n",
      "Epoch 687, Loss: 0.42862593006965144, Test Loss: 0.6949025109824417, Train Accuracy: 56.22%, Test Accuracy: 59.00%\n",
      "Epoch 688, Loss: 0.4284684431038027, Test Loss: 0.6949154572179017, Train Accuracy: 54.72%, Test Accuracy: 59.00%\n",
      "Epoch 689, Loss: 0.42831114169697837, Test Loss: 0.6949284516428587, Train Accuracy: 56.83%, Test Accuracy: 59.00%\n",
      "Epoch 690, Loss: 0.4281540254829808, Test Loss: 0.6949414941266591, Train Accuracy: 56.50%, Test Accuracy: 59.00%\n",
      "Epoch 691, Loss: 0.4279970940965703, Test Loss: 0.6949545845390415, Train Accuracy: 54.39%, Test Accuracy: 59.00%\n",
      "Epoch 692, Loss: 0.42784034717346253, Test Loss: 0.6949677227501364, Train Accuracy: 57.50%, Test Accuracy: 59.00%\n",
      "Epoch 693, Loss: 0.42768378435032534, Test Loss: 0.6949809086304626, Train Accuracy: 55.72%, Test Accuracy: 59.00%\n",
      "Epoch 694, Loss: 0.4275274052647763, Test Loss: 0.6949941420509288, Train Accuracy: 55.78%, Test Accuracy: 59.00%\n",
      "Epoch 695, Loss: 0.4273712095553794, Test Loss: 0.6950074228828295, Train Accuracy: 55.44%, Test Accuracy: 59.00%\n",
      "Epoch 696, Loss: 0.4272151968616422, Test Loss: 0.6950207509978461, Train Accuracy: 56.78%, Test Accuracy: 59.00%\n",
      "Epoch 697, Loss: 0.42705936682401324, Test Loss: 0.6950341262680442, Train Accuracy: 57.44%, Test Accuracy: 59.00%\n",
      "Epoch 698, Loss: 0.42690371908387886, Test Loss: 0.6950475485658723, Train Accuracy: 57.33%, Test Accuracy: 59.00%\n",
      "Epoch 699, Loss: 0.4267482532835606, Test Loss: 0.6950610177641613, Train Accuracy: 56.89%, Test Accuracy: 59.00%\n",
      "Epoch 700, Loss: 0.42659296906631217, Test Loss: 0.6950745337361229, Train Accuracy: 57.67%, Test Accuracy: 59.00%\n",
      "Epoch 701, Loss: 0.4264378660763166, Test Loss: 0.6950880963553483, Train Accuracy: 55.33%, Test Accuracy: 59.00%\n",
      "Epoch 702, Loss: 0.42628294395868377, Test Loss: 0.6951017054958064, Train Accuracy: 57.33%, Test Accuracy: 59.00%\n",
      "Epoch 703, Loss: 0.4261282023594469, Test Loss: 0.6951153610318435, Train Accuracy: 55.22%, Test Accuracy: 59.00%\n",
      "Epoch 704, Loss: 0.4259736409255606, Test Loss: 0.695129062838181, Train Accuracy: 56.56%, Test Accuracy: 59.00%\n",
      "Epoch 705, Loss: 0.42581925930489734, Test Loss: 0.6951428107899156, Train Accuracy: 54.78%, Test Accuracy: 59.00%\n",
      "Epoch 706, Loss: 0.4256650571462451, Test Loss: 0.6951566047625164, Train Accuracy: 56.56%, Test Accuracy: 59.00%\n",
      "Epoch 707, Loss: 0.42551103409930424, Test Loss: 0.6951704446318248, Train Accuracy: 55.17%, Test Accuracy: 59.00%\n",
      "Epoch 708, Loss: 0.42535718981468523, Test Loss: 0.6951843302740528, Train Accuracy: 55.17%, Test Accuracy: 59.00%\n",
      "Epoch 709, Loss: 0.4252035239439054, Test Loss: 0.695198261565782, Train Accuracy: 56.94%, Test Accuracy: 59.00%\n",
      "Epoch 710, Loss: 0.42505003613938636, Test Loss: 0.695212238383962, Train Accuracy: 56.72%, Test Accuracy: 59.00%\n",
      "Epoch 711, Loss: 0.42489672605445133, Test Loss: 0.6952262606059091, Train Accuracy: 55.50%, Test Accuracy: 59.00%\n",
      "Epoch 712, Loss: 0.4247435933433223, Test Loss: 0.6952403281093064, Train Accuracy: 56.00%, Test Accuracy: 59.00%\n",
      "Epoch 713, Loss: 0.42459063766111727, Test Loss: 0.6952544407722003, Train Accuracy: 56.67%, Test Accuracy: 59.00%\n",
      "Epoch 714, Loss: 0.42443785866384787, Test Loss: 0.6952685984730016, Train Accuracy: 57.22%, Test Accuracy: 59.00%\n",
      "Epoch 715, Loss: 0.424285256008416, Test Loss: 0.6952828010904823, Train Accuracy: 56.56%, Test Accuracy: 59.00%\n",
      "Epoch 716, Loss: 0.4241328293526118, Test Loss: 0.6952970485037766, Train Accuracy: 55.89%, Test Accuracy: 59.00%\n",
      "Epoch 717, Loss: 0.42398057835511055, Test Loss: 0.6953113405923769, Train Accuracy: 56.50%, Test Accuracy: 59.00%\n",
      "Epoch 718, Loss: 0.4238285026754702, Test Loss: 0.6953256772361351, Train Accuracy: 56.50%, Test Accuracy: 59.00%\n",
      "Epoch 719, Loss: 0.42367660197412843, Test Loss: 0.6953400583152604, Train Accuracy: 57.39%, Test Accuracy: 59.00%\n",
      "Epoch 720, Loss: 0.4235248759124003, Test Loss: 0.6953544837103176, Train Accuracy: 58.39%, Test Accuracy: 59.00%\n",
      "Epoch 721, Loss: 0.42337332415247525, Test Loss: 0.695368953302227, Train Accuracy: 54.39%, Test Accuracy: 59.00%\n",
      "Epoch 722, Loss: 0.423221946357415, Test Loss: 0.6953834669722625, Train Accuracy: 55.61%, Test Accuracy: 59.00%\n",
      "Epoch 723, Loss: 0.42307074219115026, Test Loss: 0.6953980246020507, Train Accuracy: 56.28%, Test Accuracy: 59.00%\n",
      "Epoch 724, Loss: 0.4229197113184785, Test Loss: 0.6954126260735695, Train Accuracy: 55.83%, Test Accuracy: 59.00%\n",
      "Epoch 725, Loss: 0.42276885340506104, Test Loss: 0.6954272712691468, Train Accuracy: 56.00%, Test Accuracy: 59.00%\n",
      "Epoch 726, Loss: 0.42261816811742087, Test Loss: 0.6954419600714604, Train Accuracy: 54.89%, Test Accuracy: 59.00%\n",
      "Epoch 727, Loss: 0.42246765512293966, Test Loss: 0.6954566923635354, Train Accuracy: 56.00%, Test Accuracy: 59.00%\n",
      "Epoch 728, Loss: 0.42231731408985546, Test Loss: 0.6954714680287437, Train Accuracy: 59.44%, Test Accuracy: 58.50%\n",
      "Epoch 729, Loss: 0.4221671446872596, Test Loss: 0.6954862869508028, Train Accuracy: 57.89%, Test Accuracy: 58.50%\n",
      "Epoch 730, Loss: 0.4220171465850944, Test Loss: 0.6955011490137752, Train Accuracy: 56.94%, Test Accuracy: 58.50%\n",
      "Epoch 731, Loss: 0.4218673194541514, Test Loss: 0.6955160541020666, Train Accuracy: 56.39%, Test Accuracy: 58.50%\n",
      "Epoch 732, Loss: 0.42171766296606716, Test Loss: 0.6955310021004243, Train Accuracy: 54.94%, Test Accuracy: 58.50%\n",
      "Epoch 733, Loss: 0.421568176793322, Test Loss: 0.6955459928939374, Train Accuracy: 55.83%, Test Accuracy: 59.00%\n",
      "Epoch 734, Loss: 0.4214188606092369, Test Loss: 0.6955610263680342, Train Accuracy: 55.50%, Test Accuracy: 59.00%\n",
      "Epoch 735, Loss: 0.42126971408797126, Test Loss: 0.6955761024084822, Train Accuracy: 57.28%, Test Accuracy: 59.00%\n",
      "Epoch 736, Loss: 0.42112073690452007, Test Loss: 0.6955912209013871, Train Accuracy: 55.61%, Test Accuracy: 59.00%\n",
      "Epoch 737, Loss: 0.42097192873471156, Test Loss: 0.6956063817331904, Train Accuracy: 59.61%, Test Accuracy: 59.00%\n",
      "Epoch 738, Loss: 0.42082328925520457, Test Loss: 0.6956215847906695, Train Accuracy: 56.72%, Test Accuracy: 59.00%\n",
      "Epoch 739, Loss: 0.4206748181434863, Test Loss: 0.6956368299609358, Train Accuracy: 56.39%, Test Accuracy: 59.00%\n",
      "Epoch 740, Loss: 0.4205265150778693, Test Loss: 0.6956521171314337, Train Accuracy: 55.44%, Test Accuracy: 59.00%\n",
      "Epoch 741, Loss: 0.4203783797374896, Test Loss: 0.6956674461899407, Train Accuracy: 57.44%, Test Accuracy: 59.00%\n",
      "Epoch 742, Loss: 0.4202304118023039, Test Loss: 0.6956828170245644, Train Accuracy: 56.61%, Test Accuracy: 59.00%\n",
      "Epoch 743, Loss: 0.420082610953087, Test Loss: 0.6956982295237424, Train Accuracy: 54.78%, Test Accuracy: 59.00%\n",
      "Epoch 744, Loss: 0.4199349768714296, Test Loss: 0.695713683576242, Train Accuracy: 56.33%, Test Accuracy: 59.00%\n",
      "Epoch 745, Loss: 0.4197875092397356, Test Loss: 0.6957291790711571, Train Accuracy: 54.89%, Test Accuracy: 59.00%\n",
      "Epoch 746, Loss: 0.41964020774121985, Test Loss: 0.6957447158979088, Train Accuracy: 55.67%, Test Accuracy: 59.00%\n",
      "Epoch 747, Loss: 0.4194930720599055, Test Loss: 0.695760293946244, Train Accuracy: 58.33%, Test Accuracy: 59.00%\n",
      "Epoch 748, Loss: 0.4193461018806216, Test Loss: 0.6957759131062334, Train Accuracy: 54.00%, Test Accuracy: 59.00%\n",
      "Epoch 749, Loss: 0.419199296889001, Test Loss: 0.6957915732682721, Train Accuracy: 54.78%, Test Accuracy: 59.00%\n",
      "Epoch 750, Loss: 0.41905265677147757, Test Loss: 0.6958072743230765, Train Accuracy: 56.78%, Test Accuracy: 59.00%\n",
      "Epoch 751, Loss: 0.4189061812152838, Test Loss: 0.695823016161685, Train Accuracy: 55.78%, Test Accuracy: 59.00%\n",
      "Epoch 752, Loss: 0.41875986990844866, Test Loss: 0.695838798675456, Train Accuracy: 57.00%, Test Accuracy: 59.00%\n",
      "Epoch 753, Loss: 0.4186137225397949, Test Loss: 0.6958546217560669, Train Accuracy: 56.00%, Test Accuracy: 59.00%\n",
      "Epoch 754, Loss: 0.4184677387989369, Test Loss: 0.6958704852955134, Train Accuracy: 55.44%, Test Accuracy: 59.00%\n",
      "Epoch 755, Loss: 0.41832191837627813, Test Loss: 0.6958863891861086, Train Accuracy: 55.06%, Test Accuracy: 59.00%\n",
      "Epoch 756, Loss: 0.4181762609630088, Test Loss: 0.6959023333204806, Train Accuracy: 57.44%, Test Accuracy: 59.00%\n",
      "Epoch 757, Loss: 0.4180307662511037, Test Loss: 0.6959183175915734, Train Accuracy: 56.33%, Test Accuracy: 59.00%\n",
      "Epoch 758, Loss: 0.41788543393331945, Test Loss: 0.6959343418926446, Train Accuracy: 55.11%, Test Accuracy: 59.00%\n",
      "Epoch 759, Loss: 0.41774026370319267, Test Loss: 0.6959504061172648, Train Accuracy: 57.11%, Test Accuracy: 59.00%\n",
      "Epoch 760, Loss: 0.41759525525503705, Test Loss: 0.695966510159316, Train Accuracy: 55.78%, Test Accuracy: 59.00%\n",
      "Epoch 761, Loss: 0.41745040828394153, Test Loss: 0.6959826539129916, Train Accuracy: 54.33%, Test Accuracy: 59.00%\n",
      "Epoch 762, Loss: 0.41730572248576764, Test Loss: 0.6959988372727944, Train Accuracy: 54.56%, Test Accuracy: 59.00%\n",
      "Epoch 763, Loss: 0.4171611975571472, Test Loss: 0.6960150601335363, Train Accuracy: 56.56%, Test Accuracy: 59.00%\n",
      "Epoch 764, Loss: 0.41701683319548055, Test Loss: 0.6960313223903364, Train Accuracy: 57.78%, Test Accuracy: 59.00%\n",
      "Epoch 765, Loss: 0.4168726290989332, Test Loss: 0.6960476239386213, Train Accuracy: 56.00%, Test Accuracy: 59.00%\n",
      "Epoch 766, Loss: 0.41672858496643456, Test Loss: 0.6960639646741226, Train Accuracy: 57.00%, Test Accuracy: 59.00%\n",
      "Epoch 767, Loss: 0.41658470049767526, Test Loss: 0.6960803444928771, Train Accuracy: 55.22%, Test Accuracy: 59.00%\n",
      "Epoch 768, Loss: 0.41644097539310443, Test Loss: 0.6960967632912249, Train Accuracy: 56.78%, Test Accuracy: 59.00%\n",
      "Epoch 769, Loss: 0.4162974093539282, Test Loss: 0.6961132209658095, Train Accuracy: 59.56%, Test Accuracy: 59.00%\n",
      "Epoch 770, Loss: 0.41615400208210707, Test Loss: 0.6961297174135751, Train Accuracy: 55.44%, Test Accuracy: 59.00%\n",
      "Epoch 771, Loss: 0.41601075328035336, Test Loss: 0.6961462525317674, Train Accuracy: 56.94%, Test Accuracy: 59.00%\n",
      "Epoch 772, Loss: 0.4158676626521295, Test Loss: 0.6961628262179316, Train Accuracy: 55.94%, Test Accuracy: 59.00%\n",
      "Epoch 773, Loss: 0.41572472990164555, Test Loss: 0.6961794383699115, Train Accuracy: 54.06%, Test Accuracy: 59.00%\n",
      "Epoch 774, Loss: 0.4155819547338567, Test Loss: 0.6961960888858489, Train Accuracy: 58.39%, Test Accuracy: 59.00%\n",
      "Epoch 775, Loss: 0.41543933685446166, Test Loss: 0.6962127776641822, Train Accuracy: 56.72%, Test Accuracy: 59.00%\n",
      "Epoch 776, Loss: 0.4152968759698997, Test Loss: 0.6962295046036455, Train Accuracy: 56.50%, Test Accuracy: 59.00%\n",
      "Epoch 777, Loss: 0.41515457178734905, Test Loss: 0.696246269603268, Train Accuracy: 56.28%, Test Accuracy: 59.00%\n",
      "Epoch 778, Loss: 0.4150124240147243, Test Loss: 0.6962630725623724, Train Accuracy: 55.44%, Test Accuracy: 59.00%\n",
      "Epoch 779, Loss: 0.4148704323606744, Test Loss: 0.6962799133805746, Train Accuracy: 59.22%, Test Accuracy: 59.00%\n",
      "Epoch 780, Loss: 0.41472859653458033, Test Loss: 0.6962967919577824, Train Accuracy: 57.11%, Test Accuracy: 59.00%\n",
      "Epoch 781, Loss: 0.4145869162465533, Test Loss: 0.6963137081941941, Train Accuracy: 56.78%, Test Accuracy: 59.00%\n",
      "Epoch 782, Loss: 0.4144453912074318, Test Loss: 0.6963306619902987, Train Accuracy: 54.11%, Test Accuracy: 59.00%\n",
      "Epoch 783, Loss: 0.41430402112878006, Test Loss: 0.6963476532468736, Train Accuracy: 56.67%, Test Accuracy: 59.00%\n",
      "Epoch 784, Loss: 0.41416280572288605, Test Loss: 0.6963646818649846, Train Accuracy: 57.94%, Test Accuracy: 59.00%\n",
      "Epoch 785, Loss: 0.4140217447027585, Test Loss: 0.6963817477459849, Train Accuracy: 56.28%, Test Accuracy: 59.00%\n",
      "Epoch 786, Loss: 0.41388083778212553, Test Loss: 0.6963988507915135, Train Accuracy: 55.39%, Test Accuracy: 59.00%\n",
      "Epoch 787, Loss: 0.413740084675432, Test Loss: 0.6964159909034946, Train Accuracy: 56.06%, Test Accuracy: 59.00%\n",
      "Epoch 788, Loss: 0.41359948509783795, Test Loss: 0.6964331679841372, Train Accuracy: 56.50%, Test Accuracy: 59.00%\n",
      "Epoch 789, Loss: 0.4134590387652156, Test Loss: 0.6964503819359331, Train Accuracy: 55.28%, Test Accuracy: 59.00%\n",
      "Epoch 790, Loss: 0.41331874539414815, Test Loss: 0.6964676326616572, Train Accuracy: 55.94%, Test Accuracy: 59.00%\n",
      "Epoch 791, Loss: 0.41317860470192713, Test Loss: 0.6964849200643655, Train Accuracy: 54.94%, Test Accuracy: 59.00%\n",
      "Epoch 792, Loss: 0.41303861640655026, Test Loss: 0.6965022440473948, Train Accuracy: 57.50%, Test Accuracy: 59.00%\n",
      "Epoch 793, Loss: 0.41289878022671966, Test Loss: 0.6965196045143611, Train Accuracy: 57.28%, Test Accuracy: 59.00%\n",
      "Epoch 794, Loss: 0.4127590958818395, Test Loss: 0.6965370013691602, Train Accuracy: 56.61%, Test Accuracy: 59.00%\n",
      "Epoch 795, Loss: 0.41261956309201403, Test Loss: 0.6965544345159647, Train Accuracy: 55.28%, Test Accuracy: 59.00%\n",
      "Epoch 796, Loss: 0.41248018157804556, Test Loss: 0.6965719038592249, Train Accuracy: 55.50%, Test Accuracy: 59.00%\n",
      "Epoch 797, Loss: 0.4123409510614321, Test Loss: 0.6965894093036665, Train Accuracy: 53.33%, Test Accuracy: 59.00%\n",
      "Epoch 798, Loss: 0.41220187126436564, Test Loss: 0.6966069507542909, Train Accuracy: 57.11%, Test Accuracy: 59.00%\n",
      "Epoch 799, Loss: 0.41206294190972975, Test Loss: 0.6966245281163737, Train Accuracy: 56.89%, Test Accuracy: 59.00%\n",
      "Epoch 800, Loss: 0.41192416272109805, Test Loss: 0.6966421412954631, Train Accuracy: 55.67%, Test Accuracy: 59.00%\n",
      "Epoch 801, Loss: 0.4117855334227315, Test Loss: 0.6966597901973808, Train Accuracy: 57.28%, Test Accuracy: 59.00%\n",
      "Epoch 802, Loss: 0.41164705373957683, Test Loss: 0.6966774747282193, Train Accuracy: 54.61%, Test Accuracy: 59.00%\n",
      "Epoch 803, Loss: 0.4115087233972641, Test Loss: 0.696695194794342, Train Accuracy: 56.83%, Test Accuracy: 59.00%\n",
      "Epoch 804, Loss: 0.4113705421221054, Test Loss: 0.6967129503023819, Train Accuracy: 58.50%, Test Accuracy: 59.00%\n",
      "Epoch 805, Loss: 0.4112325096410919, Test Loss: 0.6967307411592413, Train Accuracy: 55.17%, Test Accuracy: 59.00%\n",
      "Epoch 806, Loss: 0.41109462568189253, Test Loss: 0.69674856727209, Train Accuracy: 55.39%, Test Accuracy: 59.00%\n",
      "Epoch 807, Loss: 0.4109568899728516, Test Loss: 0.6967664285483656, Train Accuracy: 57.50%, Test Accuracy: 59.00%\n",
      "Epoch 808, Loss: 0.41081930224298724, Test Loss: 0.6967843248957712, Train Accuracy: 55.94%, Test Accuracy: 59.00%\n",
      "Epoch 809, Loss: 0.4106818622219885, Test Loss: 0.6968022562222758, Train Accuracy: 54.94%, Test Accuracy: 59.00%\n",
      "Epoch 810, Loss: 0.4105445696402145, Test Loss: 0.6968202224361129, Train Accuracy: 55.72%, Test Accuracy: 59.00%\n",
      "Epoch 811, Loss: 0.4104074242286917, Test Loss: 0.696838223445779, Train Accuracy: 55.28%, Test Accuracy: 59.00%\n",
      "Epoch 812, Loss: 0.41027042571911204, Test Loss: 0.6968562591600344, Train Accuracy: 57.39%, Test Accuracy: 59.00%\n",
      "Epoch 813, Loss: 0.4101335738438312, Test Loss: 0.6968743294879005, Train Accuracy: 55.61%, Test Accuracy: 59.00%\n",
      "Epoch 814, Loss: 0.4099968683358664, Test Loss: 0.6968924343386607, Train Accuracy: 56.39%, Test Accuracy: 59.00%\n",
      "Epoch 815, Loss: 0.4098603089288945, Test Loss: 0.6969105736218575, Train Accuracy: 55.94%, Test Accuracy: 59.00%\n",
      "Epoch 816, Loss: 0.40972389535725035, Test Loss: 0.6969287472472934, Train Accuracy: 56.72%, Test Accuracy: 59.00%\n",
      "Epoch 817, Loss: 0.40958762735592413, Test Loss: 0.6969469551250296, Train Accuracy: 54.89%, Test Accuracy: 59.00%\n",
      "Epoch 818, Loss: 0.40945150466056024, Test Loss: 0.6969651971653849, Train Accuracy: 55.44%, Test Accuracy: 59.00%\n",
      "Epoch 819, Loss: 0.40931552700745494, Test Loss: 0.6969834732789346, Train Accuracy: 55.44%, Test Accuracy: 59.00%\n",
      "Epoch 820, Loss: 0.4091796941335541, Test Loss: 0.6970017833765101, Train Accuracy: 57.44%, Test Accuracy: 59.00%\n",
      "Epoch 821, Loss: 0.4090440057764523, Test Loss: 0.6970201273691987, Train Accuracy: 54.78%, Test Accuracy: 59.00%\n",
      "Epoch 822, Loss: 0.4089084616743897, Test Loss: 0.6970385051683406, Train Accuracy: 55.67%, Test Accuracy: 59.00%\n",
      "Epoch 823, Loss: 0.40877306156625093, Test Loss: 0.697056916685531, Train Accuracy: 53.67%, Test Accuracy: 58.50%\n",
      "Epoch 824, Loss: 0.4086378051915632, Test Loss: 0.6970753618326171, Train Accuracy: 56.89%, Test Accuracy: 58.50%\n",
      "Epoch 825, Loss: 0.4085026922904937, Test Loss: 0.6970938405216981, Train Accuracy: 55.67%, Test Accuracy: 58.50%\n",
      "Epoch 826, Loss: 0.40836772260384857, Test Loss: 0.6971123526651237, Train Accuracy: 54.67%, Test Accuracy: 58.50%\n",
      "Epoch 827, Loss: 0.4082328958730703, Test Loss: 0.6971308981754949, Train Accuracy: 55.56%, Test Accuracy: 58.50%\n",
      "Epoch 828, Loss: 0.40809821184023665, Test Loss: 0.6971494769656611, Train Accuracy: 54.67%, Test Accuracy: 58.50%\n",
      "Epoch 829, Loss: 0.4079636702480581, Test Loss: 0.6971680889487212, Train Accuracy: 55.61%, Test Accuracy: 58.50%\n",
      "Epoch 830, Loss: 0.4078292708398757, Test Loss: 0.6971867340380211, Train Accuracy: 56.17%, Test Accuracy: 58.50%\n",
      "Epoch 831, Loss: 0.4076950133596606, Test Loss: 0.6972054121471541, Train Accuracy: 55.61%, Test Accuracy: 58.50%\n",
      "Epoch 832, Loss: 0.40756089755201086, Test Loss: 0.69722412318996, Train Accuracy: 56.17%, Test Accuracy: 58.50%\n",
      "Epoch 833, Loss: 0.4074269231621499, Test Loss: 0.6972428670805229, Train Accuracy: 56.61%, Test Accuracy: 58.50%\n",
      "Epoch 834, Loss: 0.40729308993592517, Test Loss: 0.6972616437331728, Train Accuracy: 55.61%, Test Accuracy: 58.50%\n",
      "Epoch 835, Loss: 0.4071593976198059, Test Loss: 0.6972804530624824, Train Accuracy: 56.67%, Test Accuracy: 58.50%\n",
      "Epoch 836, Loss: 0.40702584596088104, Test Loss: 0.6972992949832687, Train Accuracy: 57.22%, Test Accuracy: 58.50%\n",
      "Epoch 837, Loss: 0.4068924347068581, Test Loss: 0.6973181694105893, Train Accuracy: 56.00%, Test Accuracy: 58.50%\n",
      "Epoch 838, Loss: 0.4067591636060609, Test Loss: 0.6973370762597446, Train Accuracy: 56.67%, Test Accuracy: 58.50%\n",
      "Epoch 839, Loss: 0.40662603240742773, Test Loss: 0.6973560154462749, Train Accuracy: 54.22%, Test Accuracy: 58.50%\n",
      "Epoch 840, Loss: 0.40649304086050964, Test Loss: 0.6973749868859604, Train Accuracy: 55.56%, Test Accuracy: 58.50%\n",
      "Epoch 841, Loss: 0.4063601887154688, Test Loss: 0.6973939904948208, Train Accuracy: 55.56%, Test Accuracy: 58.50%\n",
      "Epoch 842, Loss: 0.4062274757230765, Test Loss: 0.6974130261891136, Train Accuracy: 56.33%, Test Accuracy: 58.50%\n",
      "Epoch 843, Loss: 0.40609490163471124, Test Loss: 0.6974320938853344, Train Accuracy: 57.83%, Test Accuracy: 58.50%\n",
      "Epoch 844, Loss: 0.40596246620235754, Test Loss: 0.6974511935002152, Train Accuracy: 56.39%, Test Accuracy: 58.50%\n",
      "Epoch 845, Loss: 0.4058301691786035, Test Loss: 0.697470324950724, Train Accuracy: 55.28%, Test Accuracy: 58.50%\n",
      "Epoch 846, Loss: 0.4056980103166391, Test Loss: 0.6974894881540642, Train Accuracy: 55.61%, Test Accuracy: 58.50%\n",
      "Epoch 847, Loss: 0.40556598937025506, Test Loss: 0.6975086830276738, Train Accuracy: 57.50%, Test Accuracy: 58.50%\n",
      "Epoch 848, Loss: 0.40543410609384045, Test Loss: 0.6975279094892237, Train Accuracy: 53.94%, Test Accuracy: 58.50%\n",
      "Epoch 849, Loss: 0.40530236024238114, Test Loss: 0.6975471674566188, Train Accuracy: 55.56%, Test Accuracy: 58.50%\n",
      "Epoch 850, Loss: 0.40517075157145793, Test Loss: 0.6975664568479957, Train Accuracy: 56.83%, Test Accuracy: 58.50%\n",
      "Epoch 851, Loss: 0.4050392798372452, Test Loss: 0.6975857775817227, Train Accuracy: 57.33%, Test Accuracy: 58.50%\n",
      "Epoch 852, Loss: 0.40490794479650877, Test Loss: 0.6976051295763983, Train Accuracy: 54.67%, Test Accuracy: 58.50%\n",
      "Epoch 853, Loss: 0.40477674620660425, Test Loss: 0.6976245127508517, Train Accuracy: 56.67%, Test Accuracy: 58.50%\n",
      "Epoch 854, Loss: 0.4046456838254756, Test Loss: 0.6976439270241406, Train Accuracy: 55.11%, Test Accuracy: 58.50%\n",
      "Epoch 855, Loss: 0.4045147574116529, Test Loss: 0.6976633723155513, Train Accuracy: 56.22%, Test Accuracy: 58.50%\n",
      "Epoch 856, Loss: 0.4043839667242511, Test Loss: 0.6976828485445986, Train Accuracy: 55.39%, Test Accuracy: 58.50%\n",
      "Epoch 857, Loss: 0.40425331152296823, Test Loss: 0.6977023556310235, Train Accuracy: 56.83%, Test Accuracy: 58.50%\n",
      "Epoch 858, Loss: 0.40412279156808345, Test Loss: 0.6977218934947933, Train Accuracy: 55.28%, Test Accuracy: 58.50%\n",
      "Epoch 859, Loss: 0.40399240662045555, Test Loss: 0.6977414620561015, Train Accuracy: 57.28%, Test Accuracy: 58.50%\n",
      "Epoch 860, Loss: 0.4038621564415213, Test Loss: 0.6977610612353655, Train Accuracy: 56.39%, Test Accuracy: 58.50%\n",
      "Epoch 861, Loss: 0.40373204079329356, Test Loss: 0.6977806909532274, Train Accuracy: 56.72%, Test Accuracy: 58.50%\n",
      "Epoch 862, Loss: 0.4036020594383599, Test Loss: 0.6978003511305526, Train Accuracy: 55.11%, Test Accuracy: 58.50%\n",
      "Epoch 863, Loss: 0.4034722121398807, Test Loss: 0.6978200416884291, Train Accuracy: 55.56%, Test Accuracy: 58.50%\n",
      "Epoch 864, Loss: 0.4033424986615875, Test Loss: 0.6978397625481665, Train Accuracy: 56.44%, Test Accuracy: 58.50%\n",
      "Epoch 865, Loss: 0.4032129187677814, Test Loss: 0.6978595136312962, Train Accuracy: 57.72%, Test Accuracy: 58.50%\n",
      "Epoch 866, Loss: 0.4030834722233314, Test Loss: 0.6978792948595697, Train Accuracy: 53.00%, Test Accuracy: 58.50%\n",
      "Epoch 867, Loss: 0.40295415879367275, Test Loss: 0.6978991061549581, Train Accuracy: 54.78%, Test Accuracy: 58.50%\n",
      "Epoch 868, Loss: 0.4028249782448053, Test Loss: 0.6979189474396521, Train Accuracy: 55.44%, Test Accuracy: 58.50%\n",
      "Epoch 869, Loss: 0.40269593034329165, Test Loss: 0.6979388186360606, Train Accuracy: 55.44%, Test Accuracy: 58.50%\n",
      "Epoch 870, Loss: 0.40256701485625607, Test Loss: 0.69795871966681, Train Accuracy: 56.44%, Test Accuracy: 58.50%\n",
      "Epoch 871, Loss: 0.40243823155138214, Test Loss: 0.6979786504547439, Train Accuracy: 54.89%, Test Accuracy: 58.50%\n",
      "Epoch 872, Loss: 0.40230958019691176, Test Loss: 0.6979986109229219, Train Accuracy: 55.00%, Test Accuracy: 58.50%\n",
      "Epoch 873, Loss: 0.40218106056164304, Test Loss: 0.6980186009946194, Train Accuracy: 55.67%, Test Accuracy: 58.50%\n",
      "Epoch 874, Loss: 0.4020526724149292, Test Loss: 0.6980386205933266, Train Accuracy: 56.00%, Test Accuracy: 58.50%\n",
      "Epoch 875, Loss: 0.40192441552667635, Test Loss: 0.6980586696427477, Train Accuracy: 56.00%, Test Accuracy: 58.50%\n",
      "Epoch 876, Loss: 0.4017962896673424, Test Loss: 0.698078748066801, Train Accuracy: 55.44%, Test Accuracy: 58.50%\n",
      "Epoch 877, Loss: 0.40166829460793513, Test Loss: 0.6980988557896168, Train Accuracy: 55.22%, Test Accuracy: 58.50%\n",
      "Epoch 878, Loss: 0.40154043012001106, Test Loss: 0.6981189927355385, Train Accuracy: 56.11%, Test Accuracy: 58.50%\n",
      "Epoch 879, Loss: 0.401412695975673, Test Loss: 0.6981391588291198, Train Accuracy: 57.78%, Test Accuracy: 58.50%\n",
      "Epoch 880, Loss: 0.40128509194756945, Test Loss: 0.6981593539951264, Train Accuracy: 54.89%, Test Accuracy: 58.50%\n",
      "Epoch 881, Loss: 0.4011576178088924, Test Loss: 0.698179578158533, Train Accuracy: 55.33%, Test Accuracy: 58.50%\n",
      "Epoch 882, Loss: 0.4010302733333759, Test Loss: 0.6981998312445248, Train Accuracy: 56.33%, Test Accuracy: 58.50%\n",
      "Epoch 883, Loss: 0.40090305829529443, Test Loss: 0.6982201131784944, Train Accuracy: 55.44%, Test Accuracy: 58.50%\n",
      "Epoch 884, Loss: 0.40077597246946184, Test Loss: 0.6982404238860442, Train Accuracy: 56.11%, Test Accuracy: 58.50%\n",
      "Epoch 885, Loss: 0.4006490156312289, Test Loss: 0.6982607632929821, Train Accuracy: 55.44%, Test Accuracy: 58.50%\n",
      "Epoch 886, Loss: 0.40052218755648245, Test Loss: 0.6982811313253248, Train Accuracy: 55.22%, Test Accuracy: 58.50%\n",
      "Epoch 887, Loss: 0.40039548802164365, Test Loss: 0.698301527909293, Train Accuracy: 57.89%, Test Accuracy: 58.50%\n",
      "Epoch 888, Loss: 0.4002689168036662, Test Loss: 0.6983219529713147, Train Accuracy: 54.78%, Test Accuracy: 58.50%\n",
      "Epoch 889, Loss: 0.40014247368003536, Test Loss: 0.6983424064380215, Train Accuracy: 57.44%, Test Accuracy: 58.50%\n",
      "Epoch 890, Loss: 0.4000161584287658, Test Loss: 0.6983628882362493, Train Accuracy: 55.00%, Test Accuracy: 58.50%\n",
      "Epoch 891, Loss: 0.3998899708284004, Test Loss: 0.6983833982930381, Train Accuracy: 56.39%, Test Accuracy: 58.50%\n",
      "Epoch 892, Loss: 0.39976391065800865, Test Loss: 0.6984039365356297, Train Accuracy: 54.89%, Test Accuracy: 58.50%\n",
      "Epoch 893, Loss: 0.3996379776971854, Test Loss: 0.698424502891469, Train Accuracy: 56.94%, Test Accuracy: 58.50%\n",
      "Epoch 894, Loss: 0.39951217172604875, Test Loss: 0.6984450972882018, Train Accuracy: 56.06%, Test Accuracy: 58.50%\n",
      "Epoch 895, Loss: 0.3993864925252391, Test Loss: 0.6984657196536753, Train Accuracy: 55.28%, Test Accuracy: 58.50%\n",
      "Epoch 896, Loss: 0.3992609398759174, Test Loss: 0.6984863699159365, Train Accuracy: 54.61%, Test Accuracy: 58.50%\n",
      "Epoch 897, Loss: 0.3991355135597636, Test Loss: 0.6985070480032323, Train Accuracy: 56.61%, Test Accuracy: 58.50%\n",
      "Epoch 898, Loss: 0.3990102133589754, Test Loss: 0.698527753844008, Train Accuracy: 57.28%, Test Accuracy: 58.50%\n",
      "Epoch 899, Loss: 0.3988850390562665, Test Loss: 0.6985484873669081, Train Accuracy: 55.94%, Test Accuracy: 58.50%\n",
      "Epoch 900, Loss: 0.3987599904348652, Test Loss: 0.6985692485007737, Train Accuracy: 56.06%, Test Accuracy: 58.50%\n",
      "Epoch 901, Loss: 0.39863506727851306, Test Loss: 0.6985900371746445, Train Accuracy: 55.67%, Test Accuracy: 58.50%\n",
      "Epoch 902, Loss: 0.39851026937146333, Test Loss: 0.6986108533177551, Train Accuracy: 54.67%, Test Accuracy: 58.50%\n",
      "Epoch 903, Loss: 0.39838559649847916, Test Loss: 0.6986316968595365, Train Accuracy: 56.33%, Test Accuracy: 58.50%\n",
      "Epoch 904, Loss: 0.39826104844483273, Test Loss: 0.6986525677296151, Train Accuracy: 55.56%, Test Accuracy: 58.50%\n",
      "Epoch 905, Loss: 0.39813662499630353, Test Loss: 0.6986734658578116, Train Accuracy: 56.89%, Test Accuracy: 58.50%\n",
      "Epoch 906, Loss: 0.39801232593917657, Test Loss: 0.6986943911741409, Train Accuracy: 56.22%, Test Accuracy: 58.50%\n",
      "Epoch 907, Loss: 0.3978881510602415, Test Loss: 0.6987153436088106, Train Accuracy: 55.33%, Test Accuracy: 58.50%\n",
      "Epoch 908, Loss: 0.3977641001467907, Test Loss: 0.6987363230922216, Train Accuracy: 56.72%, Test Accuracy: 58.50%\n",
      "Epoch 909, Loss: 0.39764017298661836, Test Loss: 0.698757329554967, Train Accuracy: 55.50%, Test Accuracy: 58.50%\n",
      "Epoch 910, Loss: 0.39751636936801815, Test Loss: 0.6987783629278309, Train Accuracy: 58.17%, Test Accuracy: 58.50%\n",
      "Epoch 911, Loss: 0.3973926890797828, Test Loss: 0.6987994231417883, Train Accuracy: 56.17%, Test Accuracy: 58.50%\n",
      "Epoch 912, Loss: 0.3972691319112022, Test Loss: 0.6988205101280051, Train Accuracy: 54.72%, Test Accuracy: 58.50%\n",
      "Epoch 913, Loss: 0.3971456976520619, Test Loss: 0.698841623817836, Train Accuracy: 56.44%, Test Accuracy: 58.50%\n",
      "Epoch 914, Loss: 0.39702238609264157, Test Loss: 0.6988627641428252, Train Accuracy: 56.44%, Test Accuracy: 58.50%\n",
      "Epoch 915, Loss: 0.3968991970237141, Test Loss: 0.6988839310347056, Train Accuracy: 52.78%, Test Accuracy: 58.50%\n",
      "Epoch 916, Loss: 0.396776130236544, Test Loss: 0.6989051244253975, Train Accuracy: 55.56%, Test Accuracy: 58.50%\n",
      "Epoch 917, Loss: 0.3966531855228854, Test Loss: 0.6989263442470088, Train Accuracy: 56.50%, Test Accuracy: 58.50%\n",
      "Epoch 918, Loss: 0.39653036267498176, Test Loss: 0.6989475904318339, Train Accuracy: 57.17%, Test Accuracy: 58.50%\n",
      "Epoch 919, Loss: 0.39640766148556333, Test Loss: 0.698968862912353, Train Accuracy: 55.22%, Test Accuracy: 58.50%\n",
      "Epoch 920, Loss: 0.39628508174784655, Test Loss: 0.6989901616212327, Train Accuracy: 57.33%, Test Accuracy: 58.50%\n",
      "Epoch 921, Loss: 0.39616262325553236, Test Loss: 0.6990114864913233, Train Accuracy: 55.00%, Test Accuracy: 58.50%\n",
      "Epoch 922, Loss: 0.3960402858028048, Test Loss: 0.69903283745566, Train Accuracy: 55.00%, Test Accuracy: 58.50%\n",
      "Epoch 923, Loss: 0.3959180691843298, Test Loss: 0.6990542144474623, Train Accuracy: 56.00%, Test Accuracy: 58.50%\n",
      "Epoch 924, Loss: 0.3957959731952536, Test Loss: 0.6990756174001317, Train Accuracy: 55.56%, Test Accuracy: 58.50%\n",
      "Epoch 925, Loss: 0.3956739976312014, Test Loss: 0.6990970462472532, Train Accuracy: 55.72%, Test Accuracy: 58.50%\n",
      "Epoch 926, Loss: 0.39555214228827634, Test Loss: 0.6991185009225933, Train Accuracy: 56.17%, Test Accuracy: 58.50%\n",
      "Epoch 927, Loss: 0.39543040696305753, Test Loss: 0.6991399813600999, Train Accuracy: 55.72%, Test Accuracy: 58.50%\n",
      "Epoch 928, Loss: 0.39530879145259923, Test Loss: 0.6991614874939023, Train Accuracy: 55.94%, Test Accuracy: 58.50%\n",
      "Epoch 929, Loss: 0.3951872955544294, Test Loss: 0.6991830192583092, Train Accuracy: 55.22%, Test Accuracy: 58.50%\n",
      "Epoch 930, Loss: 0.39506591906654787, Test Loss: 0.6992045765878098, Train Accuracy: 56.56%, Test Accuracy: 58.50%\n",
      "Epoch 931, Loss: 0.39494466178742593, Test Loss: 0.6992261594170719, Train Accuracy: 55.78%, Test Accuracy: 58.50%\n",
      "Epoch 932, Loss: 0.3948235235160038, Test Loss: 0.6992477676809421, Train Accuracy: 56.89%, Test Accuracy: 58.50%\n",
      "Epoch 933, Loss: 0.3947025040516906, Test Loss: 0.6992694013144447, Train Accuracy: 55.56%, Test Accuracy: 58.50%\n",
      "Epoch 934, Loss: 0.3945816031943619, Test Loss: 0.6992910602527822, Train Accuracy: 55.78%, Test Accuracy: 58.50%\n",
      "Epoch 935, Loss: 0.3944608207443591, Test Loss: 0.699312744431333, Train Accuracy: 55.78%, Test Accuracy: 58.50%\n",
      "Epoch 936, Loss: 0.39434015650248766, Test Loss: 0.6993344537856524, Train Accuracy: 56.39%, Test Accuracy: 58.50%\n",
      "Epoch 937, Loss: 0.39421961027001606, Test Loss: 0.6993561882514713, Train Accuracy: 56.39%, Test Accuracy: 58.50%\n",
      "Epoch 938, Loss: 0.39409918184867443, Test Loss: 0.6993779477646962, Train Accuracy: 57.83%, Test Accuracy: 58.50%\n",
      "Epoch 939, Loss: 0.3939788710406533, Test Loss: 0.6993997322614072, Train Accuracy: 56.28%, Test Accuracy: 58.50%\n",
      "Epoch 940, Loss: 0.39385867764860216, Test Loss: 0.6994215416778599, Train Accuracy: 55.28%, Test Accuracy: 58.50%\n",
      "Epoch 941, Loss: 0.3937386014756282, Test Loss: 0.6994433759504822, Train Accuracy: 57.50%, Test Accuracy: 58.50%\n",
      "Epoch 942, Loss: 0.3936186423252949, Test Loss: 0.6994652350158759, Train Accuracy: 55.94%, Test Accuracy: 58.50%\n",
      "Epoch 943, Loss: 0.39349880000162113, Test Loss: 0.6994871188108149, Train Accuracy: 54.39%, Test Accuracy: 58.50%\n",
      "Epoch 944, Loss: 0.3933790743090795, Test Loss: 0.6995090272722452, Train Accuracy: 55.17%, Test Accuracy: 58.50%\n",
      "Epoch 945, Loss: 0.39325946505259496, Test Loss: 0.6995309603372837, Train Accuracy: 55.06%, Test Accuracy: 58.50%\n",
      "Epoch 946, Loss: 0.39313997203754414, Test Loss: 0.6995529179432185, Train Accuracy: 56.50%, Test Accuracy: 58.50%\n",
      "Epoch 947, Loss: 0.39302059506975334, Test Loss: 0.6995749000275082, Train Accuracy: 55.94%, Test Accuracy: 58.50%\n",
      "Epoch 948, Loss: 0.3929013339554977, Test Loss: 0.6995969065277808, Train Accuracy: 54.94%, Test Accuracy: 58.50%\n",
      "Epoch 949, Loss: 0.3927821885014999, Test Loss: 0.6996189373818337, Train Accuracy: 54.61%, Test Accuracy: 58.50%\n",
      "Epoch 950, Loss: 0.3926631585149288, Test Loss: 0.699640992527633, Train Accuracy: 56.11%, Test Accuracy: 58.50%\n",
      "Epoch 951, Loss: 0.3925442438033979, Test Loss: 0.6996630719033129, Train Accuracy: 56.11%, Test Accuracy: 58.50%\n",
      "Epoch 952, Loss: 0.392425444174965, Test Loss: 0.6996851754471755, Train Accuracy: 54.89%, Test Accuracy: 58.50%\n",
      "Epoch 953, Loss: 0.39230675943812965, Test Loss: 0.6997073030976897, Train Accuracy: 56.50%, Test Accuracy: 58.50%\n",
      "Epoch 954, Loss: 0.3921881894018331, Test Loss: 0.6997294547934908, Train Accuracy: 54.39%, Test Accuracy: 58.50%\n",
      "Epoch 955, Loss: 0.3920697338754562, Test Loss: 0.699751630473381, Train Accuracy: 55.33%, Test Accuracy: 58.50%\n",
      "Epoch 956, Loss: 0.39195139266881873, Test Loss: 0.6997738300763274, Train Accuracy: 57.89%, Test Accuracy: 58.50%\n",
      "Epoch 957, Loss: 0.3918331655921779, Test Loss: 0.699796053541462, Train Accuracy: 54.56%, Test Accuracy: 58.50%\n",
      "Epoch 958, Loss: 0.391715052456227, Test Loss: 0.6998183008080818, Train Accuracy: 56.00%, Test Accuracy: 58.50%\n",
      "Epoch 959, Loss: 0.3915970530720945, Test Loss: 0.6998405718156475, Train Accuracy: 55.56%, Test Accuracy: 58.50%\n",
      "Epoch 960, Loss: 0.39147916725134274, Test Loss: 0.6998628665037835, Train Accuracy: 56.67%, Test Accuracy: 58.50%\n",
      "Epoch 961, Loss: 0.39136139480596627, Test Loss: 0.6998851848122769, Train Accuracy: 55.44%, Test Accuracy: 58.50%\n",
      "Epoch 962, Loss: 0.3912437355483913, Test Loss: 0.6999075266810775, Train Accuracy: 57.17%, Test Accuracy: 58.50%\n",
      "Epoch 963, Loss: 0.391126189291474, Test Loss: 0.6999298920502969, Train Accuracy: 54.06%, Test Accuracy: 58.50%\n",
      "Epoch 964, Loss: 0.39100875584849976, Test Loss: 0.699952280860208, Train Accuracy: 56.06%, Test Accuracy: 58.50%\n",
      "Epoch 965, Loss: 0.3908914350331813, Test Loss: 0.6999746930512453, Train Accuracy: 57.39%, Test Accuracy: 58.50%\n",
      "Epoch 966, Loss: 0.39077422665965805, Test Loss: 0.699997128564003, Train Accuracy: 55.83%, Test Accuracy: 58.50%\n",
      "Epoch 967, Loss: 0.39065713054249485, Test Loss: 0.7000195873392354, Train Accuracy: 55.17%, Test Accuracy: 58.50%\n",
      "Epoch 968, Loss: 0.3905401464966805, Test Loss: 0.7000420693178567, Train Accuracy: 55.61%, Test Accuracy: 58.50%\n",
      "Epoch 969, Loss: 0.3904232743376271, Test Loss: 0.7000645744409397, Train Accuracy: 55.22%, Test Accuracy: 58.50%\n",
      "Epoch 970, Loss: 0.3903065138811679, Test Loss: 0.7000871026497153, Train Accuracy: 54.06%, Test Accuracy: 58.50%\n",
      "Epoch 971, Loss: 0.3901898649435573, Test Loss: 0.700109653885573, Train Accuracy: 56.61%, Test Accuracy: 58.50%\n",
      "Epoch 972, Loss: 0.3900733273414688, Test Loss: 0.7001322280900593, Train Accuracy: 56.28%, Test Accuracy: 58.50%\n",
      "Epoch 973, Loss: 0.3899569008919943, Test Loss: 0.7001548252048778, Train Accuracy: 55.39%, Test Accuracy: 58.50%\n",
      "Epoch 974, Loss: 0.3898405854126427, Test Loss: 0.7001774451718888, Train Accuracy: 57.61%, Test Accuracy: 58.50%\n",
      "Epoch 975, Loss: 0.3897243807213387, Test Loss: 0.7002000879331084, Train Accuracy: 57.61%, Test Accuracy: 58.50%\n",
      "Epoch 976, Loss: 0.3896082866364218, Test Loss: 0.7002227534307082, Train Accuracy: 57.72%, Test Accuracy: 58.50%\n",
      "Epoch 977, Loss: 0.38949230297664506, Test Loss: 0.7002454416070145, Train Accuracy: 53.50%, Test Accuracy: 58.50%\n",
      "Epoch 978, Loss: 0.3893764295611739, Test Loss: 0.7002681524045087, Train Accuracy: 55.50%, Test Accuracy: 58.50%\n",
      "Epoch 979, Loss: 0.3892606662095853, Test Loss: 0.7002908857658261, Train Accuracy: 56.61%, Test Accuracy: 58.50%\n",
      "Epoch 980, Loss: 0.389145012741866, Test Loss: 0.7003136416337553, Train Accuracy: 56.72%, Test Accuracy: 58.50%\n",
      "Epoch 981, Loss: 0.3890294689784118, Test Loss: 0.7003364199512383, Train Accuracy: 54.28%, Test Accuracy: 58.50%\n",
      "Epoch 982, Loss: 0.38891403474002634, Test Loss: 0.7003592206613695, Train Accuracy: 56.94%, Test Accuracy: 58.50%\n",
      "Epoch 983, Loss: 0.38879870984792014, Test Loss: 0.7003820437073958, Train Accuracy: 56.50%, Test Accuracy: 58.50%\n",
      "Epoch 984, Loss: 0.388683494123709, Test Loss: 0.7004048890327152, Train Accuracy: 55.94%, Test Accuracy: 58.50%\n",
      "Epoch 985, Loss: 0.3885683873894133, Test Loss: 0.7004277565808775, Train Accuracy: 55.61%, Test Accuracy: 58.50%\n",
      "Epoch 986, Loss: 0.38845338946745667, Test Loss: 0.7004506462955828, Train Accuracy: 56.00%, Test Accuracy: 58.50%\n",
      "Epoch 987, Loss: 0.388338500180665, Test Loss: 0.7004735581206816, Train Accuracy: 55.17%, Test Accuracy: 58.50%\n",
      "Epoch 988, Loss: 0.3882237193522653, Test Loss: 0.7004964920001746, Train Accuracy: 54.83%, Test Accuracy: 58.50%\n",
      "Epoch 989, Loss: 0.3881090468058842, Test Loss: 0.700519447878211, Train Accuracy: 55.17%, Test Accuracy: 58.50%\n",
      "Epoch 990, Loss: 0.38799448236554757, Test Loss: 0.7005424256990895, Train Accuracy: 56.61%, Test Accuracy: 58.50%\n",
      "Epoch 991, Loss: 0.3878800258556788, Test Loss: 0.7005654254072572, Train Accuracy: 54.28%, Test Accuracy: 58.50%\n",
      "Epoch 992, Loss: 0.3877656771010978, Test Loss: 0.7005884469473088, Train Accuracy: 55.39%, Test Accuracy: 58.50%\n",
      "Epoch 993, Loss: 0.3876514359270204, Test Loss: 0.700611490263987, Train Accuracy: 56.78%, Test Accuracy: 58.50%\n",
      "Epoch 994, Loss: 0.3875373021590562, Test Loss: 0.7006345553021809, Train Accuracy: 55.50%, Test Accuracy: 58.50%\n",
      "Epoch 995, Loss: 0.3874232756232088, Test Loss: 0.7006576420069266, Train Accuracy: 55.06%, Test Accuracy: 58.50%\n",
      "Epoch 996, Loss: 0.38730935614587364, Test Loss: 0.7006807503234065, Train Accuracy: 56.72%, Test Accuracy: 58.50%\n",
      "Epoch 997, Loss: 0.38719554355383745, Test Loss: 0.7007038801969477, Train Accuracy: 53.83%, Test Accuracy: 58.50%\n",
      "Epoch 998, Loss: 0.387081837674277, Test Loss: 0.7007270315730243, Train Accuracy: 56.06%, Test Accuracy: 58.50%\n",
      "Epoch 999, Loss: 0.386968238334758, Test Loss: 0.7007502043972533, Train Accuracy: 57.28%, Test Accuracy: 58.50%\n",
      "Final Loss: 0.386968238334758, Test Loss: 0.7007502043972533, Test Accuracy: 58.50%\n"
     ]
    }
   ],
   "source": [
    "# batches\n",
    "# x: data_amount x features\n",
    "# y: data_amount x 1\n",
    "# alpha: learning rate\n",
    "def train(X, y, learning_rate=0.01, iterations=100, batch_size=20):\n",
    "    # inital weights, 0s\n",
    "    # weights = np.random.rand(num_features)\n",
    "    # weights = np.random.uniform(-0.025, 0.025, num_features)\n",
    "    weights = np.zeros(num_features)\n",
    "    loss_history = []\n",
    "    test_loss_history = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        batch_Xs, batch_ys = get_batches(X, y, batch_size)\n",
    "        \n",
    "        for batch_X, batch_y in zip(batch_Xs, batch_ys):\n",
    "            # predictions from model\n",
    "            predictions = f(batch_X, weights)\n",
    "            \n",
    "            # compute loss\n",
    "            loss = BCE_loss_fn(predictions, batch_y)\n",
    "\n",
    "            # compute gradients\n",
    "            gradient = compute_gradient(batch_X, batch_y, weights, 0.1)\n",
    "            # gradient = compute_gradient_SGD(batch_X, batch_y, weights, random.randint(0, len(batch_y) - 1), 0.1)\n",
    "\n",
    "            # update weights\n",
    "            weights -= learning_rate * gradient\n",
    "        \n",
    "        # testing on test dataset    \n",
    "        test_predictions = f(X_test, weights)\n",
    "        test_loss = BCE_loss_fn(test_predictions, y_test)\n",
    "        test_acc = accuracy(test_predictions, y_test)\n",
    "        train_acc = accuracy(predictions, y_train)\n",
    "\n",
    "        # print iteration\n",
    "        print(f'Epoch {i}, Loss: {loss}, Test Loss: {test_loss}, Train Accuracy: {train_acc*100:.2f}%, Test Accuracy: {test_acc*100:.2f}%')\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            loss_history.append(loss)\n",
    "            test_loss_history.append(test_loss)\n",
    "    \n",
    "    \n",
    "    print(f'Final Loss: {loss}, Test Loss: {test_loss}, Test Accuracy: {test_acc*100:.2f}%')\n",
    "    return weights, loss_history, test_loss_history\n",
    "\n",
    "trained_weights, loss_history, test_loss_history = train(X_train, y_train, 1, 1000, 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70291a3-c3de-4630-bf06-e450224f82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "total_epochs = [10, 100, 1000, 2000, 5000]\n",
    "data_sizes = [1000, 2500, 5000, 10_000]\n",
    "data_splits = [0.1, 0.25, 0.5]\n",
    "\n",
    "def hyper_paramter_tune_train(learning_rate, total_epoch, data_size, data_split):\n",
    "    diagrams, danger = generate_dataset(data_size)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(diagrams, danger, test_size=data_split)\n",
    "\n",
    "    X_train = X_train.reshape(-1, num_features)\n",
    "    X_test = X_test.reshape(-1, num_features)\n",
    "    \n",
    "    print(f\"Training with lr: {learning_rate}, iterations: {total_epoch}, data size: {data_size}, train test split: {data_split}\")\n",
    "    trained_weights, loss_history, test_loss_history = train(X_train, y_train, learning_rate, total_epoch)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for total_epoch in total_epochs:\n",
    "        for data_size in data_sizes:\n",
    "            for data_split in data_splits:\n",
    "                hyper_paramter_tune_train(lr, total_epoch, data_size, data_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
